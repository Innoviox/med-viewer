{"articles": [{"title": "Onset, duration, and persistence of taste and smell changes and other COVID-19 symptoms: longitudinal study in Israeli patients", "abstract": "Objectives: The multifaceted manifestation of COVID-19 requires longitudinal characterization of symptoms, to aid with screening and disease management. \nMethods: Phone interviews and follow-ups were completed with 112 mostly mild COVID-19 RT-PCR-positive adult patients, over a six-months period. \nResults: More than one symptom at disease onset was experienced by ~70% of the patients. About 40% of the patients experienced fever, dry cough, headache, or muscle ache as the first symptom. Fatigue, if reported, usually was the first to appear. Smell and taste changes were experienced 3.9 \u00b1 5.4 and 4.6 \u00b1 5.7 days (mean \u00b1 SD) after disease onset and emerged as first symptom in 15% and 18% of patients, respectively. Fever had the shortest duration (5.8 \u00b1 8.6 days), and taste and smell changes were the longest-lasting symptoms (17.2 \u00b1 17.6 and 18.9 \u00b1 19.7 days, durations censored at 60 days). Longer smell recovery correlated with smell change severity. Cough, taste change and smell change persisted after negative RT-PCR tests (in 20%, 26% and 29% of the patients in total). At six-months follow-up, 46% of the patients had at least one unresolved symptom, most commonly fatigue (21%), chemosensory changes (14%) or breath difficulty (9%).\nConclusions: More than one symptom typically occurred at disease onset. Chemosensory changes and cough persisted after negative RT-PCR in a quarter of the patients. Almost half of the patients reported at least one unresolved symptom at six-months follow up, mainly fatigue, smell changes and breath difficulty. Our findings highlight the prevalence of long-lasting effects of COVID-19.", "filename": "2020.09.25.20201343v2", "doi": "doi: https://doi.org/10.1101/2020.09.25.20201343 "}, {"title": "Virus detection and identification in minutes using single-particle imaging and deep learning", "abstract": "The increasing frequency and magnitude of viral outbreaks in recent decades, epitomized by the current COVID-19 pandemic, has resulted in an urgent need for rapid and sensitive viral diagnostic methods. Here, we present a methodology for virus detection and identification that uses a convolutional neural network to distinguish between microscopy images of single intact particles of different viruses. Our assay achieves labeling, imaging and virus identification in less than five minutes and does not require any lysis, purification or amplification steps. The trained neural network was able to differentiate SARS-CoV-2 from negative clinical samples, as well as from other common respiratory pathogens such as influenza and seasonal human coronaviruses, with high accuracy. Single-particle imaging combined with deep learning offers a promising alternative to traditional viral diagnostic methods, and has the potential for significant impact.", "filename": "2020.10.13.20212035v3", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212035 "}, {"title": "A haemagglutination test for rapid detection of antibodies to SARS-CoV-2", "abstract": "Serological detection of antibodies to SARS-CoV-2 is essential for establishing rates of seroconversion in populations, detection of seroconversion after vaccination, and for seeking evidence for a level of antibody that may be protective against COVID-19 disease. Several high-performance commercial tests have been described, but these require centralised laboratory facilities that are comparatively expensive, and therefore not available universally. Red cell agglutination tests have a long history in blood typing, and general serology through linkage of reporter molecules to the red cell surface. They do not require special equipment, are read by eye, have short development times, low cost and can be applied as a Point of Care Test (POCT). We describe a red cell agglutination test for the detection of antibodies to the SARS-CoV-2 receptor binding domain (RBD). We show that the Haemagglutination Test (HAT) has a sensitivity of 90% and specificity of 99% for detection of antibodies after a PCR diagnosed infection. The HAT can be titrated, detects rising titres in the first five days of hospital admission, correlates well with a commercial test that detects antibodies to the RBD, and can be applied as a point of care test. The developing reagent is composed of a previously described nanobody to a conserved glycophorin A epitope on red cells, linked to the RBD from SARS-CoV-2. It can be lyophilised for ease of shipping. We have scaled up production of this reagent to one gram, which is sufficient for ten million tests, at a cost of ~0.27 UK pence per test well. Aliquots of this reagent are ready to be supplied to qualified groups anywhere in the world that need to detect antibodies to SARS-CoV-2, but do not have the facilities for high throughput commercial tests.", "filename": "2020.10.02.20205831v3", "doi": "doi: https://doi.org/10.1101/2020.10.02.20205831 "}, {"title": "Is it Just About Physical Health? An Online Cross-Sectional Study Exploring the Psychological Distress Among University Students in Jordan in the midst of COVID-19 Pandemic", "abstract": "Background: Since the spread of COVID-19 on a global scale, most of efforts at national and international levels were directed to mitigate the spread of the disease and its physical harm , paying less attention to the psychological impacts of COVID-19 on global mental health especially at early stages of the pandemic. \n\nObjectives: This study aimed to assess and explore (i) The levels of psychological distress and its correlates (ii) Motivation for distance learning (iii) Coping activities and pandemic related concerns, among university students in Jordan in the midst of COVID-19 pandemic\n\nMethods: A cross-sectional study was conducted using an online self-administered questionnaire. The measure of psychological distress was obtained using the 10-item Kessler Psychological Distress Scale, while other questions have explored our study second and third aims.\n\nResults: A total of 381 completed questionnaires were included in the analysis. Female participants slightly predominated the sample (n=199, 52.2%). The respondents aged 18-38 years (mean 22.6 years, SD: 3.16). Concerning distress severity, most of respondents were regarded as having severe psychological distress (n=265, 69.5%). 209 students (54.9%) reported that they had no motivation for distance learning. Ordinal logistic regression revealed a significant correlation between distress severity and many predictors. Among the predictors that were found to act as a protective factors against higher levels of distress included older age (aOR=0.64, P=0.022; 95% CI: 0.44 - 0.94)  , and  having a strong motivation for distance learning (aOR=0.10, P=0.048 ; 95% CI: 0.01 - 0.96).In contrary, being a current smoker (aOR=1.99, P=0.049 ; 95% CI: 1.10 - 3.39), and having no motivation for distance learning (aOR=2.49, P=0.007; 95% CI: 1.29 - 4.80)  acted as risk factors for having higher levels of psychological distress among the students .The most common coping activity reported was spending more time on social media platforms (n=269, 70.6%), and 209 students (54.9%) reported distance learning was their most distressing concern.\n\nConclusion: The COVID-19 pandemic and related control measures could impact the mental health of individuals, including students. We recommend a nationwide psychological support program to be incorporated into Jordan preparedness plan and response strategy in combating the COVID-19 pandemic.", "filename": "2020.05.14.20102343v3", "doi": "doi: https://doi.org/10.1101/2020.05.14.20102343 "}, {"title": "Predicting dengue in the Philippines using artificial neural network", "abstract": "Dengue fever is an infectious disease caused by Flavivirus transmitted by Aedes mosquito. This disease predominantly occurs in the tropical and subtropical regions. With no specific treatment, the most effective way to prevent dengue is vector control. The dependence of Aedes mosquito population on meteorological variables make prediction of dengue infection possible using conventional statistical and epidemiologic models. However, with increasing average global temperature, the predictability of these models may be lessened employing the need for artificial neural network. This study uses artificial neural network to predict dengue incidence in the entire Philippines with humidity, rainfall, and temperature as independent variables. All generated predictive models have mean squared logarithmic error of less than 0.04.", "filename": "2020.10.08.20209718v2", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209718 "}, {"title": "Face Masks, Public Policies and Slowing the Spread of COVID-19: Evidence from Canada", "abstract": "We estimate the impact of mask mandates and other non-pharmaceutical interventions (NPI) on COVID-19 case growth in Canada, including regulations on businesses and gatherings, school closures, travel and self-isolation, and long-term care homes. We partially account for behavioural responses using Google mobility data. Our identification strategy exploits variation in the timing of indoor face mask mandates staggered over two months in the 34 public health districts in Ontario, Canada's most populous province. We find that mask mandates are associated with a 25 percent or larger weekly reduction in new COVID-19 cases in July and August, relative to the trend in absence of mask mandate. Additional analysis with province-level data provides corroborating evidence. Counterfactual policy simulations suggest that mandating indoor masks nationwide in early July could have reduced the number of new cases in Canada by 25 to 40 percent in mid-August, which corresponds to 700 to 1,100 fewer cases per week.", "filename": "2020.09.24.20201178v2", "doi": "doi: https://doi.org/10.1101/2020.09.24.20201178 "}, {"title": "Histopathological findings in COVID-19 cases: A Systematic Review", "abstract": "Background: The current COVID-19 pandemic is considered one of the most serious public health crisis over the last few decades. Although the disease can result in diverse, multiorgan pathology, there have been very few studies addressing the postmortem pathological findings of the cases. Active autopsy amid this pandemic could be an essential tool for diagnosis, surveillance, and research. \nObjective:  To provide a total picture of the SARS-CoV-2 histopathological features of different body organs through a systematic search of the published literature.\nMethods: A systematic search of electronic databases (PubMed, ScienceDirect, Google scholar, Medrxiv & Biorxiv) was carried out from December 2019 to August, 15th 2020, for journal articles of different study designs reporting postmortem pathological findings in COVID-19 cases. PRISMA guidelines were used for reporting the review.\nResults: A total of 50 articles reporting 430 cases were included in our analysis. Postmortem pathological findings were reported for different body organs, pulmonary system (42 articles), cardiovascular system ( 23 articles), hepatobiliary system (22 articles), kidney (16 articles), spleen, and lymph nodes (12 articles), and central nervous system (7 articles).  In lung samples, diffuse alveolar damage (DAD) was the most commonly reported findings in 239 cases (84.4%). Myocardial hypertrophy (87 cases by 51.2%), arteriosclerosis (121 cases by 62%), and steatosis ( 118 cases by 59.3%) were the most commonly reported pathological findings in the heart, kidney, and hepatobiliary system respectively.\nConclusion: Autopsy examination as an investigation tool could help in a better understanding of SARS-CoV-2 pathophysiology, diagnosis, management, and subsequently improving patient care. \n\nKeywords: SARS-CoV-2, Histopathology, Autopsy, forensic pathology, COVID-19", "filename": "2020.10.11.20210849v3", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210849 "}, {"title": "Superspreaders and lockdown timing explain the power law dynamics of COVID-19", "abstract": "Infectious disease outbreaks are expected to grow exponentially in time when left unchecked. Containment measures such as lockdown and social distancing can drastically alter the growth dynamics of the outbreak. This is the case for the 2019-2020 COVID-19 outbreak, which is characterized by a power law growth. Strikingly however, the power law exponent is different across countries. Here I illustrate the relationship between these two extreme scenarios, exponential and power law growth, based on the impact of superspreaders and lockdown strategies to contain the outbreak. The theory predicts a relationship between the power law exponent and the time interval between the first case and lockdown that is validated by the observed COVID-19 data across different countries.", "filename": "2020.07.23.20160531v4", "doi": "doi: https://doi.org/10.1101/2020.07.23.20160531 "}, {"title": "The impact of physical distancing measures against COVID-19 transmission on contacts and mixing patterns in the Netherlands: repeated cross-sectional surveys in 2016/2017, April 2020 and June 2020", "abstract": "Background\nDuring the current COVID-19 pandemic many countries have taken drastic measures to reduce the transmission of SARS-CoV-2. These often include decreasing the number of contacts by physical distancing.\n\nAim\nTo measure the actual reduction of contacts when physical distancing measures are implemented.\n\nMethods\nIn the Netherlands, a cross-sectional survey was carried out in 2016/2017 in which participants reported the number and age of their contacts during the previous day. The survey was repeated among a subsample of the participants in April 2020 after physical distancing measures had been implemented, and in an extended sample in June 2020 after some of these measures were relaxed.\n\nResults\nThe average number of community contacts per day was reduced from on average 14.9 (interquartile range: 4-20) in the 2016/2017 survey to 3.5 (0-4) after physical distancing measures were implemented, and rebounded to 8.8 (1-10) after some of these measures were relaxed. All age groups restricted their number of community contacts to at most 5 contacts on average after physical distancing measures were implemented. After relaxation, children reverted to baseline levels while elderly had a number of community contacts that was less than half their baseline levels.\n\nConclusion\nThe physical distancing measures have greatly reduced contact numbers, which has likely been beneficial in curbing the first wave of the COVID-19 epidemic in the Netherlands. Different age groups reacted differently upon relaxation of these measures. These findings offer guidance for the deployment of age-targeted measures in the future course of the pandemic.", "filename": "2020.05.18.20101501v2", "doi": "doi: https://doi.org/10.1101/2020.05.18.20101501 "}, {"title": "A Quantitative Lung Computed Tomography Image Feature for Multi-Center Severity Assessment of COVID-19", "abstract": "The COVID-19 pandemic has affected millions and congested healthcare systems globally. Hence an objective severity assessment is crucial in making therapeutic decisions judiciously. Computed Tomography (CT)-scans can provide demarcating features to identify severity of pneumonia - commonly associated with COVID-19 - in the affected lungs. Here, a quantitative severity assessing chest CT image feature is demonstrated for COVID-19 patients. We incorporated 509 CT images from 101 diagnosed and expert-annotated cases (age 20-90, 60% males) in the study collected from a multi-center Italian database sourced from 41 radio-diagnostic centers. Lesions in the form of opacifications, crazy-paving patterns, and consolidations were segmented. The severity determining feature - L_norm was quantified and established to be statistically distinct for the three - mild, moderate, and severe classes (p-value<0.0001). The thresholds of L_norm for a 3-class classification were determined based on the optimum sensitivity/specificity combination from Receiver Operating Characteristic (ROC) analyses. The feature L_norm classified the cases in the three severity categories with 86.88% accuracy. `Substantial' to `almost-perfect' intra-rater and inter-rater agreements were achieved involving expert (manual segmentation) and non-expert (graph-cut and deep-learning based segmentation) labels (kappa-score 0.79-0.97). We trained several machine learning classification models and showed L_norm alone has a superior diagnostic accuracy over standard image intensity and texture features. Classification accuracy was further increased when L_norm was used for 2-class classification i.e. to delineate the severe cases from non-severe ones with a high sensitivity (97.7%), and specificity (97.49%). Therefore, key highlights of the COVID-19 severity assessment feature are high accuracy, low dependency on expert availability, and wide utility across different CT-imaging centers.", "filename": "2020.07.13.20152231v2", "doi": "doi: https://doi.org/10.1101/2020.07.13.20152231 "}, {"title": "COVID-19 Susceptibility and Severity Risks in a Survey of Over 500,000 People", "abstract": "The growing toll of the COVID-19 pandemic has heightened the urgency of identifying individuals most at risk of infection and severe outcomes, underscoring the need to assess susceptibility and severity patterns in large datasets. The AncestryDNA COVID-19 Study collected self-reported survey data on symptoms, outcomes, risk factors, and exposures for over 563,000 adult individuals in the U.S., including over 4,700 COVID-19 cases as measured by a self-reported positive nasal swab test. We observed significant associations between several risk factors and COVID-19 susceptibility and severity outcomes. Many of the susceptibility associations were accounted for by differences in known exposures; a notable exception was elevated susceptibility odds for males after adjusting for known exposures and age. We also leveraged the dataset to build risk models to robustly predict individualized COVID-19 susceptibility (area under the curve [AUC]=0.84) and severity outcomes including hospitalization and life-threatening critical illness amongst COVID-19 cases (AUC=0.87 and 0.90, respectively).  The results highlight the value of self-reported epidemiological data at scale to provide public health insights into the evolving COVID-19 pandemic.", "filename": "2020.10.08.20209593v2", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209593 "}, {"title": "Risk of death during the 2020 UK COVID-19 epidemic among people with rare autoimmune diseases compared to the general population. A whole-population study in England, using data from the National Disease Registration Service and the Registration of Complex Rare Diseases - exemplars in Rheumatology (RECORDER) project.", "abstract": "Objectives: To quantify the risk of death among people with rare autoimmune rheumatic diseases (RAIRD) during the UK 2020 COVID-19 epidemic compared with baseline risk and the risk of death in the general population during COVID-19.\n\nDesign A cohort study using data from the National Congenital Anomaly and Rare Disease Registration Service (NCARDRS). We used ONS published data for general population mortality rates.\n\nSetting: Hospital Episode Statistics for England 2003 onwards, and linked data from the NHS Personal Demographics Service.\n\nParticipants: 168,691 people with RAIRD who were alive on 1 March 2020. Their median age was 61.7 (IQR 41.5-75.4) years, and 118,379 (70.2%) were female. Our case ascertainment methods had a positive predictive value >85%.\n\nMain outcome measure: Age-standardised mortality rates for all-cause death. Secondary outcome measures were age-sex standardised mortality rates, and age-stratified mortality rates.\n\nResults: 1,815 (1.1%) participants died during March and April 2020. The age-standardised mortality rate (ASMR) among people with RAIRD (3669.3, 95% CI 3500.4-3838.1 per 100,000 person-years) was 1.44 (95% CI 1.42-1.45) times higher than the average ASMR during the same months of the previous 5 years, whereas in the general population of England it was 1.38 times higher. Compared to the general population, the age-specific mortality rates in people with RAIRD compared to the pre-COVID rates were higher from the age of 35 upwards, whereas in the general population the increased risk began from age 55 upwards. Sex-specific mortality rates were similar in males and females, whereas pre-COVID women with rare autoimmune rheumatic diseases had lower mortality rates. This means women had a greater increase in mortality rates during COVID-19 compared to men.\n\nConclusions: The risk of all-cause death is more prominently raised during COVID-19 among people with RAIRD than among the general population. We urgently need to quantify how much risk is due to COVID-19 infection and how much is due to disruption to healthcare services, in order to inform better guidance about shielding, access to healthcare and vaccine priorities for people with rare diseases.", "filename": "2020.10.09.20210237v2", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210237 "}, {"title": "Physiological and psychosocial correlates of cancer related fatigue", "abstract": "Cancer-related fatigue (CRF) is a common and distressing symptom of cancer and its treatments that may persist for years following treatment completion in approximately one-third of cancer survivors. Despite its high prevalence, little is known about the pathophysiology of CRF. Using a comprehensive group of physiological and psychosocial variables, the aim of the present study was to identify correlates of CRF in a heterogenous group of cancer survivors. Ninety-three cancer survivors (51 fatigued, 42 non-fatigued, with grouping based on validated cut-off scores derived from The Functional Assessment of Chronic Illness Therapy - Fatigue scale) completed assessments of performance fatigability (i.e. the change in maximal force-generating capacity, contractile function and capacity of the central nervous system to activate muscles caused by cycling exercise), cardiopulmonary exercise testing, venous blood samples for whole blood cell count and inflammatory markers and body composition. Participants also completed questionnaires measuring demographic, treatment-related, and psychosocial variables. The results showed that performance fatigability (decline in muscle strength during exercise), time-to-task-failure, peak oxygen uptake (V\u0307O2peak), tumor necrosis factor-\u03b1 (TNF-\u03b1), body fat percentage and lean mass index were associated with CRF severity. Performance fatigability, V\u0307O2peak, TNF-\u03b1 and age explained 35% of the variance in CRF severity. Furthermore, those with clinically-relevant CRF reported more pain, more depressive symptoms, less social support, and were less physically active than non-fatigued cancer survivors. Given the association between CRF and numerous physical activity related measures, including performance fatigability, cardiorespiratory fitness, and anthropometric measures, the present study identifies potential biomarkers by which the mechanisms underpinning the effect of physical activity interventions on CRF can be investigated.", "filename": "2020.10.14.20212589v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212589 "}, {"title": "The impact of anorexia nervosa and obesity polygenic risk on childhood growth: a 20-year longitudinal population-based study", "abstract": "Background: Deviating growth from the norm during childhood has been associated with anorexia nervosa (AN) and obesity later in life. In this study, we examined whether polygenic scores (PGS) for AN and obesity are associated, individually or combined, with a range of anthropometric trajectories spanning the first two decades of life. Methods: AN-PGS and obesity-PGS were calculated for participants of the Avon Longitudinal Study of Parents and Children (ALSPAC; N= 8,654 participants with genotype data and at least one outcome measure). Using generalized (mixed) linear models, we associated PGS with trajectories of weight, height, body mass index (BMI), fat mass index (FMI), lean mass index (LMI), and bone mineral density (BMD). Growth trajectories were derived using spline modeling or mixed effects modeling. Results: Between age 5-24 years, Females with one SD higher AN-PGS had on average a 0.01% lower BMI trajectory, and between age 10-24 years a 0.01% lower FMI trajectory and 0.05% lower weight trajectory. Higher obesity-PGS was associated with higher BMI, FMI, LMI, BMD, weight, and lower height trajectories in both sexes. The average growth trajectories of females with high AN-PGS/low obesity-PGS remained consistently lower than those with low AN-PGS/low obesity-PGS; this difference did not reach statistical significance. However, post-hoc comparisons suggest that females with high AN-PGS/low obesity-PGS did follow lower growth trajectories compared to those with high PGS for both traits. Conclusion: AN-PGS and obesity-PGS have detectable sex-dependent effects on a range of anthropometry trajectories. These findings encourage further research in understanding how the AN-PGS and the obesity-PGS co-influence growth during childhood in which the obesity-PGS can mitigate the effects of the AN-PGS.", "filename": "2020.10.15.20200600v1", "doi": "doi: https://doi.org/10.1101/2020.10.15.20200600 "}, {"title": "A betacoronavirus multiplex microsphere immunoassay detects early SARS-CoV-2 seroconversion and controls for pre-existing seasonal human coronavirus antibody cross-reactivity", "abstract": "With growing concern of persistent or multiple waves of SARS-CoV-2 in the United States, sensitive and specific SARS-CoV-2 antibody assays remain critical for community and hospital-based SARS-CoV-2 surveillance. Here, we describe the development and application of a multiplex microsphere-based immunoassay (MMIA) for COVD-19 antibody studies, utilizing serum samples from non-human primate SARS-CoV-2 infection models, an archived human sera bank and subjects enrolled at five U.S. military hospitals. The MMIA incorporates prefusion stabilized spike glycoprotein trimers of SARS-CoV-2, SARS-CoV-1, MERS-CoV, and the seasonal human coronaviruses HCoV-HKU1 and HCoV-OC43, into a multiplexing system that enables simultaneous measurement of off-target pre-existing cross-reactive antibodies. We report the sensitivity and specificity performances for this assay strategy at 98% sensitivity and 100% specificity for subject samples collected as early as 10 days after the onset of symptoms. In archival sera collected prior to 2019 and serum samples from subjects PCR negative for SARS-CoV-2, we detected seroprevalence of 72% and 98% for HCoV-HKU1 and HCoV-0C43, respectively. Requiring only 1.25 uL of sera, this approach permitted the simultaneous identification of SARS-CoV-2 seroconversion and polyclonal SARS-CoV-2 IgG antibody responses to SARS-CoV-1 and MERS-CoV, further demonstrating the presence of conserved epitopes in the spike glycoprotein of zoonotic betacoronaviruses. Application of this serology assay in observational studies with serum samples collected from subjects before and after SARS-CoV-2 infection will permit an investigation of the influences of HCoV-induced antibodies on COVID-19 clinical outcomes.", "filename": "2020.10.14.20207050v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20207050 "}, {"title": "ATTENTIONAL MODULATION OF NEURAL DYNAMICS IN TACTILE PERCEPTION OF COMPLEX REGIONAL PAIN SYNDROME PATIENTS", "abstract": "Body perceptual disturbances are an increasingly acknowledged set of symptoms and possible clinical markers of Complex Regional Pain Syndrome (CRPS), but the neurophysiological and neurocognitive changes that underlie them are still far from being clear. We adopted a novel multivariate and neurodynamical approach to the analysis of EEG modulations evoked by touch, to highlight differences between patients and healthy controls, between affected and unaffected side of the body, and between 'passive' (i.e. no task demands and equiprobable digit stimulation) and 'active' tactile processing (i.e. where a digit discrimination task was administered and spatial probability manipulated). Contrary to our expectations we found no support for early differences in neural processing between CRPS and healthy participants, however, there was increased decodability in the CRPS group compared to healthy volunteers between 280 and 320 ms after stimulus onset. This group difference seemed to be driven by the affected rather than the unaffected side and was enhanced by attentional demands. These results found support in the exploratory analysis of neural representation dynamics and behavioural modelling, highlighting the need for single participant analyses. Although several limitations impacted the robustness and generalizability of our comparisons, the proposed novel analytical approach yielded promising insights (as well as possible biomarkers based on neural dynamics) into the relatively unexplored alterations of tactile decision-making and attentional control mechanisms in chronic CRPS.", "filename": "2020.10.14.20212464v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212464 "}, {"title": "Estimating incidence of infection from diverse data sources: Zika virus in Puerto Rico, 2016", "abstract": "Emerging epidemics are challenging to track. Only a subset of cases is recognized and reported, as seen with the Zika virus (ZIKV) epidemic where large proportions of infection were asymptomatic. However, multiple imperfect indicators of infection provide an opportunity to estimate the underlying incidence of infection. We developed a modeling approach that integrates a generic Time-series Susceptible-Infected-Recovered epidemic model with assumptions about reporting biases in a Bayesian framework and applied it to the 2016 Zika epidemic in Puerto Rico using three indicators: suspected arboviral cases, suspected Zika-associated Guillain-Barre Syndrome cases, and blood bank data. Using this combination of surveillance data, we estimated the peak of the epidemic occurred during the week of August 15, 2016 (the 33rd week of year), and 120 to 140 (50% credible interval [CrI], 95% CrI: 97 to 170) weekly infections per 10,000 population occurred at the peak. By the end of 2016, we estimated that approximately 890,000 (95% CrI: 660,000 to 1,100,000) individuals were infected in 2016 (26%, 95% CrI: 19% to 33%, of the population infected). Utilizing multiple indicators offers the opportunity for real-time and retrospective situational awareness to support epidemic preparedness and response.", "filename": "2020.10.14.20212134v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212134 "}, {"title": "How to remove the testing bias in CoV-2 statistics", "abstract": "BACKGROUND. Public health measures and private behaviour are based on reported numbers of SARS-CoV-2 infections. Some argue that testing influences the confirmed number of\ninfections.\nOBJECTIVES/METHODS. Do time series on reported infections and the number of tests allow one to draw conclusions about actual infection numbers? A SIR model is presented where the true numbers of susceptible, infectious and removed individuals are unobserved. Testing is\nalso modelled.\nRESULTS. Official confirmed infection numbers are likely to be biased and cannot be compared over time. The bias occurs because of different reasons for testing (e.g. by symptoms, representative or testing travellers). The paper illustrates the bias and works out the effect of the number of tests on the number of reported cases. The paper also shows that the positive rate (the ratio of positive tests to the total number of tests) is uninformative in the presence of non-representative testing.\nCONCLUSIONS. A severity index for epidemics is proposed that is comparable over time. This index is based on Covid-19 cases and can be obtained if the reason for testing is known.", "filename": "2020.10.14.20212431v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212431 "}, {"title": "Title: COVID-19 and frontline health workers in West Africa: a scoping review", "abstract": "Introduction\nThe novel Coronavirus 2019 (COVID-19) has become a severe global health threat since its emergence. Overcoming the virus is partly dependent on the holistic well-being of frontline health workers. Implications of COVID-19 on frontline health workers in West Africa could be substantial given the limited resources and logistics. This scoping review maps available literature on the impact of COVID-19 on frontline health workers in West Africa.\nMaterials and methods\nLiterature on the impact of COVID-19 on frontline health workers in West Africa were searched in six databases namely Cochrane Library, PubMed, EMBASE, Google Scholar, Africa Journals Online (AJOL) and CINAHL. Further search was done across websites of the ministries of health of West African countries and notable organisations. We conducted a narrative synthesis of the findings taking cognisance of the overarching purpose of the study and the research question.\nResults\nOf the 67 studies identified, 19 were included in the final synthesis. Three main themes emerged and these are impact of COVID-19 on frontline health workers, drivers of susceptibility to COVID-19 and government/donor support. A greater number of the studies originated from Nigeria. Each study reported at least one impact of COVID-19 on frontline health workers in West Africa. The impacts included death, fear, unwillingness to attend to COVID-19 patients and stigmatisation. Some health workers were not adhering to the safety protocols coupled with periodic shortage of personal protective equipment (PPE) and thereby had an increased susceptibility.\nConclusion\nBeing the first scoping review on the impact of COVID-19 on frontline health workers in West Africa, the study has illustrated the urgent need for West African governments to enact laws/rules that would compel all frontline health workers to adhere to all the COVID-19 protocols at the workplace. To end intermittent shortage or issue of inadequate PPEs, governments ought to liaise with local industries by empowering them, providing financial support and creating a conducive atmosphere for them to produce cost effective PPEs using available local resources.", "filename": "2020.10.15.20213249v1", "doi": "doi: https://doi.org/10.1101/2020.10.15.20213249 "}, {"title": "Microscale dynamics of electrophysiological markers of epilepsy", "abstract": "Objective: \nInterictal discharges (IIDs) and high frequency oscillations (HFOs) are neurophysiologic biomarkers of epilepsy. In this study, we use custom poly(3,4-ethylenedioxythiophene) polystyrene sulfonate (PEDOT:PSS) microelectrodes to better understand their microscale dynamics.\n\nMethods:\nElectrodes with spatial resolution down to 50\u03bcm were used to record intraoperatively in 30 subjects. For IIDs, putative spatiotemporal paths were generated by peak-tracking, followed by clustering. For HFOs, repeating patterns were elucidated by clustering similar time windows. Fast events, consistent with multi-unit activity (MUA), were covaried with either IIDs or HFOs.\n\nResults:\nIIDs seen across the entire array were detected in 93% of subjects. Local IIDs, observed across <50% of the array, were seen in 53% of subjects. IIDs appeared to travel across the array in specific paths, and HFOs appeared in similar repeated spatial patterns. Finally, microseizure events were identified spanning 50-100\u03bcm. HFOs covaried with MUA, but not with IIDs.\n\nConclusions:\nOverall, these data suggest micro-domains of irritable cortex that form part of an underlying pathologic architecture that contributes to the seizure network.\n\nSignificance:\nMicroelectrodes in cases of human epilepsy can reveal dynamics that are not seen by conventional electrocorticography and point to new possibilities for their use in the diagnosis and treatment of epilepsy.", "filename": "2020.10.14.20211649v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20211649 "}, {"title": "Novel Machine-Learned Approach for COVID-19 Resource Allocation: A Tool for Evaluating Community Susceptibility", "abstract": "Despite worldwide efforts to develop an effective COVID vaccine, it is quite evident that initial supplies will be limited. Therefore, it is important to develop methods that will ensure that the COVID vaccine is allocated to the people who are at major risk until there is a sufficient global supply. Herein, I developed a machine-learning tool that could be applied to assess the risk in communities based on social, medical, and lifestyle risk factors. As a proof of concept, I modeled COVID risk in the Massachusetts communities using 29 risk factors, including the prevalence of preexisting comorbid conditions like COPD and social factors such as racial composition. Of the 29 factors, 14 were found to be significant (p < 0.1) indicators: poverty, food insecurity, lack of high school education, lack of health insurance coverage, premature mortality, population, population density, recent population growth, Asian percentage, high-occupancy housing, and preexisting prevalence of cancer, COPD, overweightness, and heart attacks. The machine-learning approach finds the 9 highest risk communities in the state of Massachusetts: Lynn, Brockton, Revere, Randolph, Lowell, New Bedford, Everett, Waltham, and Fitchburg. The 5 most at-risk counties are Suffolk, Middlesex, Bristol, Norfolk, and Plymouth. With appropriate data, the tool could evaluate risk in other communities, or even enumerate individual patient susceptibility. A ranking of communities by risk may help policymakers ensure equitable allocation of limited doses of the COVID vaccine.", "filename": "2020.10.14.20212571v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212571 "}, {"title": "The effect of influenza vaccination on trained immunity: impact on COVID-19", "abstract": "Every year, influenza causes 290.000 to 650.000 deaths worldwide and vaccination is encouraged to prevent infection in high-risk individuals. Interestingly, cross-protective effects of vaccination against heterologous infections have been reported, and long-term boosting of innate immunity (also termed trained immunity) has been proposed as the underlying mechanism. Several epidemiological studies also suggested cross-protection between influenza vaccination and COVID-19 during the current pandemic.  However, the mechanism behind such an effect is unknown. Using an established in-vitro model of trained immunity, we demonstrate that the quadrivalent inactivated influenza vaccine used in the Netherlands in the 2019-2020 influenza season can induce a trained immunity response, including an improvement of cytokine responses after stimulation of human immune cells with SARS-CoV-2. In addition, we found that SARS-CoV-2 infection was less common among Dutch hospital employees who had received influenza vaccination during the 2019/2020 winter season (RR = 0,61 (95% CI, 0.4585 - 0.8195, P = 0.001). In conclusion, a quadrivalent inactivated influenza vaccine can induce trained immunity responses against SARS-CoV-2, which may result in relative protection against COVID-19. These data, coupled with similar recent independent reports, argue for a beneficial effect of influenza vaccination against influenza as well as COVID-19, and suggests its effective deployment in the 2020-2021 influenza season to protect against both infections.", "filename": "2020.10.14.20212498v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212498 "}, {"title": "Early Prediction of COVID-19 Severity Using Extracellular Vesicles and Extracellular RNAs", "abstract": "The clinical manifestations of COVID-19 vary broadly, ranging from asymptomatic infection to acute respiratory failure and death. But the predictive biomarkers for characterizing the variability are still lacking. Since emerging evidence indicates that extracellular vesicles (EVs) and extracellular RNAs (exRNAs) are functionally involved in a number of pathological processes, we hypothesize that these extracellular components may be key determinants and/or predictors of COVID-19 severity. To test our hypothesis, we collected serum samples from 31 patients with mild COVID-19 symptoms at the time of their admission. After standard therapy without corticosteroids, 9 of the 31 patients developed severe COVID-19 symptoms. We analyzed EV protein and exRNA profiles to look for correlations between these profiles and COVID-19 severity. Strikingly, we identified three distinct groups of markers (antiviral response-related EV proteins, coagulation-related markers, and liver damage-related exRNAs) with the potential to serve as early predictive biomarkers for COVID-19 severity. Among these markers, EV COPB2 has the best predictive value for severe deterioration of COVID-19 patients in this cohort. This type of information concerning functional extracellular component profiles could have great value for patient stratification and for making early clinical decisions about strategies for COVID-19 therapy.", "filename": "2020.10.14.20212340v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212340 "}, {"title": "Multi-organ impairment in low-risk individuals with long COVID", "abstract": "Background: Severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) infection has disproportionately affected older individuals and those with underlying medical conditions. Research has focused on short-term outcomes in hospital, and single organ involvement. Consequently, impact of long COVID (persistent symptoms three months post-infection) across multiple organs in low-risk individuals is yet to be assessed.\n\nMethods: An ongoing prospective, longitudinal, two-centre, observational study was performed in individuals symptomatic after recovery from acute SARS-CoV-2 infection. Symptoms and organ function (heart, lungs, kidneys, liver, pancreas, spleen) were assessed by standardised questionnaires (EQ-5D-5L, Dyspnoea-12), blood investigations and quantitative magnetic resonance imaging, defining single and multi-organ impairment by consensus definitions.  \n\nFindings: Between April and September 2020, 201 individuals (mean age 44 (SD 11.0) years, 70% female, 87% white, 31% healthcare workers) completed assessments following SARS-CoV-2 infection (median 140, IQR 105-160 days after initial symptoms). The prevalence of pre-existing conditions (obesity: 20%, hypertension: 6%; diabetes: 2%; heart disease: 4%) was low, and only 18% of individuals had been hospitalised with COVID-19. Fatigue (98%), muscle aches (88%), breathlessness (87%), and headaches (83%) were the most frequently reported symptoms. Ongoing cardiorespiratory (92%) and gastrointestinal (73%) symptoms were common, and 42% of individuals had ten or more symptoms. \n\nThere was evidence of mild organ impairment in heart (32%), lungs (33%), kidneys (12%), liver (10%), pancreas (17%), and spleen (6%). Single (66%) and multi-organ (25%) impairment was observed, and was significantly associated with risk of prior COVID-19 hospitalisation (p<0.05).\n\nInterpretation: In a young, low-risk population with ongoing symptoms, almost 70% of individuals have impairment in one or more organs four months after initial symptoms of SARS-CoV-2 infection. There are implications not only for burden of long COVID but also public health approaches which have assumed low risk in young people with no comorbidities.", "filename": "2020.10.14.20212555v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212555 "}, {"title": "Enrichment for Cases of African-American Patients with Pathogenic TTR V142I Variant in the TOPCAT Trial", "abstract": "Transthyretin cardiac amyloidosis (ATTR-CA) is a treatable cause of heart failure with a hereditary form that disproportionally affects patients of West African ancestry. The clinical management of ATTR-CA has dramatically changed in the past five years, with rapidly evolving diagnostic approaches and life-prolonging therapies. The TTR variant c.424G>A, p.V142I (aka V122I) is pathogenic and occurs in 3-4% of individuals of West African ancestry. Despite its high frequency, V142I ATTR-CA is often unrecognized due to variable clinical penetrance, limited knowledge, and lack of inexpensive non-invasive diagnostic tests. Currently unknown is which TTR V142I carriers will progress to heart failure and at what age. Here we studied the prevalence of TTR V142I among a random cohort of African-American patients enrolled in the Treatment of Preserved Cardiac Function Heart Failure With an Aldosterone Antagonist Trial (TOPCAT). Three of the 26 HFpEF patients (11.5%) studied carried the pathogenic TTR V142I variant. While we cannot conclude at this point that TTR V142I was the underlying cause of the clinical phenotype in these patients, our results suggest that rapid TTR V142I genotyping, in combination with heart imaging, could have immediate clinical utility for identifying under-/mis-diagnosed HFpEF patients.", "filename": "2020.10.14.20201046v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20201046 "}, {"title": "On Modeling of COVID-19 for the Indian Subcontinent using Polynomial and Supervised Learning Regression", "abstract": "COVID-19, a recently declared pandemic by WHO has taken the world by storm causing catastrophic damage to human life. The novel cornonavirus disease was first incepted in the Wuhan city of China on 31st December 2019. The symptoms include fever, cough, fatigue, shortness of breath or breathing difficulties, and loss of smell and taste. Since the devastating phenomenon is essentially a time-series representation, accurate modeling may benefit in identifying the root cause and accelerate the diagnosis. In the current analysis, COVID-19 modeling is done for the Indian subcontinent based on the data collected for the total cases confirmed, daily recovered, daily deaths, total recovered and total deaths. The data is treated with total confirmed cases as the target variable and rest as feature variables. It is observed that Support vector regressions yields accurate results followed by Polynomial regression. Random forest regression results in overfitting followed by poor Bayesian regression due to highly correlated feature variables. Further, in order to examine the effect of neighbouring countries, Pearson correlation matrix is computed to identify geographic cause and effect.", "filename": "2020.10.14.20212563v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212563 "}, {"title": "Development and Validation of a Deep Learning Model for Automated View Classification of Pediatric Focused Assessment with Sonography for Trauma (FAST)", "abstract": "The pediatric Focused Assessment with Sonography for Trauma (FAST) is a sequence of ultrasound views rapidly performed by the clinician to diagnose hemorrhage. One limitation of FAST is inconsistent acquisition of required views.  We sought to develop a deep learning model and classify FAST views using a heterogeneous dataset of pediatric FAST. This study of diagnostic test developed and tested a deep learning model for view classification of archived real-world pediatric FAST studies collected from two pediatric emergency departments. FAST frames were randomly distributed to training, validation, and test datasets in a 70:20:10 ratio; each patient was represented in only one dataset to maintain sample independence. The outcome was the prediction accuracy of the model in classifying FAST frames and video clips. FAST studies performed by 30 different clinicians from 699 injured children included 4,925 videos representing 1,062,612 frames from children who were a median of 9 years old. On test dataset, the overall view classification accuracy for the model was 93.4% (95% CI: 93.3-93.6) for frames and 97.8% (95% CI: 96.0-99.0) for video clips. Frames were correctly classified with an accuracy of 96.0% (95% CI: 95.9-96.1) for cardiac, 99.8% (95% CI: 99.8-99.8) for thoracic, 95.2% (95% CI: 95.0-95.3) for abdominal upper quadrants, and 95.9% (95% CI: 95.8-96.0) for suprapubic. A deep learning model can be developed to accurately classify pediatric FAST views. Accurate view classification is the important first step to support developing a consistent and accurate multi-stage deep learning model for pediatric FAST interpretation.", "filename": "2020.10.14.20206607v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20206607 "}, {"title": "Identifying Factors Associated with Neonatal Mortality in Sub-Saharan Africa using Machine Learning", "abstract": "This study aimed at identifying the factors associated with neonatal mortality. We analyzed the Demographic and Health Survey (DHS) datasets from 10 Sub-Saharan countries. For each survey, we trained machine learning models to identify women who had experienced a neonatal death within the 5 years prior to the survey being administered. We then inspected the models by visualizing the features that were important for each model, and how, on average,\nchanging the values of the features affected the risk of neonatal mortality. We confirmed the known positive correlation between birth frequency and neonatal mortality and identified an unexpected negative correlation between household size and neonatal mortality. We further established that mothers living in smaller households have a higher risk of neonatal mortality compared to mothers living in larger households; and that factors such as the age and gender of the head of the household may influence the association between household size and neonatal mortality.", "filename": "2020.10.14.20212225v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212225 "}, {"title": "Role of the common PRSS1-PRSS2 haplotype in alcoholic and non-alcoholic chronic pancreatitis: meta- and re-analyses", "abstract": "The association between a common PRSS1-PRSS2 haplotype and alcoholic chronic pancreatitis (ACP), which was revealed by the first genome-wide association study of chronic pancreatitis (CP), has been consistently replicated. However, the association with non-ACP (NACP) has been controversial. Herein, we sought to clarify this basic issue by means of an allele-based meta-analysis of currently available studies. We then used studies informative for genotype distribution to explore the biological mechanisms underlying the association data and to test for gene-environment interaction between the risk haplotype and alcohol consumption by means of a re-analysis. A literature search was conducted to identify eligible studies. Meta-analysis was performed using the Review Manager software. The association between the risk genotypes and NACP or ACP was tested for the best-fitting genetic model. Gene-environment interaction was estimated by both case-only and multinomial approaches. Five and eight studies were employed for the meta-analysis of ACP and NACP findings, respectively. The risk allele was significantly associated with both ACP (pooled OR 1.67, 95% CI 1.56-1.78; P<0.00001) and NACP (pooled OR 1.28, 95% CI 1.17-1.40; P<0.00001). Consistent with a dosage effect of the risk allele on PRSS1/PRSS2 mRNA expression in human pancreatic tissue, both ACP and NACP association data were best explained by an additive genetic model. Finally, the risk haplotype was found to interact synergistically with ACP.", "filename": "2020.10.13.20212365v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212365 "}, {"title": "TREATMENT PROFILES AND CLINICAL OUTCOMES OF COVID-19 PATIENTS AT PRIVATE HOSPITAL IN JAKARTA", "abstract": "Background: Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) is a virus that causes COVID-19, which has become a worldwide pandemic. However, until now, there is no vaccine or specific drug to prevent or treat COVID-19. Objectives: To find out the effective treatment as an antiviral agent for COVID-19, to determine the correlation between sociodemography with clinical outcomes and duration of treatment, and to determine the relationship between comorbidities with clinical outcomes and duration of treatment for COVID-19 patients. Methods: A prospective cohort study was conducted in this study. This study included only confirmed COVID-19 patients who were admitted to the hospital during April-May 2020. Convenience sampling was used to select 103 patients, but only 72 patients were suitable for inclusion. Results: The survival analysis for COVID-19 patients using the Kaplan Meier method showed that patients receiving Oseltamivir + Hydroxychloroquine had an average survival rate of about 83% after undergoing treatment for about ten days. Gender (p = 0.450) and age (p = 0.226) did not have a significant correlation with the duration of treatment for COVID-19 patients. Gender (p = 0.174) and age (p = 0.065) also did not have a significant correlation with clinical outcome of COVID-19 patients. Comorbidities showed a significant correlation with duration of treatment (p = 0.002) and clinical outcome (p = 0.014) of COVID-19 patients. Conclusion: The most effective antiviral agent in this study based on treatment duration was the combination of Oseltamivir + Hydroxychloroquine.The higher the patient's average treatment duration, the lower the average survival rate for COVID-19 patients.", "filename": "2020.10.14.20212449v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212449 "}, {"title": "LuftiBus in the school (LUIS): a population-based study on respiratory health in schoolchildren.", "abstract": "Respiratory disease is common in children and strongly associated with lifestyle and environmental exposures. Thus, it is important to study the epidemiology locally. LuftiBus in the school (LUIS) was set up to assess the respiratory health of schoolchildren in the canton of Zurich, Switzerland.\n\nLUIS is a cross-sectional population-based study that was carried-out 2013 to 2016. Children aged 6-17 years living in the canton of Zurich were eligible to participate. All schools in the canton were approached and the school head decided whether the school would participate and with which classes. Consenting parents answered a standardized questionnaire at home and assenting children completed a shorter questionnaire by interview at school. Trained technicians measured children's lung function including spirometry, double tracer gas single-breath washout (DTG-SBW) and fractional exhaled nitric oxide (FeNO). Address histories of participants were geocoded and can be linked with area-based socioeconomic measures and environmental exposures including spatiotemporal air pollution estimates for specific time periods and locations. A subgroup was seen again 12 months later using the same procedures to collect longitudinal data.\n\nThe study included 3879 children at baseline and 646 at the one-year follow-up. Median age was 12.7 years; 281 (8%) had wheezed in the past year. At baseline we collected 3466 (89%) parental and 3555 (92%) children's questionnaires, and 3402 (88%) FeNO, 3478 (90%) spirometry, and 2251 (58%) DTG-SBW measurements. \n\nLUIS is a rich resource of health-related data, with information on lung function, environmental exposures and respiratory health on Swiss schoolchildren.", "filename": "2020.10.14.20212076v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212076 "}, {"title": "CoViD-19, learning from the past: A wavelet and cross-correlation analysis of the epidemic dynamics looking to emergency calls and Twitter trends in Italian Lombardy region", "abstract": "The first case of Coronavirus Disease 2019 in Italy was detected on February the 20th  in Lombardy region. Since that date, Lombardy has been the most affected Italian region by the epidemic, and its healthcare system underwent a severe crisis during the outbreak. From a public health point of view, therefore, it is fundamental to provide healthcare services with tools that can reveal a possible new epidemic burden with a certain time anticipation, which is the main aim of the present study. Moreover, the sequence of law decrees to face the epidemic and the large amount of news generated in the population feelings of anxiety and suspicion. Considering this whole complex context, it is easily understandable how people overcrowded social media with messages dealing with the pandemic, and emergency numbers were overwhelmed by the calls. Thus, in order to find potential predictors of a possible second epidemic wave, we analyzed data both from Twitter and from emergency services comparing them to the daily infected time series at a regional level. Since our principal goal is to forecast a possible new ascending phase of the epidemic, we performed a wavelet analysis in the time-frequency plane, to finely discriminate over time the anticipation capability of the considered potential predictors. In addition, a cross-correlation analysis has been performed to find a synthetic indicator of the time delay between the predictor and the infected time series. Our results show that Twitter data are more related to social and political dynamics, while the emergency calls trends can be further evaluated as a powerful tool to potentially forecast a new burden. Since we analyzed aggregated regional data, and taking into account also the huge geographical heterogeneity of the epidemic spread, a future perspective would be to conduct the same analysis on a more local basis.", "filename": "2020.10.14.20212415v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212415 "}, {"title": "Analysis of Collective Response Reveals that COVID-19-Related Activities Start From the End of 2019 in Mainland China", "abstract": "While the COVID-19 outbreak is making an impact at a global scale, the collective response to the pandemic becomes the key to analyzing past situations, evaluating current measures, and formulating future predictions. In this paper, we analyze the public reactions to the pandemic using search engine data and mobility data from Baidu Search and Baidu Maps respectively, where we particularly pay attentions to the early stage of pandemics and find early signals from the collective response to COVID-19. First, we correlate the number of confirmed cases per day to daily search queries of a large number of keywords through Dynamic Time Warping (DTW) and Detrended Cross-Correlation Analysis (DCCA), where the keywords top in the most critical days are believed the most relevant to the pandemic. We then categorize the ranking lists of keywords according to the specific regions of the search, such as Wuhan, Mainland China, the USA, and the whole world. Through the analysis on search, we succeed in identifying COVID-19 related collective response  would not be earlier than the end of 2019 in Mainland China. Finally, we confirm this observation again using human mobility data, where we specifically compare the massive mobility traces, including the real-time population densities inside key hospitals and inter-city travels departing from/arriving in Wuhan, from 2018 to 2020. No significant changes have been witnessed before December, 2019.", "filename": "2020.10.14.20202531v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20202531 "}, {"title": "shinyCurves, a shiny web application to analyse multisource qPCR amplification data: a COVID 19 case study", "abstract": "Quantitative, reverse transcription polymerase chain reaction (qRT-PCR) has been the gold-standard tool for viral detection during the SARS-CoV-2 pandemic. However, the desperate rush for a quick diagnosis led the use of very different types of machines and proprietary software, leading to an unbearable complexity of data analysis with a limited parameter setup. Here, we present shinyCurves, a shiny web application created to analyse multisource qPCR amplification data from independent multi-plate format. Furthermore, our automated system allows the classification of the results as well as the plot of both amplification and melting curves. Altogether, our web application is an automated qPCR analysis resource available to the research community.", "filename": "2020.10.14.20212381v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212381 "}, {"title": "p-tau/A\u03b242 Ratio Associates with Cognitive Decline in Alzheimer's disease, Mild Cognitive Impairment, and Cognitively Unimpaired Older Adults", "abstract": "INTRODUCTION: The most well-studied biomarkers in AD are CSF amyloid beta-42 (A\u03b242), tau, p-tau, and the ratio p-tau/A\u03b242. The ratiometric measure of p-tau/A\u03b242 shows the best diagnostic accuracy, and correlates reliably with metrics of cognition in unimpaired participants. However, no study has examined the impact of the CSF p-tau/A\u03b242 ratio in predicting cognitive decline in both healthy and AD individuals in one sample. The goal of this study was to examine whether CSF-based p-tau/A\u03b242 predicts changes in global cognitive functioning, episodic memory, and executive functioning over a two-year period in cognitively impaired older adults (CU), and in individuals with Mild Cognitive Impairment (MCI) and Alzheimer\u2032s disease (AD).\n\nMETHODS: This study involves secondary analysis of data from 1215 older adults available in the Alzheimer\u2032s Disease Neuroimaging Initiative (ADNI). Neuropsychological variables, collected at baseline, 6-month, 12-month, and 24-month follow-ups, included the Preclinical Alzheimer\u2032s Cognitive Composite (PACC) to assess global cognitive functioning, ADNI-MEM to assess episodic memory functioning, and ADNI-EF to assess executive functioning. Linear mixed models were constructed to examine the effect of CSF p-tau/A\u03b242, diagnostic group, and change over time (baseline, 6-month, 12-month, and 24-month) on cognitive scores.\n\nRESULTS: CSF p-tau/A\u03b242 ratios predicted worsening cognitive impairment, both on global cognition and episodic memory in individuals with MCI and AD, but not in CU older adults and predicted decline in executive functioning for all three diagnostic groups.\n\nDISCUSSION: Our study, including CU, MCI, and AD individuals, provides evidence for differential cognitive consequences of accumulated AD pathology based on diagnostic groups.", "filename": "2020.10.13.20211375v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211375 "}, {"title": "Peto odds ratios demonstrate no advantage over classic odds ratios in meta-analysis of binary rare outcomes", "abstract": "In this study, we examined the discrepancy between large studies and small studies in meta-analyses of rare event outcomes and the impact of Peto versus the classic odds ratios (ORs) through empirical data from the Cochrane Database of Systematic Reviews that collected from January 2003 to May 2018. Meta-analyses of binary outcomes with rare events (event rate <=5%), with at least 5 studies, and with at least one large study (N>=1000) were extracted. The Peto and classic ORs were used as the effect sizes in the meta-analyses, and the magnitude and direction of the ORs of the meta-analyses of large studies versus small studies were compared. The p-values of the meta-analyses of small studies were examined to assess if the Peto and the classic OR methods gave similar results. Totally, 214 meta-analyses were included. Over the total 214 pairs of pooled ORs of large studies versus pooled small studies, 66 (30.84%) had a discordant direction (kappa=0.33) when measured by Peto OR and 69 (32.24%) had a discordant direction (kappa=0.22) when measured by classic OR. The Peto ORs resulted in smaller p-values compared to classic ORs in a substantial (83.18%) number of cases. In conclusion, there is considerable discrepancy between large studies and small studies among the results of meta-analyses of sparse data. The use of Peto odds ratios does not improve this situation and is not recommended as it may result in less conservative error estimation.", "filename": "2020.10.13.20212290v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212290 "}, {"title": "m6A RNA methylation regulators contribute to progression and impact the prognosis of breast cancer", "abstract": "N6-methyladenosine (m6A) is the most commonly modified form of mRNA. M6A RNA methylation regulators are proved to be expressed clearly in some cancers by plenty of studies. Moreover, they also are proved to be indirectly involved in the growth of cancers. However, it remains unclear that the role of m6A RNA methylation regulator in the prognosis of breast cancer (BRCA). The data that we used in this study is the mRNA expression data obtained from the corresponding clinical information and the Tumor Genome Atlas (TCGA) database. And the goal we used the Wilcoxon rank-sum test was to evaluate the difference in the expression of m6A RNA methylation regulators in the normal group and the tumor group, and analyze the correlation between m6A RNA methylation regulators. We identified two subgroups of BRCA (cluster1 and 2) by using the K-mean algorithm and analyzing the correlation between clinic information and subgroups. The LASSO regression model then was used to figure out three m6A RNA methylation regulators, namely YTHDF3, ZC3H13, and HNRNPC. The riskScore of each patient was calculated according to the regression coefficients of the three m6A RNA methylation regulators. Base on the riskScore, we divided the patients into two groups, the high-risk group, and the low-risk group. After analyzing, we found that the overall survival rate (OS) of the low-risk group was higher than that of the other group. We conducted a univariate and multi-factor independent prognostic analysis of riskScore and three m6A RNA methylation regulators, and found that riskScore has a significant correlation with BRCA. In conclusion, the m6A RNA methylation regulator is closely related to the development of BRCA, and the prognostic factor riskScore obtained from the regression of the expression of the three m6A RNA methylation regulators in the human body are likely to guide the individualization of BRCA patients A useful prognostic biomarker for treatment.", "filename": "2020.10.13.20212332v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212332 "}, {"title": "Polybrominated diphenyl ether serum concentrations and depressive symptomatology in pregnant African American women.", "abstract": "Background: Polybrominated diphenyl ethers (PBDEs) are lipophilic, persistent endocrine disrupting chemicals often used as flame retardants in products that were widely produced in the United States until 2004. The potential for environmental toxicants such as PBDEs to disrupt normal neuroendocrine pathways resulting in depression and other neurological symptoms has been largely understudied. This study examined whether PBDE exposure in pregnant women was associated with antenatal depressive symptomatology.\nMethods: This study is part of a larger longitudinal pregnancy and birth cohort study. Data were collected from 193 African American pregnant women at 8-14 weeks gestation. Serum PBDEs were analyzed using gas chromatography-tandem mass spectrometry. The Edinburgh Depression Scale (EDS) was used to identify depressive symptoms experienced in the last seven days prior to biosampling. The dichotomous depression variable was used to explore varying high-risk EDS cutoffs and illustrated with receiver operating characteristic curves. Logistic regression models were constructed to investigate associations with antenatal depression and a weighted quantile sum (WQS) index was calculated to account for the mixture of PBDE congeners.\nResults: Of the total sample, 52 women (26.9%) were categorized as having a high risk of depression. PBDE congeners -47, -99, and -100 were detected in 50% or more of the samples tested. BDE-47 was positively associated with depressive symptoms (\u03b2 =2.36, p=0.05). The risk of being mild to moderately depressed increased by a factor of 4.52 for BDE-47 (CI 1.50, 13.60) and 1.58 for BDE-99 (CI 1.08, 2.29). The WQS index, a weighted estimate of the body burden of the congener mixture was positively associated with a higher risk of mild to moderate depression using an EDS cutoff \u226510 (OR=2.93; CI 1.18, 7.82).\nConclusion: BDE-47 and -99 exposures are significantly associated with depressive symptomatology in a pregnant cohort. These exposures will likely continue for years due to slow chemical degradation. Interventions should focus on PBDE mitigation to reduce toxic neuroendocrine effects on vulnerable pregnant women.", "filename": "2020.10.13.20212316v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212316 "}, {"title": "Understanding the value of clinical symptoms of COVID-19. A logistic regression model", "abstract": "Background\nThe new coronavirus SARS-CoV-2, the causative agent of COVID-19, is responsible for the current pandemic outbreak worldwide. However, there is limited information regarding the set of specific symptoms of COVID-19. Therefore, the objective of this study was to describe the main symptoms associated with COVID-19 to aid in the clinical diagnosis for the rapid identification of cases.\nMethods and findings\nA cross sectional study of all those diagnosed by RT-PCR for SARS-CoV-2 between April 1 and May 24 in Argentina was conducted. The data includes clinical and demographic information from all subjects at the time of presentation, which were uploaded to the centralized national reporting system at health centers. A total of 67318 individuals were included in this study, where 12% tested positive for SARS-CoV-2. The study population was divided in two age groups, a group aged 0 to 55 years-old (<56 group), (median = 32, n=48748) and another group aged 56 to 103 years-old (\u226556 group) (median =72, n=18570). A cross sectional study of all those diagnosed by RT-PCR for SARS-CoV-2 between April 1 and May 24 in Argentina was conducted. The data includes clinical and demographic information from all subjects at the time of presentation, which were uploaded to the centralized national reporting system at health centers.Multivariate logistic regression analyses showed that out of a total of 23 symptoms, only five were found to have a positive association with COVID-19: anosmia (odds ratio [OR] 10.40, 95% confidence interval [CI] 8.20-13.10, <56 group; OR 6.09 CI 3.05-12.20, \u226556 group), dysgeusia (OR 3.67, CI 2.7-4.9, <56 group; OR 3.53 CI 1.52-8.18, \u226556 group), low grade fever (37.5-37.9 \u00b0C) (OR 1.61, CI 1.20-2.05, <56 group; OR 1.80 CI 1.07-3.06, \u226556 group), cough (OR 1.20, CI 1.05-1.38, <56 group; OR 1.37 CI 1.04-1.80, \u226556 group) and headache only in <56 group (OR 1.71, CI 1.48-1.99). In turn, at the time of presentation, the symptoms associated with respiratory problems: chest pain, tachypnea, dyspnea, respiratory failure and use of accessory muscles for breathing, had a negative association with COVID-19 (OR <1) or did not present statistical relevance (OR = 1).\nWith the intention of helping the clinical diagnosis, we designed a model to be able to identify possible cases of COVID-19. This model included 16 symptoms, the age and sex of the individuals, and was able to detect 80% of those infected with SARS-CoV-2 with a specificity of 46%.\nConclusions\nThe analysis of symptoms opens the opportunity for a guidance and improved symptoms based definition of suspected cases of COVID-19, where multiple factors (age, sex, symptoms and interaction between symptoms) are considered. We present a tool to help identify COVID-19 cases to provide quick information to aid decision-making by health personnel and program managers.", "filename": "2020.10.07.20207019v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207019 "}, {"title": "Recovery of monocyte exhaustion is associated with resolution of lung injury in COVID-19 convalescence.", "abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection resulting in the clinical syndrome COVID-19 is associated with an exaggerated immune response and monocyte infiltrates in the lungs and other peripheral tissues. It is now increasingly recognised that chronic morbidity persists in some patients. We recently demonstrated profound alterations of monocytes in hospitalised COVID-19 patients. It is currently unclear whether these abnormalities resolve or progress following patient discharge. We show here that blood monocytes in convalescent patients at their 12 week follow up, have a greater propensity to produce pro-inflammatory cytokines TNF\u03b1 and IL-6, which was consistently higher in patients with resolution of lung injury as indicated by a normal chest X-ray and no shortness of breath (a key symptom of lung injury). Furthermore, monocytes from convalescent patients also displayed enhanced levels of molecules involved in leucocyte migration, including chemokine receptor CXCR6, adhesion molecule CD31/PECAM and integrins VLA-4 and LFA-1. Expression of migration molecules on monocytes was also consistently higher in convalescent patients with a normal chest X-ray. These data suggest persistent changes in innate immune function following recovery from COVID-19 and indicate that immune modulating therapies targeting monocytes and leucocyte migration may be useful in recovering COVID-19 patients with persistent symptoms.", "filename": "2020.10.10.20207449v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20207449 "}, {"title": "sMAdCAM:IL-6 (sMIL Index): A novel signature associated with COVID-19 disease progression and development of anti-SARS-CoV-2 antibodies", "abstract": "IMPORTANCE: Recent studies positing the gut as a sanctuary site for viral persistence in SARS-CoV-2 infection highlight the importance of assimilating profiles of systemic as well as gut inflammatory mediators to understand the pathology of COVID-19. Also, the role of these markers in governing virus specific immunity following infection remains largely unexplored.\nOBJECTIVE: To evaluate the role of systemic and gut inflammatory markers in disease progression and development of anti-viral humoral immunity following SARS-CoV-2 infection.\nDESIGN, SETTING AND PARTICIPANTS: This cohort study (n=58) of SARS-CoV-2 infected individuals included a group of in-patients (n=36) at various stages of disease progression together with convalescent individuals (n=22) recruited between April and June 2020 (peak of the epidemic) from a tertiary care hospital in Mumbai, India. Follow-up of 11 in-patients at day 7 post diagnosis was carried out, resulting in a total of 47 in-patient samples.\nEXPOSURES: Diagnosis of SARS-CoV-2 infections was confirmed by reverse transcriptase-polymerase chain reaction-based testing of nasopharyngeal/oropharyngeal samples.\nMAIN OUTCOMES AND MEASURES: Primary outcomes were the measurement of inflammatory markers including Th1/Th2/Th17 cytokines and levels of soluble mucosal addressin cell adhesion molecule (sMAdCAM) in plasma. Anti-viral humoral response was measured by rapid antibody test (IgG, IgM) and chemiluminescent immunoassay (CLIA) (IgG). Also antibodies binding to SARS-CoV-2 proteins were measured by surface plasmon resonance (SPR). Secondary outcomes were correlation of the inflammatory signature with clinical information, including age, sex, disease duration and co-morbidities. \nRESULTS: Twenty eight of 36 (78%) in-patients and 19 of 22 (86%) convalescents were males. Out of 47 in-patient samples, 22 (46%), 11 (23%) and 14 (30%) were IgG-/IgM-, IgG+/IgM+ and IgG+/IgM- respectively. Of 22 convalescent samples, 3 (14%), 1 (4%) and 17 (77%) were respectively IgG-/IgM-, IgG+/IgM+ and IgG+/IgM-. Two out of 22 (9%) convalescents showed high IL-6 levels (>100pg/ml) and 4 (18%) had high TNF levels (>30pg/ml). However, the convalescents (n =22) had significantly lower levels of IL-6 [Median=27.48 (IQR=23.54-39.92)]  compared to followed up in-patients (n = 11) at day 0 [Median=111(IQR=68-129.7), p =0.0002] and higher levels of sMAdCAM [Median=1940 (1711-2174) pg/ml] compared to these individuals at day 0 [Median=1701 (IQR=1532-1836) pg/ml; p=0.032]  and day 7 [Median=1534 (IQR=1236-1654) pg/ml; p=0.0007]. Further, IL-6 and sMAdCAM levels among in-patients inversely correlated with one another (r =-0.374, p = 0.009, CI = 95%). When expressed as a novel integrated marker, sMIL (sMAdCAM/IL-6 ratio) index, these levels were incrementally and significantly higher across various disease states with convalescents exhibiting the highest values [Median= 64.74 (IQR=47.33-85.58)].  Also, the sMIL index was significantly higher in convalescents (with class-switched responses) compared to IgG+/IgM+ individuals at early stages of infection [Median=28.65 (IQR=13.63-96.26), p = 0.034]. Real-time measurement by SPR of plasma antibody binding to viral nucleocapsid (NC), receptor binding domain (RBD) and spike (S) revealed waxing and waning of plasma antibody responses to all 3 targets. Importantly, sMAdCAM levels as well as sMIL index (fold change) correlated with peak association rates of RBD-binding (r = 0.462, p = 0.03, CI = 95%) and fold change in binding to S (r = 0.68, p = 0.050, CI = 95%) respectively.\nCONCLUSION AND RELEVANCE: Our results highlight key systemic and gut-associated immune parameters that need to be monitored and investigated further to optimally guide therapeutic and prophylactic interventions for COVID-19.", "filename": "2020.10.13.20182949v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20182949 "}, {"title": "Quantitative assessment on the severity degree of Alzheimer dementia by algebraic analysis on cortical thickness profiles of human brains", "abstract": "Alzheimer disease (AD) affects profoundly the quality of human life. Quantifying the severity degree of Alzheimer dementia for an individual person is critical for the early diagnose and prescription for delaying the further dementia progression. However, the quantitative diagnose for human subjects of the mild cognitively impairment (MCI) or AD with the different degree of dementia severity is a difficult task due to both the very broad distribution of dementia severities and the lack of good quantitative determinant to assess it. Here, based on cortical thickness profiles of human brains measured by magnetic resonance experiment, a new algebraic approach is presented for the personalized quantification of the severity degree of AD, ranging from 0 for the basin of cognitively normal state to 1 for AD state. Now one can unfold the broad distribution of dementia severities and corresponding cortex regions of human brains with MCI or AD by the different severity degree.", "filename": "2020.10.13.20212324v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212324 "}, {"title": "Early stopping in clinical PET studies: how to reduce expense and exposure", "abstract": "Clinical positron emission tomography (PET) research is costly and entails exposing participants to radioactivity. Researchers should therefor aim to include just the number of subjects needed to fulfill the purpose of the study, no more, no less. In this tutorial we show how to apply sequential Bayes Factor testing in order to stop the recruitment of subjects in a clinical PET study as soon as enough data have been collected to make a conclusion. We evaluate this framework in two common PET study designs: a cross-sectional (e.g., patient-control comparison) and a paired-sample design (e.g., pre-intervention-post scan comparison). By using simulations, we show that it is possible to stop a clinical PET study early, both when there is an effect and when there is no effect, while keeping the number of erroneous conclusions at acceptable levels. Based on the results we recommend settings for a sequential design that are appropriate for commonly seen sample sizes in clinical PET-studies. Finally, we apply sequential Bayes Factor testing to a real PET data set and show that it is possible to obtain support in favor of an effect while simultaneously reducing the sample size with 30%. Using this procedure allows researchers to reduce expense and radioactivity exposure for a range of effect sizes relevant for PET research.", "filename": "2020.09.13.20192856v2", "doi": "doi: https://doi.org/10.1101/2020.09.13.20192856 "}, {"title": "School closures and SARS-CoV-2. Evidence from Sweden's partial school closure", "abstract": "To reduce the transmission of SARS-CoV-2 most countries closed schools, despite uncertainty if school closures are an effective containment measure. At the onset of the pandemic, Swedish upper secondary schools moved to online instruction while lower secondary school remained open. This allows for a comparison of parents and teachers differently exposed to open and closed schools, but otherwise facing similar conditions. Leveraging rich Swedish register data, we connect all students and teachers in Sweden to their families and study the impact of moving to online instruction on the incidence of SARS-CoV-2 and COVID-19. We find that among parents, exposure to open rather than closed schools resulted in a small increase in PCR-confirmed infections [OR 1.15; CI95 1.03-1.27]. Among lower secondary teachers the infection rate doubled relative to upper secondary teachers [OR 2.01; CI95 1.52-2.67]. This spilled over to the partners of lower secondary teachers who had a higher infection rate than their upper secondary counterparts [OR 1.30; CI95 1.00-1.68]. When analyzing COVID-19 diagnoses from healthcare visits and the incidence of severe health outcomes, results are similar for teachers but somewhat weaker for parents and teachers' partners. The results for parents indicate that keeping lower secondary schools open had minor consequences for the transmission of SARS-CoV-2 in society. The results for teachers suggest that measures to protect teachers could be considered.", "filename": "2020.10.13.20211359v2", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211359 "}, {"title": "Modeling the Spread and Control of COVID-19", "abstract": "Data-centric models of COVID-19 have been tried, but have certain limitations.  In this work, we propose an agent-based model of the epidemic in a confined space of agents representing humans.  An extension to the SEIR model allows us to consider the difference between the appearance (black-box view) of the spread of disease, andthe real situation (glass-box view).  Our model allows for simulations of lockdowns, social distancing, personal hygiene, quarantine, and hospitalization, with further considerations of different parameters such as the extent to which hygiene and social distancing are observed in a population.  Our results give qualitative indications of the effects of various policies and parameters; for instance, that lockdowns by themselves are extremely unlikely to bring an end to an epidemic and may indeed make things worse, that social distancing matters more than personal hygiene, and that the growth of infection comes down significantly for moderately high levels of social distancing and hygiene, even in the absence of herd immunity.", "filename": "2020.09.16.20195826v2", "doi": "doi: https://doi.org/10.1101/2020.09.16.20195826 "}, {"title": "Awareness-driven Behavior Changes Can Shift the Shape of Epidemics Away from Peaks and Towards Plateaus, Shoulders, and Oscillations", "abstract": "The COVID-19 pandemic has caused more than 1,000,000 reported deaths globally, of which more than 200,000 have been reported in the United States as of October 1, 2020. Public health interventions have had significant impacts in reducing transmission and in averting even more deaths. Nonetheless, in many jurisdictions the decline of cases and fatalities after apparent epidemic peaks has not been rapid. Instead, the asymmetric decline in cases appears, in most cases, to be consistent with plateau- or shoulder-like phenomena - a qualitative observation reinforced by a symmetry analysis of US state-level fatality data. Here we explore a model of fatality-driven awareness in which individual protective measures increase with death rates. In this model, fast increases to the peak are often followed by plateaus, shoulders, and lag-driven oscillations. The asymmetric shape of model-predicted incidence and fatality curves are consistent with observations from many jurisdictions. Yet, in contrast to model predictions, we find that population-level mobility metrics usually increased from low early-outbreak levels before peak levels of fatalities. We show that incorporating fatigue and long-term behavior change can reconcile the apparent premature relaxation of mobility reductions and help understand when post-peak dynamics are likely to lead to a resurgence of cases.", "filename": "2020.05.03.20089524v3", "doi": "doi: https://doi.org/10.1101/2020.05.03.20089524 "}, {"title": "COVID-19 Aerosolized Viral Loads, Environment, Ventilation, Masks, Exposure Time, Severity, And Immune Response: A Pragmatic Guide Of Estimates", "abstract": "This study helps answer the question \"How long may a person safely remain within a given environment and what is the associated risk relative to other environments\". Understanding how COVID-19 infection likelihood, symptom severity, and immune response correlate to aerosolized viral load concentration exposure levels and time durations could enable optimized Non-Pharmaceutical Interventions (NPI) that reduce severe case counts and improve at-large epidemiologic responses. The model herein estimates the relationships between aerosolized viral load concentrations present in a given environment containing infected persons, the exposure time duration, ventilation, mask usage, exercise / activity level, and likelihood of infection, severity level, and immune response. This study references peer reviewed and published studies and uses them as data sources. Measured aerosolized viral load concentration data from a hospital environment is used to estimate exposure time durations associated with exposures at multiple viral load levels, within multiple indoor ventilation and outdoor environment scenarios, with the exposed subject respirating at both light activity and heavy exercise liter-per-minute volumes, and without and without wearing surgical masks. Information from ASHRAE Office Ventilation standards and an Outdoor Air Exchange model are a part of the model. This estimated total viral load accumulated within specific exposure time durations in the various environmental scenarios is then interpreted using human challenge viral load escalation data into severity categories including Not Ill, Minor Illness, Clinical Mild Illness, and Possible Severe Illness. Immune response data related to these categories is also provided. When appropriately interpreted for individualized applications, the estimates herein could contribute to guidance for those at low-risk for a severe case that have no obvious COVID-19 co-morbidities, with the understanding that those at higher risk should seek to avoid all exposure risk. The estimates herein may help efforts to strike a balance in developing holistic epidemiologic interventions that consider the effects of these interventions on economic, civic, social, and mental health, which have pathologies within their own realms.", "filename": "2020.10.03.20206110v3", "doi": "doi: https://doi.org/10.1101/2020.10.03.20206110 "}, {"title": "Effect of APOE and a polygenic risk score on incident dementia and cognitive decline in a healthy older population", "abstract": "Importance: Few studies have measured the effect of genetic factors on dementia and cognitive decline in a population of healthy older individuals followed prospectively.\nObjective: To examine the effect of Apolipoprotein E (APOE) genotypes and a polygenic risk score (PRS) on incident dementia and cognitive decline in a longitudinal cohort of healthy older people.\nDesign, Setting and Participants: Post-hoc genetic analysis of a randomized clinical trial population - the ASPirin in Reducing Events in the Elderly (ASPREE) trial. At enrollment, participants had no history of diagnosed dementia, atherothrombotic cardiovascular disease, or permanent physical disability and were without cognitive impairment. \nMain Outcomes and Measures: Dementia (adjudicated trial endpoint) and cognitive decline, defined as a >1.5 standard deviation decline in test score for either global cognition, episodic memory, language/executive function or psychomotor speed, versus baseline scores. Cumulative incidence curves for all-cause dementia and cognitive decline were calculated with mortality as a competing event, stratified by APOE genotypes and tertiles of a PRS based on 23 common non-APOE variants.\nResults: 12,978 participants with European ancestry were included; 54.8% were female, and average age at baseline was 75 years (range 70 to 96). During a median 4.5 years of follow-up, 324 (2.5%) participants developed dementia and 503 (3.8%) died. Cumulative incidence of dementia to age 85 years was estimated to be 7.4% in all participants, 12.6% in APOE \u03b54 heterozygotes, 26.6% in \u03b54 homozygotes, 9.6% in the high PRS tertile, and 7.3% in the low PRS tertile. APOE \u03b54 heterozygosity/homozygosity was associated with a 2.5/6.3-fold increased risk of dementia and a 1.4/1.8-fold increased risk of cognitive decline, versus \u03b53/\u03b53 (P<0.001 for both). A high PRS (top tertile) was associated with a 1.4-fold increase risk of dementia, versus the low tertile (CI 1.04-1.76, P=0.02), but was not associated with cognitive decline risk (CI 0.96-1.22, P = 0.18). \nConclusions and Relevance: Incidence of dementia among healthy older individuals is low across all genotypes; however, APOE \u03b54 and high PRS increase relative risk. APOE \u03b54 is associated with cognitive decline, but PRS is not", "filename": "2020.10.11.20210963v2", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210963 "}, {"title": "Repurposed antiviral drugs for COVID-19; interim WHO SOLIDARITY trial results", "abstract": "BACKGROUND\nWHO expert groups recommended mortality trials in hospitalized COVID-19 of four re-purposed antiviral drugs. \nMETHODS\nStudy drugs were Remdesivir, Hydroxychloroquine, Lopinavir (fixed-dose combination with Ritonavir) and Interferon-\u03b21a (mainly subcutaneous; initially with Lopinavir, later not). COVID-19 inpatients were randomized equally between whichever study drugs were locally available and open control (up to 5 options: 4 active and local standard-of-care). The intent-to-treat primary analyses are of in-hospital mortality in the 4 pairwise comparisons of each study drug vs its controls (concurrently allocated the same management without that drug, despite availability). Kaplan-Meier 28-day risks are unstratified; log-rank death rate ratios (RRs) are stratified for age and ventilation at entry.\nRESULTS\nIn 405 hospitals in 30 countries 11,266 adults were randomized, with 2750 allocated Remdesivir, 954 Hydroxychloroquine, 1411 Lopinavir, 651 Interferon plus Lopinavir, 1412 only Interferon, and 4088 no study drug. Compliance was 94-96% midway through treatment, with 2-6% crossover. 1253 deaths were reported (at median day 8, IQR 4-14). Kaplan-Meier 28-day mortality was 12% (39% if already ventilated at randomization, 10% otherwise). Death rate ratios (with 95% CIs and numbers dead/randomized, each drug vs its control) were: Remdesivir RR=0.95 (0.81-1.11, p=0.50; 301/2743 active vs 303/2708 control), Hydroxychloroquine RR=1.19 (0.89-1.59, p=0.23; 104/947 vs 84/906), Lopinavir RR=1.00 (0.79-1.25, p=0.97; 148/1399 vs 146/1372) and Interferon RR=1.16 (0.96-1.39, p=0.11; 243/2050 vs 216/2050). No study drug definitely reduced mortality (in unventilated patients or any other subgroup of entry characteristics), initiation of ventilation or hospitalisation duration.\nCONCLUSIONS \nThese Remdesivir, Hydroxychloroquine, Lopinavir and Interferon regimens appeared to have little or no effect on hospitalized COVID-19, as indicated by overall mortality, initiation of ventilation and duration of hospital stay. The mortality findings contain most of the randomized evidence on Remdesivir and Interferon, and are consistent with meta-analyses of mortality in all major trials. (Funding: WHO. Registration: ISRCTN83971151,  NCT04315948)", "filename": "2020.10.15.20209817v1", "doi": "doi: https://doi.org/10.1101/2020.10.15.20209817 "}, {"title": "Predictions for Europe for the Covid-19 pandemic from a SIR model", "abstract": "Understanding the characteristics of the SARS-Cov-2/Covid-19 pandemic is central to developing control strategies. Here we show how a simple Susceptible-Infective-Recovered (SIR) model applied to data for eight European countries and the United Kingdom (UK) can be used to forecast the descending limb (post-peak) of confirmed cases and deaths as a function of time, and predict the duration of the pandemic once it has peaked, by estimating and fixing parameters using only characteristics of the ascending limb and the magnitude of the first peak. As with all epidemiological analyses, unanticipated behavioral changes will result in deviations between projection and observation. This is abundantly clear for the current pandemic.  Nonetheless, accurate short-term projections are possible, and the methodology we present is a useful addition to the epidemiologist's armamentarium. Since our predictions assume that control measures such as lockdown, social distancing, use of masks etc. remain the same post-peak as before peak, deviations from our predictions are a measure of the extent to which loosening of control measures have impacted case-loads and deaths since the first peak and initial decline in daily cases and deaths. The predicted and actual case fatality ratio,  or number of deaths per million population from the start of the pandemic to when daily deaths number less than five for the first time, was lowest in Norway (pred: 44 +/- 5 deaths/million; actual: 36 deaths/million) and highest for the United Kingdom (pred: 578 +/- 65 deaths/million; actual 621 deaths/million). The inferred pandemic characteristics separated into two distinct groups: those that are largely invariant across countries, and those that are highly variable. Among the former is the infective period, T_L, (Average T_L = 16.3 +/- 2.7 days); the average time between contacts, T_R (Average T_R = 3.8 +/- 0.5) days  and the average number of contacts while infective , R  (Average R=  4.4 +/- 0.5). In contrast, there is a highly variable time lag T_D between the peak in the daily number of confirmed cases and the peak in the daily number of deaths, ranging from a low of T_D= 2,4 days for Denmark and Italy respectively, to highs of T_D= 12, 15 for Germany and Norway respectively. The mortality fraction, or ratio of deaths to confirmed cases, was also highly variable, ranging from low values 3%, 5% and 5% for Norway, Denmark and Germany respectively, to high values of 18%, 20% and 21% for Sweden, France, and the UK respectively.  The probability of mortality rather than recovery was a significant correlate of the duration of the pandemic, defined as the time from 12/31/2019 to when the number of daily deaths fell below 5. Finally, we observed a small but detectable effect of average temperature on the probability \u03b1 of infection per contact, with higher temperatures associated with lower infectivity.  Policy implications of our findings are also briefly discussed.", "filename": "2020.05.26.20114058v3", "doi": "doi: https://doi.org/10.1101/2020.05.26.20114058 "}, {"title": "Reductions in 2020 US life expectancy due to COVID-19 and the disproportionate impact on the Black and Latino populations", "abstract": "COVID-19 has resulted in a staggering death toll in the US: over 215,000 by mid-October 2020, according to the Centers for Disease Control and Prevention. Black and Latino Americans have experienced a disproportionate burden of COVID-19 morbidity and mortality, reflecting persistent structural inequalities that increase risk of exposure to COVID-19 and mortality risk for those infected. We estimate life expectancy at birth and at age 65 for 2020, for the total US population and by race and ethnicity, using four scenarios of deaths - one in which the COVID-19 pandemic had not occurred and three including COVID-19 mortality projections produced by the Institute for Health Metrics and Evaluation. Our medium estimate indicates a reduction in US life expectancy at birth of 1.13 years to 77.48 years, lower than any year since 2003. We also project a 0.87-year reduction in life expectancy at age 65. The Black and Latino populations are estimated to experience declines in life expectancy at birth of 2.10 and 3.05 years, respectively, both of which are several times the 0.68-year reduction for whites. These projections imply an increase of nearly 40% in the Black-white life expectancy gap, from 3.6 to over five years, thereby eliminating progress made in reducing this differential since 2006. Latinos, who have consistently experienced lower mortality than whites (a phenomenon known as the Latino or Hispanic paradox), would see their more than three-year survival advantage reduced to less than one year.", "filename": "2020.07.12.20148387v3", "doi": "doi: https://doi.org/10.1101/2020.07.12.20148387 "}, {"title": "A delayed SEIQR epidemic model of COVID-19 in Tokyo area", "abstract": "The infection of COVID-19 has caused a global pandemic. In order to avoid excessive restriction to the social activity, a good strategy of quarantine based on a realistic model is expected. Several epidemic models with a quarantine compartment such as susceptible-exposed-infectious-quarantined-recovered (SEIQR) model have been applied. However, in the actual situation, the infection test and quarantine is often delayed from the beginning of the infectious stage. \n  This article presents a delayed SEIQR model to analyze the effect of the delay of quarantine. The latency period (compartment E) and the incubation period were assumed to be 3 days and 5 days, respectively. Considering that the presymptomatic infection ratio is 0.4, the natural decay rate of the number of infectious patients was assumed to be 0.25 days-1. The recovery rate was assumed to be 0.07 days-1 from the typical PCR test positive period. The PCR test positive number in the period from March 10 to July 18 in 2020 in Tokyo area was analyzed. The delay time distribution of the quarantine was derived from the record of the symptom onset date, and was utilized to determine the delay time profile of quarantine in the model.\n  It was found that the major contributor to the infection control was the restraint of social contact. However, the quarantine action also contributed to reducing the reproduction number by the ratio of 0.88 and 0.8 in the period from March 10 to June 3 and from June 4 to July 18, respectively. The delay of quarantine was found to be well correlated to the effectiveness of quarantine. Therefore a record on a symptom onset date is very important to estimate the effect of quarantine measure. The basic reproduction number was estimated to be 2.56. In view of the presymptomatic infection ratio 0.4, it would be very hard to restrain the expansion of infection only by quarantining the symptomatic patients.", "filename": "2020.08.18.20177709v4", "doi": "doi: https://doi.org/10.1101/2020.08.18.20177709 "}, {"title": "INFERRED RESOLUTION THROUGH HERD IMMMUNITY OF FIRST COVID-19 WAVE IN MANAUS, BRAZILIAN AMAZON", "abstract": "Background\n\nAs in many other settings, peak excess mortality preceded the officially reported 'first wave' peak of the COVID-19 epidemic in Manaus, Brazil, reflecting delayed case recognition and limited initial access to diagnostic testing. \n\nMethods and Findings\n\nTo avoid early information bias, we used detailed age and gender stratified death certificate and hospitalisation data to evaluate the epidemic's trajectory and infer the cause of its decline using a stochastic model. Our results are consistent with heterogenous transmission reducing from mid-April 2020 due to the development of herd immunity. Relative to a baseline model that assumed homogenous mixing across Manaus, a model that permitted a self-isolated population fraction reduced the population-wide attack rate required to drop the effective reproduction number below one from 62% to 47%, and reduced the final attack rate from 86% to 65%. In the latter scenario, a substantial proportion of vulnerable, older individuals remained susceptible to infection.\n\nConclusions\n\nOur models indicate that the development of herd immunity amongst the mixing proportion of the Manaus population had effectively halted the COVID-19 epidemic by late July 2020. Given uncertainties regarding the distancing behaviours of population subgroups with different social and economic characteristics, and the duration of sterilising or transmission-modifying immunity in exposed individuals, we conclude that the potential for epidemic outbreaks remains, but that future waves of infection are likely to be much less pronounced than that already experienced.", "filename": "2020.09.25.20201939v3", "doi": "doi: https://doi.org/10.1101/2020.09.25.20201939 "}, {"title": "SCOAT-Net: A Novel Network for Segmenting COVID-19 Lung Opacification from CT Images", "abstract": "Coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has spread worldwide at a rapid rate. As of yet, there is no clinically automated tool to quantify the infection of COVID-19 patients, which is of great significance for judging the disease development and treatment response of patients. Automatic segmentation of lung opacification from computed tomography (CT) images shows excellent potential for this purpose but still faces some challenges, including the complexity and variability features of the opacity regions, the small difference between the infected and healthy tissues, and the noise of CT images. However, due to limited medical resources, it is impractical to obtain a large amount of data in a short time, which further hinders the training of deep learning models. To answer these challenges, we proposed a novel spatial- and channel-wise coarse-to-fine attention network (SCOAT-Net), inspired by the biological vision mechanism, for the segmentation of COVID-19 lung opacification from CT images. SCOAT-Net has a spatial-wise attention module and a channel-wise attention module to attract the self-attention learning of the network, which serves to extract the practical features at the pixel and channel level successfully. Experiments show that our proposed SCOAT-Net achieves better results compared to state-of-the-art image segmentation networks.", "filename": "2020.09.23.20191726v2", "doi": "doi: https://doi.org/10.1101/2020.09.23.20191726 "}, {"title": "CN-105 in Participants with Acute SupraTentorial IntraCerebral Hemorrhage (CATCH) Trial", "abstract": "Background: Endogenous apoliloprotein E mediates neuroinflammatory responses and recovery after brain injury. Exogenously administered apolipoprotein E-mimetic peptides can effectively penetrate the brain and down-regulate acute inflammation. CN-105 is a novel apolipoprotein E-mimetic pentapeptide with excellent preclinical evidence as an acute intracerebral hemorrhage (ICH) therapeutic. The CN-105 in participants with Acute supraTentorial intraCerebral Hemorrhage (CATCH) trial is a first-in-disease-state, multi-center, open-label trial evaluating safety and feasability of CN-105 administration in patients with acute primary supratentorial ICH. \n\nMethods: Eligible patients were age 30-80 years, had confirmed primary supratentorial ICH, and able to intiate CN-105 administration (1.0 mg/kg every 6 hours for 72 hours) within 12 hours of symptom onset. A priori defined safety endpoints, including hematoma volume, pharmacokinetics, and 30-day neurological outcomes were analyzed. For comparisons, CATCH participants were matched 1:1 with a contemporary ICH cohort through random selection. Hematoma volumes determined from computed tomography images on Days 0, 1, 2, and 5 and ordinal modified Rankin Score at 30 days after ICH were compared. \n\nResults: In 39 participants enrolled across six study sites in the United States, adverse events occurred at expected rate without increase in hematoma expansion or neurological deterioration or significant serum accumulation. CN-105 treatment had an odds ratio (95% confidence interval) of 2.69 (1.31-5.51) for lower 30-day mRS, after adjustment for ICH Score, sex, and race/ethnicity, compared to matched contemporary cohort. \n\nConclusion: CN-105 administration represents an excellent translational candidate as an actue ICH therapeutic due to its safety, dosing feasibility, favorable pharmacokinetics, and evidence of improved neurological recovery.", "filename": "2020.10.13.20211417v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211417 "}, {"title": "Long-Term Exposure to Fine Particulate Matter, Lung Function and Cognitive Performance: A Prospective Dutch Cohort Study on the Underlying Routes", "abstract": "Background\n\nExposure to fine particulate matter and black carbon is related to cognitive impairment and poor lung function, but less is known about the routes taken by different types of air pollutants to affect cognition.\n\nObjectives\n\nWe tested two possible routes of fine particulate matter (PM2.5) and black carbon (BC) in impairing cognition, and evaluated their importance:  a direct route over the olfactory nerve or the blood stream, and an indirect route over the lung.\n\nMethods\n\nWe used longitudinal observational data for 31232 people aged 18+ from 2006 to 2015 from the Dutch Lifelines cohort study. By linking current and past home addresses to air pollution exposure data from ELAPSE, long-term average exposure (\u2264 ten years) to PM2.5 and BC was calculated. Lung function was assessed by spirometry and Global Initiative (GLI) z-scores of forced expiratory volume in 1s (FEV1) and forced vital capacity (FVC) were calculated. Cognitive performance was measured by cognitive processing time (CPT) assessed by the Cogstate Brief Battery. Linear structural equation modeling was performed to test the direct/indirect associations.\n\nResults\n\nHigher exposure to PM2.5 but not BC was directly related to higher CPT and thus slower cognitive processing speed [18.33 (\u00d710-3) SD above the mean (95% CI: 6.84, 29.81)]. The direct association of PM2.5 constituted more than 97% of the total effect. Mediation by lung function was low for PM2.5 with a mediated proportion of 1.78% (FEV1) and 2.62% (FVC), but higher for BC (28.49% and 46.22% respectively).\n \nDiscussion\n\nOur results emphasize the importance of the lung acting as a mediator in the relationship between both exposure to PM2.5 and BC, and cognitive performance. However, higher exposure to PM2.5 was mainly directly associated with worse cognitive performance, which emphasizes the health-relevance of fine particles due to their ability to reach vital organs directly.", "filename": "2020.10.14.20212506v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212506 "}, {"title": "The global burden of yellow fever", "abstract": "Background: Yellow fever (YF) is a viral haemorrhagic fever endemic in tropical regions of Africa and South America. Current intervention policies, namely the Eliminate Yellow fever Epidemics (EYE) strategy are actioned through vaccination. However, the stockpiles and production mean that vaccination can be in short supply. As such, intervention strategies need to be optimised; one of the tools for doing this is mathematical modelling.\nMethods: We fit a generalised linear model of YF reports to occurrence data available from 1987 to 2019 in Africa and South America and available serology survey data to estimate the force of infection across the continents. Then, using demographic and vaccination data, we examine the impact of interventions.\nFindings: We estimate that in 2018 there were approximately 51,000 (95%CrI [31,000 - 82,000]) deaths due to YF in Africa and South America. When we examine the impact of mass vaccination campaigns in Africa, these amount to approximately 10,000 (95%CrI [6,000 - 17,000]) deaths averted in 2018 due to mass\nvaccination activities in Africa; this corresponds to a 47% reduction (95%CrI [10% - 77%]).\nInterpretation: We find that the majority, 92% (95%CrI [89% - 95%]), of global burden occurs in Africa and that mass vaccination activities have significantly reduced the current deaths per year due to YF. This methodology allows us to evaluate the effectiveness of vaccination campaigns past, present and future and illustrates the need for continued vigilance and surveillance of YF.", "filename": "2020.10.14.20212472v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212472 "}, {"title": "Extended laboratory panel testing in the Emergency Department for risk-stratification of patients with COVID-19: a single centre retrospective service evaluation", "abstract": "Background \nThe role of specific blood tests to predict poor prognosis in patients admitted with infection from SARS-CoV2 virus remains uncertain. During the first wave of the global pandemic, an extended laboratory testing panel was integrated into the local pathway to guide triage and healthcare resource utilisation for emergency admissions. We conducted a retrospective service evaluation to determine the utility of extended tests (D-dimer, ferritin, high-sensitivity troponin I, lactate dehydrogenase, procalcitonin) compared to the core panel (full blood count, urea & electrolytes, liver function tests, C-reactive protein). \n\nMethods\nClinical outcomes for adult patients with laboratory-confirmed COVID-19 admitted between 17th March to 30st June 2020 were extracted, alongside costs estimates for individual tests. Prognostic performance was assessed using multivariable logistic regression analysis with 28-day mortality used as the primary endpoint, and a composite of 28-day intensive care escalation or mortality for secondary analysis. \n\nResults\nFrom 13,500 emergency attendances we identified 391 unique adults admitted with COVID-19. Of these, 113 died (29%) and 151 (39%) reached the composite endpoint. Core test variables adjusted for age, gender and index of deprivation had a prognostic AUC of 0.79 (95% Confidence Interval, CI: 0.67 to 0.91) for mortality and 0.70 (95% CI: 0.56 to 0.84) for the composite endpoint. Addition of extended test components did not improve upon this. \n\nConclusion\nOur findings suggest use of the extended laboratory testing panel to risk stratify community-acquired COVID-19-positive patients on admission adds limited prognostic value. We suggest laboratory requesting should be targeted to patients with specific clinical indications.", "filename": "2020.10.06.20205369v2", "doi": "doi: https://doi.org/10.1101/2020.10.06.20205369 "}, {"title": "Heterogeneity in transmissibility and shedding SARS-CoV-2 via droplets and aerosols", "abstract": "A growing number of studies provide insight into how SARS-CoV-2 spreads1-7. Yet, many factors that characterize its transmissibility remain unclear, including mechanistic correlates of overdispersion, viral kinetics, the extent to which respiratory droplets and aerosols carry viable virus and the infectiousness of asymptomatic, presymptomatic and pediatric cases7. Here, we developed a comprehensive dataset of respiratory viral loads (rVLs) via systematic review and investigated these factors using meta-analyses and modeling. By comparing cases of COVID-19, SARS and influenza A(H1N1)pdm09, we found that heterogeneity in rVL was associated with overdispersion and facilitated the distinctions in individual variation in infectiousness among these emergent diseases. For COVID-19, case heterogeneity was broad throughout the infectious period, although rVL tended to peak at 1 day from symptom onset (DFSO) and be elevated for 1-5 DFSO. While most cases presented minimal risk, highly infectious ones could spread SARS-CoV-2 by talking, singing or breathing, which shed virions at comparable rates via droplets and aerosols. Coughing shed considerable quantities of virions, predominantly via droplets, and greatly increased the contagiousness of many symptomatic cases relative to asymptomatic ones. Asymptomatic and symptomatic infections showed similar likelihoods of expelling aerosols with SARS-CoV-2, as did adult and pediatric cases. Children tended to be less contagious by droplet spread than adults based on tendencies of symptomatology rather than rVL. Our findings address longstanding questions on SARS-CoV-2 transmissibility and present pertinent considerations for disease control.", "filename": "2020.10.13.20212233v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212233 "}, {"title": "Innate immune cytokine profiling and biomarker identification for outcome in dengue patients", "abstract": "Biomarkers of progression to severe dengue are urgently required for effective patient management. Innate immune cells have been implicated in the enhancement of infection and cytokine storm associated with dengue severity. Using intracellular cytokine staining and flow cytometry, we observed significantly higher proportions of innate immune cells secreting inflammatory cytokines dominated by IFN-\u03b3 and TNF-\u03b1 at admission associated with good prognosis. Secondary dengue predisposed to severe outcomes.  In patients with severe dengue and those with liver impairment, early activation as well as efficient down-regulation of innate responses were compromised. IFN-\u03b3+CD56+CD3+ NKT cells and IL-6+ granulocytes served as novel biomarkers of progression to severity (composite AUC=0.85-0.9). Strong correlations among multiple cytokine-secreting innate cell subsets pointed to coordinated activation of the entire innate immune system by DENV.", "filename": "2020.10.14.20212001v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212001 "}, {"title": "Sociodemographic correlates of access to sanitary pads among college students in Lucknow during COVID 19 lockdown", "abstract": "Introduction\nSanitary napkin is an essential aspect of the Menstrual management materials for women and adolescent girls between menarche and menopause. Despite being an important issue concerning women and girls in the menstruating age group, access to menstrual hygiene products neglected during the COVID19 pandemic. Further, there is no evidence of the practice of menstrual hygiene products in Indian settings during this period. This paper investigates the prevalence of socio-demographic correlations of access to sanitary napkins among college students in Lucknow.\nMethods\nAn online retrospective cross-sectional survey was conducted in Lucknow in September 2020. In total, 1439 participants took part in the survey. After removing 55 participants, those quit the survey by clicking on the disagree button and 13 were not satisfying inclusion criteria. So the final samples were 1371, which were included in the analysis. Students of UG and PG currently studying in colleges in the Lucknow were eligible to participate. The data collection was anonymous. Responses were analysed using descriptive and bivariate logistic regression.\nResults\nIn this study, 1371 students were included, making a response rate of 96.2 percent. Nearly 12.5 percent of students reported about difficulty encountered during the lockdown. Muslims, Father education illiterate or upto12th, father occupation as farmer, monthly salary less than 25 thousand, residence as rural, and history of reusable clothes were more likely to face problems to access sanitary pads during the lockdown in Lucknow (P < .05). \nConclusions\nDuring COVID-19 lockdown, about 12.5 percent of girls were dependent on either locally available resources as absorbents during menstruation or paid more to access in Lucknow. Because of the lockdown, many people have lost their livelihood. More than ever, economically low-income families are reluctant to spend on sanitary pads, which is why few college girls were going back to their previous handling periods by using rags.", "filename": "2020.10.14.20210815v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20210815 "}, {"title": "Knowledge and practices towards COVID-19 among Palestinians during the COVID-19 outbreak: A second round cross-sectional survey", "abstract": "Coronavirus disease 2019 (COVID-19) is a highly transmissible illness that spreads rapidly through human-to-human transmission. To assess the knowledge and practices of Palestinians towards COVID-19 after the ease of movement restrictions, we collected data from Palestinian adults between June 15th and June 30th 2020. The participants' pool represented a stratified sample of 1355 adults from Palestinian households across 11 governorates in the West Bank. The questionnaire included 7 demographic questions, 13 questions about participants' knowledge and awareness of COVID-19, and 4 questions regarding the participants' safety measures that had been taken in the last three months.  Based on the results of this study, we conclude that the majority of participants have a good knowledge about COVID-19, but were not adequately committed to the infection control measures necessary to protect themselves and others. The findings may provide valuable feedback to lawmakers and health administrators to prevent the spread of the epidemic.", "filename": "2020.10.13.20211888v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211888 "}, {"title": "Characteristics and Factors Associated with COVID-19 Infection, Hospitalization, and Mortality Across Race and Ethnicity", "abstract": "Background\nData on the characteristics of COVID-19 patients disaggregated by race/ethnicity remain limited. We evaluated the sociodemographic and clinical characteristics of patients across the major racial/ethnic groups and assessed their associations with COVID-19 outcomes.\n\nMethods\nThis retrospective cohort study analyzed patients who were tested for SARS-CoV-2 in a large, integrated health system spanning California, Oregon, and Washington between March 1 and August 30, 2020. Sociodemographic and clinical characteristics were obtained from electronic health records. Odds of SARS-CoV-2 infection, COVID-19 hospitalization, and in-hospital death were assessed with multivariate logistic regression.\n\nFindings\n289,294 patients with known race/ethnicity were tested for SARS-CoV-2 by PCR, of whom 27.5% were non-White minorities. 15,605 persons tested positive, with minorities representing 58.0%. Disparities were widest among Hispanics, who represented 40.5% of infections but 12.8% of those tested. Hispanics were generally younger and had fewer comorbidities except diabetes than White patients. Of the 3,197 patients hospitalized, 58.9% were non-White. 459 patients died, of whom 49.8% were minorities. Racial/ethnic distributions of outcomes across the health system tracked with state-level statistics. Increase odds of testing positive and hospitalization were associated with all minority races/ethnicities except American Indian/Alaska Native. Highest odds of testing SARS-CoV-2 positive was for Hispanic patients (OR [95% CI]: 3.68 [3.52-3.84]) and highest odds of COVID-19 hospitalization was for Native Hawaiian/Pacific Islander patients (2.13 [1.48 - 3.06]). Hispanic patients also exhibited increased morbidity including need for mechanical ventilation. In multivariate modeling, Hispanic race/ethnicity was associated with increased odds of hospital mortality (1.75 [1.15-2.67]) among patients over age 70, but hospital mortality was not increased for any race/ethnicity sub-population in the multivariate model.\n\nInterpretation\nMajor healthcare disparities were evident, especially among Hispanics who tested positive at a higher rate, and despite younger in age, required excess hospitalization and need for mechanical ventilation compared to their expected demographic proportions. As characteristics of patients varying between race/ethnicity, targeted, culturally-responsive interventions are needed to address the increased risk of poor outcomes among minority populations with COVID-19.\n\nFunding\nBiomedical Advanced Research and Development Authority; National Center for Advancing Translational Sciences", "filename": "2020.10.14.20212803v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212803 "}, {"title": "Development of a deep learning classifier to accurately distinguish COVID-19 from look-a-like pathology on lung ultrasound", "abstract": "Objectives\nLung ultrasound (LUS) is a portable, low cost respiratory imaging tool but is challenged by user dependence and lack of diagnostic specificity.  It is unknown whether the advantages of LUS implementation could be paired with deep learning techniques to match or exceed human-level, diagnostic specificity among similar appearing, pathological LUS images.  \nDesign\nA convolutional neural network was trained on LUS images with B lines of different etiologies.  CNN diagnostic performance, as validated using a 10% data holdback set was compared to surveyed LUS-competent physicians.\nSetting\nTwo tertiary Canadian hospitals.\nParticipants\n600 LUS videos (121,381 frames) of B lines from 243 distinct patients with either 1) COVID-19, Non-COVID acute respiratory distress syndrome (NCOVID) and 3) Hydrostatic pulmonary edema (HPE).  \nResults\nThe trained CNN performance on the independent dataset showed an ability to discriminate between COVID (AUC 1.0), NCOVID (AUC 0.934) and HPE (AUC 1.0) pathologies.  This was significantly better than physician ability  (AUCs of 0.697, 0.704, 0.967 for the COVID, NCOVID and HPE classes, respectively), p < 0.01.   \nConclusions\nA deep learning model can distinguish similar appearing LUS pathology, including COVID-19,  that cannot be distinguished by humans.  The performance gap between humans and the model suggests that subvisible biomarkers within ultrasound images could exist and multi-center research is merited.", "filename": "2020.10.13.20212258v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212258 "}, {"title": "Social contact patterns among employees in 3 U.S. companies during early phases of the COVID-19 pandemic, April to June 2020.", "abstract": "Importance: Devising control strategies against diseases such as COVID-19 require understanding of contextual social mixing and contact patterns. There has been no standardized multi-site social contact study conducted in workplace settings in the United States that can be used to broadly inform pandemic preparedness policy in these settings.\nObjective: The study aimed to characterize the patterns of social contacts and mixing across workplace environments, including on-site or when teleworking.\nDesign: This was a cross-sectional non-probability survey that used standardized social contact diaries to collect data. Employees were requested to record their physical and non-physical contacts in a diary over two consecutive days, documented at the end of each day. Employees from each company were enrolled through email and electronic diaries sent as individual links. Data were collected from April to June 2020.\nSetting: Two multinational consulting companies and one university administrative department, all located in Georgia, USA.\nParticipants: Employees opted into the study by accepting the invitation on a link sent via email.\nMain Outcome: The outcome was median number of contacts per person per day. This was stratified by day of data collection, age, sex, race and ethnicity.\nResults: Of 3,835 employees approached, 357 (9.3%) completed the first day of contact diary of which 304 completed both days of contact diary. There was a median of 2 contacts (IQR: 1-4, range: 0-21) per respondent on both day one and two. The majority (55%) of contacts involved conversation only, occurred at home (64%), and cumulatively lasted more than 4 hours (38%). Most contacts were repeated, and within same age groups, though participants aged 30-59 years reported substantial inter-generational mixing with children.\nConclusion: Participating employees in 3 surveyed workplaces reported few contacts, similar to studies from the UK and China when shelter-in-place orders were in effect during the pandemic. Many contacts were repeated which may limit the spread of infection. Future rounds are planned to assess changes in contact patterns when employees resume work in the office after the lockdown due to COVID-19 pandemic.", "filename": "2020.10.14.20212423v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212423 "}, {"title": "An attempt to optimize human resources allocation based on spatial diversity of COVID-19 cases in Poland", "abstract": "Our task is to examine the relationship between the SARS-CoV-2 arrival and the number of confirmed COVID-19 cases in the first wave (period from March 4 to May 22, 2020 (unofficial data)), and socio-economic variables at the powiat (county) level (NUTS-4) using simple statistical techniques such as data visualization, correlation analysis, spatial clustering and multiple linear regression. We showed that immigration and the logarithm of general mobility is the best predictor of SARS-CoV-2 arrival times, while emigration, industrialization and air quality explain the most of the size of the epidemic in poviats. On the other hand, infection dynamics is driven to a lesser extent by previously postulated variables such as population size and density, income or the size of the elderly population. Our analyses could support Polish authorities in preparation for the second wave of infections and optimal management of resources as we have provided a proposition of optimal distribution\nof human resources between poviats.", "filename": "2020.10.14.20090985v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20090985 "}, {"title": "Parental acceptance toward behavior guidance techniques for pediatric dental visits: a meta-analysis", "abstract": "Objective: The systematic review aimed to compare agreement with behavior guidance techniques (BGT) between parents of children with special health care needs (SHCN) and those non-SHCN. Methods: A structured search of Cochrane Library, Latin American and Caribbean Health Sciences, PubMed, PsycInfo, Scopus, Web of Science, ProQuest Dissertations and Theses Database, Opengrey and Google Scholar was taken up to October 2020. Two authors selected studies independently, extracted the data, assessed the studies methodological quality using the Joanna Briggs scale and the Recommendations, Assessment, Development and Evaluation (GRADE). Results: Forty-eight studies covering the parents agreement with BGT were included and 41 were retained for random-effects proportion meta-analysis. The methodological quality assessment varied from low to high. Among the parents of non-SHCN children, the agreement with BGT varied from 84.1% (95% CI: 75.8-90.9; p<0.001; I2 93.3%) for tell-show-do to 25.7% (95% CI: 17.8-34.4; p<0.001; I2 90.4%) for passive protective stabilization, without hand-over-mouth. Among the parents of children with SHCN, the acceptance of BGT varied from 89.1% (95% CI: 56.1-99.7; p<0.001; I2 95.7%) for tell-show-do to 29.1% (95% CI: 11.8-50.0; p=0.001; I2 84.8%) to general anesthesia. Conclusion: There is very low certainty in evidence that both the parents of children SHCN and non-SHCN were more likely to agree with basic BGT and that they were less likely to agree with the advanced ones.", "filename": "2020.10.13.20212191v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212191 "}, {"title": "Physical Activity Decreases the Prevalence of COVID-19-associated Hospitalization: Brazil EXTRA Study", "abstract": "Objectives: We compared physical activity levels before the outbreak and quarantine measures with COVID-19-associated hospitalization prevalence in surviving patients infected with SARS-CoV-2. Additionally, we investigated the association of physical activity levels with symptoms of the disease, length of hospital stay, and mechanical ventilation.\nMethods: Between June 2020 and August 2020, we invited Brazilian survivors and fully recovered patients infected with SARS-CoV-2 to respond to an online questionnaire. We shared the electronic link to the questionnaire on the internet. In this cross-sectional study, we collected data about clinical outcomes (symptoms, medications, hospitalization, and length of hospital stay) and cofactors, such as age, sex, ethnicity, preexisting diseases, socioeconomic and educational, and physical activity levels using the International Physical Activity Questionnaire (IPAQ short version).\nResults: Out of 938 patients, 91 (9.7%) were hospitalized due to COVID-19. In a univariate analysis, sex, age, and BMI were all associated with hospitalizations due to COVID-19. Men had a higher prevalence of hospitalization (66.6%, P=0.013). Patients older than 65 years, obese, and with preexisting disease had a higher prevalence of COVID-19-related hospitalizations. In a multivariate regression model, performance of at least 150 min/wk (moderate) and/or 75 min/wk (vigorous) physical activity was associated with a lower prevalence of hospitalizations after adjustment for age, sex, BMI, and preexisting diseases (PR=0.657; P=0.046).\nConclusions: Sufficient physical activity levels are associated with a lower prevalence of COVID-19-related hospitalizations. Performing at least 150 minutes a week of moderate-intensity, or 75 minutes a week of vigorous-intensity physical activity reduces this prevalence by 34.3%.", "filename": "2020.10.14.20212704v1", "doi": "doi: https://doi.org/10.1101/2020.10.14.20212704 "}, {"title": "Local and Distant responses to single pulse electrical stimulation reflect different forms of connectivity", "abstract": "Background: Measuring connectivity in the human brain can involve innumerable approaches using both noninvasive (fMRI, EEG) and invasive (intracranial EEG or iEEG) recording modalities, including the use of external probing stimuli, such as direct electrical stimulation.\nObjective/Hypothesis: To examine how different measures of connectivity correlate with one another, we compared 'passive' measures of connectivity during resting state conditions map to the more 'active' probing measures of connectivity with single pulse electrical stimulation (SPES).\nMethods: We measured the network engagement and spread of the cortico-cortico evoked potential (CCEP) induced by SPES at 53 total sites across the brain, including cortical and subcortical regions, in patients with intractable epilepsy (N=11) who were undergoing intracranial recordings as a part of their clinical care for identifying seizure onset zones. We compared the CCEP network to functional, effective, and structural measures of connectivity during a resting state in each patient. Functional and effective connectivity measures included correlation or Granger causality measures applied to stereoEEG (sEEGs) recordings. Structural connectivity was derived from diffusion tensor imaging (DTI) acquired before intracranial electrode implant and monitoring (N=8).\nResults: The CCEP network was most similar to the resting state voltage correlation network in channels near to the stimulation location. In contrast, the distant CCEP network was most similar to the DTI network. Other connectivity measures were not as similar to the CCEP network.\n3\nConclusions: These results demonstrate that different connectivity measures, including those derived from active stimulation-based probing, measure different, complementary aspects of regional interrelationships in the brain.", "filename": "2020.10.13.20212266v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212266 "}, {"title": "PREOPERATIVE SERUM ALBUMIN LEVEL AS A PREDICTOR OF MORTALITY AND MORBIDITY AFTER VALVE REPLACEMENT SURGERY", "abstract": "Introduction: Serum albumin has a close correlation with degree of malnutrition which is associated with poor outcome and quality of life after cardiac surgery. Hypoalbuminemia is associated with increased wound infection, prolonged hospital stay and death after major surgery. Although there are many risk assessment methods available which are used to assess risk of cardiac operative mortality and morbidity but they have some limitations. Hence, preoperative serum albumin level can be utilized to upgrade risk models which will further benefit the cardiac surgical patients without extra financial burden.\nObjective: To evaluate the role of serum albumin as a predictor of morbidity and mortality after valve replacement surgery.\nMaterials and Methods: This comparative cross-sectional study was carried out at the department of cardiac surgery in BSMMU. The study population was 50, with two groups having 25 patients each. Grouping of patients were done with respect to a preset cut off value for serum albumin. The period of study was from August, 2018 to February, 2020 and purposive sampling method was applied for this study. Data was collected by using a standardized semi-structured questionnaire and face to face interview.\nResults: In comparison to demographic characteristics, mean age in group A and B were 41.6011.16 years & 49.96\u00b18.69 years respectively, which was found statistically significant (p=0.005). Gender distribution was insignificant but BMI was found statistically significant in between groups (p<0.05). Difference in terms of preoperative risk factors and investigations, no statistical significance found in between groups. Comparison of peroperative variables were also found statistically insignificant. In terms of postoperative outcome, total chest drain collection was higher in group B (968.80\u00b1183.49 ml) than group A (816.00\u00b1113.40 ml), which was statistically significant (p=0.001). Similarly, duration of ICU stay and hospital stay were longer in group B (4.60\u00b10.76 days & 9.88\u00b11.56 days respectively) than group A (3.92\u00b10.86 days & 8.64\u00b10.81 days respectively), which were found statistically significant (p=0.005 & p=0.001 respectively). Among postoperative complications wound infection was found much more in group B (16%) compared to group A (4%), but that was not found to be statistically significant (p>0.05). In comparison to overall morbidity and mortality, higher morbidity was seen in group B (48%) compared to group A (20%), which was found statistically significant (p<0.05), but difference in terms of mortality was not found statistically significant, though it was higher in group B (12% compared to 4%). Pearson co-efficient correlation test showed strong inverse relationship of serum albumin with total chest drain, ICU stay and hospital stay following valve replacement surgery (r= -0.473, r= -0.448 & r= -0.487 respectively), which was most significant than age and BMI (p\u22640.001). Multivariate logistic regression analysis was done to assess the predictive value of serum albumin level, age and BMI, where preoperative serum albumin level was found to be the most valuable predictor of postoperative morbidity after valve replacement surgery (B= -2.251, OR 0.105, 95% CI 0.011-0.986, p<0.05).\nConclusion: This study demonstrated that preoperative low serum albumin level is associated with increased morbidity and mortality after valve replacement surgery. Hence preoperative serum albumin level can be used as a reliable predictor of postoperative outcome.\nKey words: Morbidity, In-hospital mortality, preoperative serum albumin level, valve replacement surgery.", "filename": "2020.10.13.20206409v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20206409 "}, {"title": "IgM autoantibodies recognizing ACE2 are associated with severe COVID-19", "abstract": "SARS-CoV-2 infection induces severe disease in a subpopulation of patients, but the underlying mechanisms remain unclear. We demonstrate robust IgM autoantibodies that recognize angiotensin converting enzyme-2 (ACE2) in 18/66 (27%) patients with severe COVID-19, which are rare (2/52; 3.8%) in hospitalized patients who are not ventilated. The antibodies do not undergo class-switching to IgG, suggesting a T-independent antibody response.  Purified IgM from anti-ACE2 patients activates complement. Pathological analysis of lung obtained at autopsy shows endothelial cell staining for IgM in blood vessels in some patients.   We propose that vascular endothelial ACE2 expression focuses the pathogenic effects of these autoantibodies on blood vessels, and contributes to the angiocentric pathology observed in some severe COVID-19 patients. These findings may have predictive and therapeutic implications.", "filename": "2020.10.13.20211664v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211664 "}, {"title": "Stay-at-home policy: is it a case of exception fallacy? An internet-based ecological study", "abstract": "Background: Countries with strict lockdown had a spike on the number of deaths. A recent mathematical model has suggested that staying at home did not play a dominant role in reducing COVID-19 transmission. Comparison between number of deaths and social mobility is difficult due to the non-stationary nature of the COVID-19 data. \nObjective: To propose a novel approach to assess the association between staying at home values and the reduction/increase in the number of deaths due to COVID-19 in several regions around the world.\nMethods: In this ecological study, data from www.google.com/covid19/mobility/, ourworldindata.org and covid.saude.gov.br were combined. Countries with >100 deaths and with a Healthcare Access and Quality Index of \u226567 were included. Data were preprocessed and analyzed using the difference between number of deaths/million between 2 regions and the difference between the percentage of staying at home. Analysis was performed using linear regression and residual analysis\nResults: After preprocessing the data, 87 regions around the world were included, yielding 3,741 pairwise comparisons for linear regression analysis. Only 63 (1.6%) comparisons were significant. \nDiscussion: With our results, we were not able to explain if COVID-19 mortality is reduced by staying as home in ~98% of the comparisons after epidemiological weeks 9 to 34.", "filename": "2020.10.13.20211284v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211284 "}, {"title": "Thermal Effect On The Persistence Of SARS-CoV2 Egyptian Isolates As Measured By Quantitative RT-PCR", "abstract": "Coronavirus pandemic that caused by severe acute respiratory syndrome Coronavirus 2 (SARS-CoV-2) appeared in China in 2019 then spread all over the world. COVID-19 firstly appeared in Egypt in Feb 2020. Studies on the thermal stability of the virus is crucial proper specimens transportation for molecular study. Oropharyngeal swabs were taken from recently infected military people with COVID-19 from Egypt during April 2020. Samples were aliquoted and the thermal stability of the virus was measured using quantitative real Time RT-PCR for samples treated at different temperature ranges from 20 C to 70 C for 2,4and 6 hours. Results shown that inactivation of the virus and significant reduction in the \u0394Cq values begin at 40 C/4h. Complete virus inactivation and loss of \u0394Cq values were seen at 50 C/6h and 60 C. Tested samples showed no significant difference in thermal stability at any temp/time combinations tested.", "filename": "2020.10.13.20211771v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211771 "}, {"title": "Automatic detection of generalized paroxysmal fast activity in interictal EEG using time-frequency analysis", "abstract": "Objective: Markup of generalized interictal epileptiform discharges (IEDs) on EEG is an important step in the diagnosis and characterization of epilepsy. However, manual EEG mark-up is a time-consuming, subjective, and highly specialized task where the human reviewer needs to visually inspect a large amount of data to facilitate accurate clinical decisions. The objective of this study was to develop a framework for automated detection of generalized paroxysmal fast activity (GPFA),  which is a characteristic type of generalized IED seen in scalp EEG recordings of patients with Lennox-Gastaut syndrome (LGS), a severe form of drug-resistant generalized epilepsy.\nMethods: We studied 13 children with LGS who had GPFA events in their interictal EEG recordings. Time-frequency information derived from manually marked IEDs across multiple EEG channels was used to automatically detect similar events in each patient's interictal EEG. We validated true positives and false positives of the proposed spike detection approach using both standalone scalp EEG and simultaneous EEG-functional MRI (EEG-fMRI) recordings.\nResults: GPFA events displayed a consistent low-high frequency arrangement in the time-frequency domain. This bimodal spectral feature was most prominent over frontal EEG channels. Our automatic detection approach using this feature identified likely epileptic events with similar time-frequency properties to the manually marked GPFAs. Brain maps of EEG-fMRI signal change during these automatically detected IEDs were comparable to the EEG-fMRI brain maps derived from manual IED markup. \nConclusion: GPFA events have a characteristic bimodal time-frequency feature that can be automatically detected from scalp EEG recordings in patients with LGS. Validity of this time-frequency feature is demonstrated by EEG-fMRI analysis of automatically detected events, which recapitulates the brain maps we have previously shown to underlie generalized IEDs in LGS.  \nSignificance: This study provides a novel methodology that paves the way for quick, automated, and objective inspection of generalized IEDs in LGS. The proposed framework may be extendable to a wider range of epilepsy syndromes in which monitoring the burden of epileptic activity can aid clinical decision-making. For example, automated quantification of generalized discharges may permit faster assessment of treatment response and estimation of future seizure risk.", "filename": "2019.12.28.19016089v3", "doi": "doi: https://doi.org/10.1101/2019.12.28.19016089 "}, {"title": "Quantifying the Effects of Social Distancing on the Spread of COVID-19", "abstract": "This paper studies the interplay between the social distancing and the spread of COVID-19 disease, a widely spread pandemic that has affected nearly most of the world population. Starting in China, the virus has reached the  United  States of America with devastating consequences. Other countries severely affected by the pandemic are Brazil, Russia, United Kingdom, Spain, India, Italy, and France. Even though it is not possible to eliminate the spread of the virus from the world or any other country, it might be possible to reduce its effect by decreasing the number of infected people. Implementing such policies needs a good understanding of the system dynamics, generally not possible with mathematical linear equations or Monte Carlo methods because human society is a complex adaptive system with complex and continuous feedback loops. As a result, we use agent-based methods to conduct our study. Moreover, recent agent-based modeling studies for the COVID-19 pandemic show significant promise assisting decision-makers in managing the crisis through applying some policies such as social distancing, disease testing, contact tracing, home isolation,  providing good emergency and hospitalization strategies, and preventing traveling would lead to reducing the infection rates. Based on imperial college modeling studies that prove increasing levels of interventions could slow down the spread of disease and infection cases as much as possible,  and taking into account that social distancing policy is considered to be the most important factor that was recommended to follow. Our proposed model is designed to test if increasing the social distancing policies strictness can slow down the spread of disease significantly or not, and find out what is the required safe level of social distancing. So, the model was run six times, with six different percentages of social distancing with keeping the other parameters levels fixed for all experiments. The results of our study show that social distancing affects the spread of  COVID-19  significantly, where the spread of disease and infection rates decrease once social distancing procedures are implemented at higher levels. Also, the behavior space tool was used to run ten experiments with different levels of social distancing, which supported the previous results. We concluded that applying and increasing social distancing policy levels led to significantly reduced infection rates, which result in decreasing deaths. Both types of experiments prove that infection rates are reduced dramatically when the level of social distancing intervention is implemented between 80% to 100%.", "filename": "2020.09.19.20197996v3", "doi": "doi: https://doi.org/10.1101/2020.09.19.20197996 "}, {"title": "Novel SARS-CoV-2 specific antibody and neutralization assays reveal wide range of humoral immune response during COVID-19", "abstract": "Development of antibody protection during SARS-CoV-2 infection is a pressing question for public health and for vaccine development. We developed highly sensitive SARS-CoV-2-specific antibody and neutralization assays. SARS-CoV-2 Spike protein or Nucleocapsid protein specific IgG antibodies at titers more than 1:100,000 were detectable in all PCR+ subjects (n=115) and were absent in the negative controls. Other isotype antibodies (IgA, IgG1-4) were also detected. SARS-CoV-2 neutralization was determined in COVID-19 and convalescent plasma at up to 10,000-fold dilution, using Spike protein pseudotyped lentiviruses, which were also blocked by neutralizing antibodies (NAbs). Hospitalized patients had up to 3000-fold higher antibody and neutralization titers compared to outpatients or convalescent plasma donors. Interestingly, some COVID-19 patients also possessed NAbs against SARS-CoV Spike protein pseudovirus. Together these results demonstrate the high specificity and sensitivity of our assays, which may impact understanding the quality or duration of the antibody response during COVID-19 and in determining the effectiveness of potential vaccines.", "filename": "2020.07.07.20148106v3", "doi": "doi: https://doi.org/10.1101/2020.07.07.20148106 "}, {"title": "Rationale and prognosis of repurposed drugs with risk stratification of COVID-19 patients requiring Oxygen supplementation: A systematic review and meta-analysis", "abstract": "Background\nThe rising number of trials on repurposed dugs in COVID-19 has led to duplication and a need for curation of available outcomes from treatments that have been followed across the world.  We have conducted a systematic review and meta-analysis that focus on evaluating the clinical outcomes of repurposed interventions against COVID-19.\nMethods\nRandom effects model was adopted to estimate overall treatment effect and heterogeneity. Meta-regression was performed to study the correlation between comorbid conditions and non-invasive or invasive ventilation requirement. \nResults\nTwenty-nine articles met our eligibility criteria. In subgroup analysis, Tocilizumab was highly significant with lower mortality rate (OR 27.50; 95%CI [5.39-140.24]) of severe COVID-19 patients. Hydroxychloroquine and Lopinavir-ritonavir was found to be inefficacious in severe patients (OR 0.64; 95%CI [0.47-0.86] and 1.40 [0.71-2.76]). Dexamethasone had marginal effect on overall mortality rate (OR 1.19; 95%CI [1.05-1.35]). The meta-regression shows a positive correlation between prevalence of patients on Tocilizumab in non invasive support and hypertension condition (P = 0.02), whereas a negative correlation was identified with patients having lung disease (P = 0.03).\nConclusion\nOverall, our study confirmed that tocilizumab may probably reduce the mortality rate (<10%) of severe COVID-19 patients than other interventions. Further, reduce the risk of requiring non-invasive ventilator support in patients with comorbid condition of lung disease. Hydroxychloroquine and Lopinavir-ritonavir has no clinical benefits in severe COVID-19. A high quality evidence is required to evaluate the usage of Serpin + Favipiravir combination in severe or critical COVID-19.", "filename": "2020.10.04.20206516v2", "doi": "doi: https://doi.org/10.1101/2020.10.04.20206516 "}, {"title": "Performance of a point of care test for detecting IgM and IgG antibodies against SARS-CoV-2 and seroprevalence in blood donors and health care workers in Panama", "abstract": "Novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is the etiologic agent of the ongoing coronavirus disease 2019 (COVID-19) pandemic, which has reached 28 million cases worldwide in eight months. The serological detection of antibodies against the virus will play a pivotal role in complementing molecular tests to improve diagnostic accuracy, contact tracing, vaccine efficacy testing and seroprevalence surveillance. Here, we aimed first to evaluate a lateral flow assay ability to identify specific IgM and IgG antibodies against SARS-CoV-2 and second, to report the seroprevalence of these antibodies among health care workers and healthy volunteer blood donors in Panama. We recruited study participants between April 30th and July 7th, 2020.  For the test validation and performance evaluation, we analyzed serum samples from participants with clinical symptoms and confirmed positive RT-PCR for SARS-CoV-2, and a set of pre-pandemic serum samples. We used two by two table analysis to determine the test sensitivity and specificity as well as the kappa agreement value with a 95% confidence interval. Then, we used the lateral flow assay to determine seroprevalence among serum samples from COVID-19 patients, potentially exposed health care workers, and healthy volunteer donors. Our results show this assay reached a positive percent agreement of 97.2% (95% CI 84.2-100.0%) for detecting both IgM and IgG.  The assay showed a kappa of 0.898 (95%CI 0.811- 0.985) and 0.918 (95% CI 0.839-0.997) for IgM and IgG, respectively. The evaluation of serum samples from hospitalized COVID-19 patients indicates a correlation between test sensitivity and the number of days since symptom onset; the highest positive percent agreement (87% (95% CI 67.0-96.3%)) was observed at 15 days post-symptom onset. We found an overall antibody seroprevalence of 11.6% (95% CI 8.5-15.8%) among both health care workers and healthy blood donors. Our findings suggest this lateral flow assay could contribute significantly to implementing seroprevalence testing in locations with active community transmission of SARS-CoV-2.", "filename": "2020.09.25.20201459v3", "doi": "doi: https://doi.org/10.1101/2020.09.25.20201459 "}, {"title": "Spatial analysis of COVID-19 spread in Iran: Insights into geographical and structural transmission determinants at a province level", "abstract": "The Islamic Republic of Iran reported its first COVID-19 cases by 19th February 2020, since then it has become one of the most affected countries, with more than 73,000 cases and 4,585 deaths to this date. Spatial modeling could be used to approach an understanding of structural and sociodemographic factors that have impacted COVID-19 spread at a province-level in Iran. Therefore, in the present paper, we developed a spatial statistical approach to describe how COVID-19 cases are spatially distributed and to identify significant spatial clusters of cases and how  socioeconomic and climatic features of Iranian provinces might predict the number of cases. The analyses are applied to cumulative cases of the disease from February 19th to March 18th. They correspond to obtaining maps associated with quartiles for rates of COVID-19 cases smoothed through a Bayesian technique and relative risks, the calculation of global (Moran's I) and local indicators of spatial autocorrelation (LISA), both univariate and bivariate, to derive significant clustering, and the fit of a multivariate spatial lag model considering a set of variables potentially affecting the presence of the disease.  We identified a cluster of provinces with significantly higher rates of COVID-19 cases around Tehran (p-value< 0.05), indicating that the COVID-19 spread within Iran was spatially correlated. Urbanized, highly connected provinces with older population structures and higher average temperatures were the most susceptible to present a higher number of COVID-19 cases (p-value < 0.05). Interestingly, literacy is a factor that is associated with a decrease in the number of cases (p-value < 0.05), which might be directly related to health literacy and compliance with public health measures.  These features indicate that social distancing, protecting older adults, and vulnerable populations, as well as promoting health literacy, might be useful to reduce SARS-CoV-2 spread in Iran. One limitation of our analysis is that the most updated information we found concerning socioeconomic and climatic features is not for 2020, or even for a same year, so that the obtained associations should be interpreted with caution. Our approach could be applied to model COVID-19 outbreaks in other countries with similar characteristics or in case of an upturn in COVID-19 within Iran.", "filename": "2020.04.19.20071605v2", "doi": "doi: https://doi.org/10.1101/2020.04.19.20071605 "}, {"title": "A Rapid Review and Meta-Analysis of the Asymptomatic Proportion of PCR-Confirmed SARS-CoV-2 Infections in Community Settings", "abstract": "Background: Up to 80% of active SARS-CoV-2 infections are proposed to be asymptomatic based on cross-sectional studies. However, accurate estimates of the asymptomatic proportion require systematic detection and follow-up to differentiate between truly asymptomatic and pre-symptomatic cases. We conducted a rapid review and meta-analysis of the asymptomatic proportion of PCR-confirmed SARS-CoV-2 infections based on methodologically-appropriate studies in community settings.\n\nMethods: We searched Medline and EMBASE for peer-reviewed articles, and BioRxiv and MedRxiv for pre-prints published before 25/08/2020. We included studies based in community settings that involved systematic PCR testing on participants and follow-up symptom monitoring regardless of symptom status. We extracted data on study characteristics, frequencies of PCR-confirmed infections by symptom status, and (if available) cycle threshold/genome copy number values and/or duration of viral shedding by symptom status, and age of asymptomatic versus (pre)symptomatic cases. We computed estimates of the asymptomatic proportion and 95% confidence intervals for each study and overall using random effect meta-analysis.  \n\nFindings: We screened 1138 studies and included 21. The pooled asymptomatic proportion of SARS-CoV-2 infections was 23% (95% CI 16%-30%). When stratified by testing context, the asymptomatic proportion ranged from 6% (95% CI 0-17%) for household contacts to 47% (95% CI 21-75%) for non-outbreak point prevalence surveys with follow-up symptom monitoring. Estimates of viral load and duration of viral shedding appeared to be similar for asymptomatic and symptomatic cases based on available data, though detailed reporting of viral load and natural history of viral shedding by symptom status were limited. Evidence into the relationship between age and symptom status was inconclusive. \n\nConclusion: Asymptomatic viral shedding comprises a substantial minority of SARS-CoV-2 infections when estimated using methodologically-appropriate studies. Further investigation into variation in the asymptomatic proportion by testing context, the degree and duration of infectiousness for asymptomatic infections, and demographic predictors of symptom status are warranted.", "filename": "2020.05.20.20108183v2", "doi": "doi: https://doi.org/10.1101/2020.05.20.20108183 "}, {"title": "From more testing to smart testing: data-guided SARS-CoV-2 testing choices", "abstract": "We present an in-depth analysis of data from drive through testing stations using rapid antigen detection tests (RDTs), RT-PCR and virus culture, to assess the ability of RDTs to detect infectious cases. We show that the detection limits of five commercially available RDTs differ considerably, impacting the translation into the detection of infectious cases. We recommend careful fit-for-purpose testing before implementation of antigen RDTs in routine testing algorithms as part of the COVID-19 response.", "filename": "2020.10.13.20211524v2", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211524 "}, {"title": "Real-world effectiveness of hydroxychloroquine, azithromycin, and ivermectin among hospitalized COVID-19 patients: results of a target trial emulation using observational data from a nationwide healthcare system in Peru", "abstract": "Introduction: Peru is one of the most impacted countries due to COVID-19. Given the authorized use of hydroxychloroquine (HCQ), azithromycin (AZIT), and ivermectin (IVM), we aimed to evaluate their effectiveness alone or combined to reduce mortality among COVID-19 hospitalized patients without life-threatening illness.\nMethods: Retrospective cohort emulating a target trial, using nationwide data of mid- and high-level hospitals from the Peruvian Social Health Insurance 01/April/2020-19/July/2020. Patients 18 yo and above with PCR-confirmed SARS-CoV-2, and no life-threatening illness at admission were included. Five treatment groups (HCQ alone, IVM alone, AZIT alone, HCQ+AZIT, and IVM+AZIT within 48 hours of admission) were compared with standard of care alone. Primary outcome was all-cause mortality rate; secondary outcomes were all-cause death and/or ICU transfer, and all-cause death and/or oxygen prescription. Analyses were adjusted using inverse probability of treatment weighting. Propensity scores were estimated using machine learning boosting models. Weighted hazard ratios (wHR) were calculated using Cox regression.\nResults: Among 5683 patients, 200 received HCT, 203 IVM, 1600 AZIT, 692 HCQ+AZIT, 358 IVM+AZIT, and 2630 standard of care. HCQ+AZIT was associated with 84% higher all-cause death hazard compared to standard care (wHR=1.84, 95%CI 1.12-3.02). Consistently, HCQ+AZIT was also associated with higher death and/or ICU transfer (wHR=1.49, 95%CI 1.01-2.19), and death and/or oxygen prescription (wHR=1.70, 95%CI 1.07-2.69). HCQ only showed higher death and/or oxygen prescription hazard. No effect was found for AZIT or IVM+AZIT.  \nConclusions: Our study reported no beneficial effects of hydroxychloroquine, ivermectin, azithromycin. The HCQ+AZIT treatment seems to increase risk for all-cause death.", "filename": "2020.10.06.20208066v3", "doi": "doi: https://doi.org/10.1101/2020.10.06.20208066 "}, {"title": "COVID-CT-Mask-Net: Prediction of COVID-19 from CT Scans Using Regional Features", "abstract": "We present COVID-CT-Mask-Net model that predicts COVID-19 from CT scans. The model works in two stages: first, it detects the instances of ground glass opacity and consolidation in CT scans, then predicts the condition from the ranked bounding box detections. To develop the solution for the three-class problem (COVID, common pneumonia and control), we used the COVIDx-CT dataset derived from the dataset of CT scans collected by China National Center for Bioinformation. We use about $5\\%$ of the training split of COVIDx-CT to train the model, and without any complicated data normalization, balancing and regularization, and training only a small fraction of the model's parameters, we achieve a $\\mathbf{90.80\\%}$ COVID sensitivity, $\\mathbf{91.62\\%}$ common pneumonia sensitivity and $\\mathbf{92.10\\%}$ normal sensitivity, and an overall accuracy of $\\textbf{91.66\\%}$ on the test data (21182 images), bringing the ratio of test/train data to \\textbf{7.06}, which implies a very high capacity of the model to generalize to new data.  We also establish an important result, that ranked regional predictions (bounding boxes with scores) in Mask R-CNN can be used to make accurate predictions of the image class. The full source code, models and pretrained weights are available on \\url{https://github.com/AlexTS1980/COVID-CT-Mask-Net}.\n    %One of the challenges of training a machine learning model to detect the presence of COVID-related areas in CT scans is the scarcity of segmented data. We present the COVID-CT-Mask-Net, a COVID19 detection model based on instance segmentation of COVID-related areas in CT scans. The model is first trained to segment instances of two types of COVID correlates: ground-glass opacity and consolidation. Then, this model is augmented with three classification modules to predict COVID from the regional features in CT scans. Our model achieves the state-of-the-art accuracy in predicting COVID in patients, it is conceptually simpler, requires a smaller dataset for training compared to other machine learning models, and does not require tricks to balance the data.", "filename": "2020.10.11.20211052v2", "doi": "doi: https://doi.org/10.1101/2020.10.11.20211052 "}, {"title": "Circulating tumour cell and cell-free DNA kinetics during radiotherapy in patients with intact head and neck squamous cell carcinoma", "abstract": "Head and neck squamous cell carcinoma (HNSCC) treatment response relies heavily on macroscopic clinical findings. Blood monitoring of circulating markers during treatment may improve earlier detection of responders versus non-responders during radiotherapy. In this study, patients with intact tumour of HNSCC were enrolled in the prospective PREDICT-HN study. Pre-, after first treatment, weekly, and post-treatment blood samples were collected. CTC was enumerated using the CellSearch system. cfDNA was quantified from cfNA isolated at pre-, mid- and post-treatment timepoints. Blood samples were collected from 45 patients. Of the 339 samples analysed for CTC, 31% had detectable CTCs. Nine patients had detectable CTCs (1-3/7.5ml blood) in pre-treatment samples. After 1 fraction, 16 patients had CTCs detected, with 12 who had no pre-treatment CTC. Sixteen (36%) patients had detectable CTC in final week of treatment. There was no correlation between cancer stage, nodal status and tumour burden with CTC. cfDNA levels increased during treatment, with its highest level in the final week and lowest at post-treatment. Our results showed in HNSCC that CTCs can be detected during radiotherapy, suggesting mobilization into circulation during treatment, with as-yet-unknown viability. cfDNA kinetics during treatment correlated with CTC release, and may indicate apoptotic change.", "filename": "2020.10.13.20211516v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211516 "}, {"title": "The effectiveness of eight nonpharmaceutical interventions against COVID-19 in 41 countries", "abstract": "Governments are attempting to control the COVID-19 pandemic with nonpharmaceutical interventions (NPIs). However, it is still largely unknown how effective different NPIs are at reducing transmission. Data-driven studies can estimate the effectiveness of NPIs while minimising assumptions, but existing analyses lack sufficient data and validation to robustly distinguish the effects of individual NPIs. We gather chronological data on NPIs in 41 countries between January and the end of May 2020, creating the largest public NPI dataset collected with independent double entry. We then estimate the effectiveness of 8 NPIs with a Bayesian hierarchical model by linking NPI implementation dates to national case and death counts. The results are supported by extensive empirical validation, including 11 sensitivity analyses with over 200 experimental conditions. We find that closing schools and universities was highly effective; that banning gatherings and closing high-risk businesses was effective, but closing most other businesses had limited further benefit; and that many countries may have been able to reduce R below 1 without issuing a stay-at-home order.", "filename": "2020.05.28.20116129v4", "doi": "doi: https://doi.org/10.1101/2020.05.28.20116129 "}, {"title": "Coronavirus Disease-2019 Case, Death, and Testing Rates in the United States and Worldwide: Primary Data and Review", "abstract": "ABSTRACT       \nCoronavirus disease-2019 (COVID-19), due to the severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2), has been associated with a world-wide pandemic, with the United States (US) having the largest total number of cases and deaths (>7 million and >200,000, respectively) at this time. We assessed data as of September 1, 2020 from our combined laboratories and as reported for selected states and countries for case, death, and testing rates per 1 million in the population. Our goal was to elucidate potential causes for the large rate differences observed. SARS-CoV-2 naso-pharyngeal (NP) RNA swab testing in 985,219 US subjects referred to our laboratories by healthcare providers revealed an overall 10.1% positive rate, comparable to the 7.3% rate reported nationwide. In a small subset of 91 subjects, all of whom had been positive for SARS-CoV-2 RNA in NP swabs 2-4 weeks earlier, NP swab testing was twice as likely to be positive (58.6%) as saliva samples (21.5%), based on paired sampling. Our positive rates per state agreed reasonably well with reported Centers for Disease Control and Prevention (CDC) data (r=0.609, P<0.0001) based on 19,898 cases, 593 deaths, and 271,637 tests, all per 1 million in the US population. Louisiana had the highest case rate; New Jersey had the highest death rate; and Rhode Island had the highest testing rate. Of 47 countries, including all countries with populations >50 million, Qatar had the highest case rate; Peru had the highest death rate; and Israel had the highest testing rate for SARS-CoV-2 infection. Correlations between case rates and death rates as well as testing rates were 0.473 and 0.398 for US states and 0.473 and 0.476 for the various countries, respectively (all P<0.0001). In conclusion, outpatient saliva testing is not as sensitive as NP testing for SARS-CoV-2 RNA detection. While testing is important, without adequate public health measures, it is unlikely that we will get this pandemic under adequate control until vaccines become available.", "filename": "2020.10.13.20172957v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20172957 "}, {"title": "Impact of never use abbreviations (Error Prone Abbreviations-EPAs) list on incidence of EPAs in inpatient medical prescriptions in apex tertiary care public hospital in India", "abstract": "Introduction\nAbbreviations are commonly used in medical records to save time and space but use in prescriptions can be a reason for communication failures and preventable harm during healthcare delivery. Nearly 5% of medication errors can be attributable to abbreviation use. Prescriptions need to be clear so that nurses and pharmacists can correctly interpret intentions of doctors. For patient safety, hospitals should implement a process for uniform use of approved abbreviations, such as through use of an approved list or never-use list of abbreviations and symbols. The study envisaged to assess impact of never use list in an apex tertiary care hospital in India.\nMethods\nThe study design was pre-post interventional / quasi-experimental design to assess the impact of never use list and standardized abbreviations. The study was conducted after ethical approval from Institute Ethics Committee. Pre intervention data was collected by a retrospective closed in-patient medical record review. An approved Never use list and standardized abbreviations were developed and poster copies were affixed in inpatient wards, doctors were educated and poster pamphlets were also distributed. Post interventional incidence of error prone abbreviations was determined and the effectiveness of the same was assessed by using statistical analysis.\nResults\nIncidence of error abbreviations in inpatient prescription were 47.5% and Never Use list of abbreviation led to a statistically significant reduction of error-prone abbreviation by 8.2% from 47.5% to 43.6% (P\\0.006) \nConclusion  \nNever Use lists are effective in reducing incidence of common error-prone abbreviations and discipline wise variation is observed. Adoption of such lists is highly recommended. The lists should be comprehensive, regularly updated and educational interventions should be comprehensive and integration into patient medical charts and pocket friendly flash cards may be provided for better outcomes. Enforcing a policy to prohibit the use of EPAs while prescribing will also be helpful.", "filename": "2020.10.05.20206896v2", "doi": "doi: https://doi.org/10.1101/2020.10.05.20206896 "}, {"title": "The effect of face mask mandates during the COVID-19 pandemic on the rate of mask use in the United States", "abstract": "As COVID-19 continues to spread throughout the United States, there has been a search for policies to prevent individual infections, to slow the spread of the virus in general, and to mitigate the economic impact of the pandemic. Masks have proven to be a cost-effective measure in all regards, and as such some state governments have begun to mandate their use. However, while the efficacy of masks has been demonstrated, the efficacy of public policies which mandate the use of masks has not been demonstrated. This paper compares the rates of mask use in counties as defined by state policy. It finds that state mandates are strongly correlated with higher rates of mask use, and that mandating use by all individuals in public spaces is more effective than a less comprehensive mandate for mask use by all public facing employees.", "filename": "2020.10.03.20206326v2", "doi": "doi: https://doi.org/10.1101/2020.10.03.20206326 "}, {"title": "Estimating the false-negative test probability of SARS-CoV-2 by RT-PCR", "abstract": "Introduction: Reverse transcription-polymerase chain reaction (RT-PCR) assays are used to test for infection with the SARS-CoV-2 virus. RT-PCR tests are highly specific and the probability of false positives is low, but false negatives are possible depending on the individual, swab type and timing as infection progresses. \n\nObjectives: To determine how the false negative test probability in infected patients depends on the time since symptom onset and swab type. \n\nMethods: We use General Additive Mixed Models to analyse publicly available data from patients who received multiple RT-PCR tests and were identified as SARS-CoV-2 positive at least once. \n\nResults: We identify that the probability of a positive test decreases with time after symptom onset, with oropharyngeal [OP]samples less likely to yield a positive result than nasopharyngeal [NP] ones. We also comment on the likely false negative rates in cohorts of patients who present for testing at different clinical stages and assess the robustness of these estimates to the probability of false positive tests. \n\nConclusion: NP samples are more sensitive than OP samples. The later an infected individual is tested after the onset of symptoms, the less likely they are to test positive. This has implications for identification of infected patients, contact tracing, and also for the discharge of convalescing patients who are potentially still infectious. There is an urgent need for data from asymptomatic and presymptomatic individuals.", "filename": "2020.04.05.20053355v3", "doi": "doi: https://doi.org/10.1101/2020.04.05.20053355 "}, {"title": "Presence Of Infection By Mycobacterium Avium Subsp. Paratuberculosis In The Blood Of Patients With Crohns Disease And Control Subjects Shown By Multiple Laboratory Culture And Antibody Methods", "abstract": "Mycobacterium avium subspecies paratuberculosis (MAP) has long been suspected to be involved in the etiology of Crohns disease (CD). An obligate intracellular pathogen, MAP persists and influences host macrophages.  The primary goals of this study were to assess the degree of viable culturable MAP bacteremia in humans, definite identification of the organisms cultured and to assess if CD patients have a significantly higher rate of MAP infection compared to controls.  A secondary goal was to compare the efficacy of three culture methods plus a phage assay and four antibody assays performed in separate laboratories, to detect MAP from the parallel samples. Culture and serological MAP testing was performed blind on whole blood samples obtained from 201 subjects including 61 CD patients, two patients with CD and concurrent ulcerative colitis (UC), 14 patients with UC only and 140 non-CD controls. Viable MAP bacteremia was detected in a significant number of study subjects across all groups. This included Pozzato culture (124/201 or 62% of all subjects, 35/61 or 57% of CD patients), Phage assay (113/201 or 56% of all subjects, 28/61 or 46% of CD patients), TiKa culture (64/201 or 32% of all subjects, 22/61 or 36% of CD patients) and MGIT culture (36/201 or 18% of all subjects, 15/61 or 25% of CD patients). A link between MAP detection and CD was observed with MGIT culture and one of the antibody methods (Hsp65) confirming previous studies. Other detection methods showed no association between any of the groups tested. Nine subjects with positive Phage assay (8/9) or MAP culture (1/9) were again positive with the Phage assay one year later. This study highlights viable MAP bacteremia is widespread in the study population including CD patients, those with other autoimmune conditions and asymptomatic healthy subjects.", "filename": "2020.10.12.20209221v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20209221 "}, {"title": "Impact of COVID-19 Restrictions on People with Hypertension", "abstract": "Objectives: It is unclear how people with hypertension are responding to the COVID-19 pandemic given their increased risk, and whether targeted public health strategies are needed. \nDesign: This retrospective case-control study compared people with hypertension to matched healthy controls during COVID-19 lockdown, to determine whether they have higher risk perceptions, anxiety and prevention intentions.\nMethods: Baseline data from a national survey were collected in April 2020 during COVID-19 lockdown. Of 4362 baseline participants, 466 people reported hypertension with no other chronic conditions, and were randomly matched to healthy controls with similar age, gender, education and health literacy. A subset (n=1369) was followed-up at 2 months after restrictions eased, including 147 participants with hypertension only. Risk perceptions, prevention intentions and anxiety were measured.\nResults: At baseline, perceived seriousness was high for both hypertension and control groups. The hypertension group had higher anxiety than controls; and were more willing to have the influenza vaccine. At follow-up, these differences were no longer present in the longitudinal sub-sample. Perceived seriousness and anxiety had decreased, but vaccine intentions for both influenza and COVID-19 remained high (>80%).\nConclusions: Anxiety was above normal levels during the COVID-19 lockdown. This was higher in the hypertension group, who also had higher vaccination intentions. Locations with prolonged restrictions may require targeted mental health screening for vulnerable groups. Despite a decrease in perceived risk and anxiety after 2 months of lockdown restrictions, vaccination intentions for both influenza and COVID-19 remained high, which is encouraging for future prevention of COVID-19.", "filename": "2020.10.12.20211722v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211722 "}, {"title": "Dynamic dysregulation of IL-6 and genes functional in NETosis, complement and coagulation in severe COVID-19 illness", "abstract": "Comprehensive and unbiased re-analysis of published blood transcriptome data from patients of COVID-19 reveals significant up-regulation of the gene set functional in NETosis, but no evidence of general cytokine storm. In severe COVID-19 illness, there is significant up-regulation of complement and coagulation pathway, and negative correlation between NETosis and respiratory function (oxygen saturation). Interestingly, there is an early spike in the level of IL-6 gene expression in severe illness compared to moderate illness. With passing days post-onset, the level of IL-6 expression in severe illness approaches that in moderate illness. The data are consistent with IL-6 acting as a driver of NETosis in the early phase of severe COVID-19 illness, that results in a vicious cycle of NETosis-complement/coagulation-respiratory dysfunction. This has important consequence for timing of rational therapy with anti-IL-6 and NETosis inhibitors in severe COVID-19 illness.", "filename": "2020.10.13.20211425v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211425 "}, {"title": "Circulating Proteins Influencing COVID-19 Susceptibility and Severity: a Mendelian Randomization Study", "abstract": "Proteins detectable in peripheral blood may influence COVID-19 susceptibility or severity. However, understanding which circulating proteins are etiologically involved is difficult because their levels may be influenced by COVID-19 itself and also subject to confounding factors. To identify circulating proteins influencing COVID-19 susceptibility and severity we undertook a large-scale two-sample Mendelian randomization (MR) study, since this study design can rapidly scan hundreds of circulating proteins and reduces bias due to confounding and reverse causation. We began by identifying the genetic determinants of 955 circulating proteins in up to 10,708 SARS-CoV-2 uninfected individuals, retaining only single nucleotide polymorphisms near the gene encoded by the circulating protein. We then undertook an MR study to estimate the effect of these proteins on COVID-19 susceptibility and severity using the Host Genetics Initiative. We found that a standard deviation increase in OAS1 levels was associated with reduced COVID-19 death or ventilation (N = 2,972 cases / 284,472 controls; OR = 0.48, P = 7x10-8), COVID-19 hospitalization (N = 6,492 / 1,012,809; OR = 0.60, P = 2x10-7) and COVID-19 susceptibility (N = 17,607 / 1,345,334; OR = 0.81, P = 6x10-5). Results were consistent despite multiple sensitivity analyses probing MR assumptions. OAS1 is an interferon-stimulated gene that promotes viral RNA degradation. Other potentially implicated proteins included IL10RB. Available medicines, such as interferon-beta-1b, increase OAS1 and could be explored for their effect on COVID-19 susceptibility and severity.", "filename": "2020.10.13.20212092v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212092 "}, {"title": "Genetics of Low Polygenic Risk Score Type 1 Diabetes Patients: rare variants in 22 novel loci", "abstract": "With polygenic risk score (PRS) for autoimmune type 1 diabetes (T1D), this study identified T1D cases with low T1D PRS and searched for susceptibility loci in these cases. Our hypothesis is that genetic effects (likely mediated by relatively rare genetic variants) of non-mainstream (or non-autoimmune) T1D might have been diluted in the previous studies on T1D cases in general. Two cohorts for the PRS modeling and testing respectively were included. The first cohort consisted of 3,356 T1D cases and 6,203 controls, and the independent second cohort consisted of 3,355 T1D cases and 6,203 controls. Cases with low T1D PRS were identified using PRSice-2 and compared to controls with low T1D PRS by genome-wide association (GWA) test. Twenty-six genetic loci with SNPs/SNVs associated with low PRS T1D at genome-wide significance (P\u22645.0xE-08) were identified, including 4 established T1D loci, as well as 22 novel loci represented by rare SNVs. For the 22 novel loci, 12 regions have been reported of association with obesity related traits by previous GWA studies. Five loci encoding long intergenic non-protein coding RNAs (lncRNA), two loci involved in N-linked glycosylation, two loci encoding GTPase activators, and two ciliopathy genes, are also highlighted in this study.", "filename": "2020.10.13.20211987v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211987 "}, {"title": "Association between early discontinuation of endocrine therapy and recurrence of breast cancer among premenopausal women in a Danish population-based cohort", "abstract": "Purpose: Premenopausal women diagnosed with estrogen receptor (ER) positive breast cancer are prescribed 5-10 years of endocrine therapy to prevent or delay recurrence. Many women who initiate endocrine therapy fail to complete the recommended course of treatment. In this study, we evaluated the association between early discontinuation of adjuvant endocrine therapy and breast cancer recurrence in a cohort of premenopausal women.\nPatients and Methods: We identified 4,503 premenopausal ER+ breast cancer patients who initiated adjuvant endocrine therapy and were registered in the Danish Breast Cancer Group clinical database (2002-2011). Women were excluded if they had a recurrence or were lost to follow-up less than 1.5 years after breast cancer surgery. Endocrine therapy was considered complete if the patient received at least 4.5 years of treatment or discontinued medication less than 6 months before recurrence. Exposure status was updated annually and modeled as a time-dependent variable. We accounted for baseline and time-varying confounders via time-varying weights, which we calculated from multivariable logistic regression models and included in regression models to estimate hazard ratios (HR) and accompanying 95% confidence intervals (CI) associating early discontinuation with breast cancer recurrence.\nResults: Over the course of follow-up, 1,001 (22%) women discontinued endocrine therapy. We observed 202 (20%) recurrences among those who discontinued endocrine therapy, and 388 (11%) among those who completed the recommended treatment. The multivariable-adjusted estimated rate of recurrence was higher in women who discontinued endocrine therapy relative to those who completed their treatment (HR=1.67, 95% CI 1.25, 2.14).  \nConclusion: These results highlight the importance of clinical follow-up and behavioral interventions that support persistence of adjuvant endocrine therapy to prevent breast cancer recurrence.", "filename": "2020.10.13.20212217v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212217 "}, {"title": "Mathematical Perspective of Covid-19 Pandemic: Disease Extinction Criteria in Deterministic and Stochastic Models", "abstract": "The world has been facing the biggest virological invasion in the form of Covid-19 pandemic since the beginning of the year 2020. In this paper, we consider a deterministic epidemic model of four compartments classified based on the health status of the populations of a given country to capture the disease progression. A stochastic extension of the deterministic model is further considered to capture the uncertainty or variation observed in the disease transmissibility. In the case of a deterministic system, the disease-free equilibrium will be globally asymptotically stable if the basic reproduction number is less than unity, otherwise, the disease persists. Using Lyapunov functional methods, we prove that the infected population of the stochastic system tends to zero exponentially almost surely if the basic reproduction number is less than unity. The stochastic system has no interior equilibrium, however, its asymptotic solution is shown to fluctuate around the endemic equilibrium of the deterministic system under some parametric restrictions, implying that the infection persists. A case study with the Covid-19 epidemic data of Spain is presented and various analytical results have been demonstrated. The epidemic curve in Spain clearly shows two waves of infection. The first wave was observed during March-April and the second wave started in the middle of July and not completed yet. A real-time basic reproduction number has been given to illustrate the epidemiological status of Spain throughout the study period. Estimated cumulative numbers of confirmed and death cases are 1,613,626 and 42,899, respectively, with case fatality rate 2.66 per cent till the deadly virus is eliminated from Spain.", "filename": "2020.10.12.20211201v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211201 "}, {"title": "Motiro: an unified non-supervised framework for statistical analysis of probe-based confocal laser endomicroscopy videos of colorectal mucosa", "abstract": "Objective: To present Motiro, an unified framework for non-supervised statistical analysis endomicroscopy videos of the colorectal mucosa.\nMaterials and Methods: We wrote an open-source Python wrapper using ImageJ software with OpenCV, Seaborn and NumPy libraries. It generates a mosaic from the video of the mucosa, evaluates morphometric properties of the crypts, their distribution, and return their statistics. Shannon entropy (and Hellinger distance) are used for quantifying variability (and comparing different mucosa).\nResults: The segmentation process applied to normal mucosa of pre(post)-neoadjuvant patient is presented along with the corresponding statistical analysis of morphometric parameters.\nDiscussion: Our analysis provides estimation of morphometric parameters consistent with available methods, is faster, and, additionally, provides statistical characterization of the mucosa morphometry. Motiro enables the analysis of large amounts of endomicroscopy videos for building a normal rectum features dataset to help on: detection of small variability; classification of post-neoadjuvant recovery; decision about surgical intervention necessity.", "filename": "2020.10.13.20209254v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20209254 "}, {"title": "Frequent testing regimen based on salivary samples for an effective COVID-19 containment strategy", "abstract": "Rapid and accurate diagnostic tests are essential for controlling the ongoing COVID-19 pandemic. Although the current gold standard involves testing of nasopharyngeal swabs specimens by nucleic acid amplification test, such as real-time reverse-transcription polymerase chain reaction (rRT-PCR) to detect the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), it presents several limitations that ultimately may translate into a bottleneck in the surveillance regimen. New strategies based on frequent testing using less invasive specimens are urgently needed for containment of the infection. Rapid antigen assay using saliva as a reliable alternative to nasopharyngeal swabs should be proposed as a valuable part of the overall testing strategy.", "filename": "2020.10.13.20210013v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20210013 "}, {"title": "Innate lymphoid cell composition associates with COVID-19 disease severity", "abstract": "Objectives: The role of innate lymphoid cells (ILCs) in coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), is unknown. Understanding the immune response in COVID-19 could contribute to unravel the pathogenesis and identification of treatment targets. To describe the phenotypic landscape of circulating ILCs in COVID-19 patients and to identify ILC phenotypes correlated to serum biomarkers, clinical markers, and laboratory parameters relevant in COVID-19.\n\nMethods: Blood samples collected from moderately (n=11) and severely ill (n=12) COVID-19 patients as well as healthy control donors (n=16), were analyzed with 18-parameter flow cytometry. Using supervised and unsupervised approaches, we examined the ILC activation status and homing profile. Clinical and laboratory parameters were obtained from all COVID-19 patients and serum biomarkers were analyzed with multiplex immunoassays. \n\nResults: ILCs were largely depleted from the circulation of COVID-19 patients compared with healthy controls. Remaining circulating ILCs from patients revealed increased frequencies of ILC2 in moderate COVID-19, with a concomitant decrease of ILC precursors (ILCp), as compared with controls. ILC2 and ILCp showed an activated phenotype with increased CD69 expression, whereas expression levels of the chemokine receptors CXCR3 and CCR4 were significantly altered in ILC2 and ILCp, and ILC1, respectively. The activated ILC profile of COVID-19 patients was associated with soluble inflammatory markers, while frequencies of ILC subsets were correlated with laboratory parameters that reflect the disease severity.\n\nConclusion: This study provides insights into the potential role of ILCs in immune responses against SARS-CoV-2, particularly linked to the severity of COVID-19.", "filename": "2020.10.13.20211367v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211367 "}, {"title": "Intra-operative Laxity Following Total Knee Arthroplasty is Highly Variable and Different Than Osteoarthritic and Normal Knees", "abstract": "Background: Achieving a stable joint is an important yet challenging part of total knee arthroplasty (TKA). Neither manual manipulation of the knee nor instrumented sensors biomechanically characterize knee laxity or objectively characterize how TKA changes the laxity of an osteoarthritic (OA) knee. Therefore, the purposes of this study were: 1) objectively characterize changes in knee laxity due to TKA, 2) objectively determine whether TKA resulted in equal amounts of varus-valgus motion under a given load (i.e., balance) and 3) determine how TKA knee laxity and balance differ from values seen in non-osteoarthritic knees.\nMethods:Two surgeons used a custom navigation system and intra-operative device to record varus-valgus motion under quantified loads in a cohort of 31 patients (34 knees ) undergoing primary TKA. Similar data previously were collected from a cohort of 42 native cadaveric knees.\nResults: Performing a TKA resulted in a \"looser knee\" on average, but great variability existed within and between surgeons. Under the maximum applied moment, 20 knees were \"looser\" in the varus-valgus direction, while 14 were \"tighter\". Surgeon 1 generally \"loosened\" knees (OA laxity 6.1\u00b0\u00b12.3\u00b0, TKA laxity 10.1\u00b0\u00b13.6\u00b0), while Surgeon 2 did not substantially alter knee laxity  (OA laxity 8.2\u00b0\u00b12.4\u00b0, TKA laxity 7.5\u00b0\u00b13.3\u00b0). TKA resulted in balanced knees, and, while several differences in laxity were observed between OA, TKA, and cadaveric knees, balance was only different under the maximum load between OA and cadaveric knees.\nConclusions:  Large variability exists within and between surgeons suggests in what is considered acceptable laxity and balance of the TKA knee when it is assessed by only manual manipulation of the leg. Knees were \"balanced\" yet displayed different amounts of motion under applied load.\nClinical Relevance: Our results suggest that current assessments of knee laxity may leave different patients with biomechanically different knees. Objective intra-operative measurements should inform surgical technique to ensure consistency across different patients.", "filename": "2020.10.13.20212159v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212159 "}, {"title": "Methods for detection of clusters of observations with an outlying correlation coefficient value", "abstract": "Multivariate datasets with a clustered structure are the natural framework for, e.g., multicentre clinical trials. We propose a number of methods aimed at detecting clusters with outlying correlation coefficients. While the methods can be used in a variety of settings, we focus mainly on their application to central statistical monitoring of clinical trials. In particular, we consider the issue of detecting centers (or other clusters of patients such as regions) with outlying correlation coefficients for bivariate data in a multicenter clinical trial. It appears that, in that context, the proposed methods perform well, as we show by using a simulation study and a number of real life datasets.", "filename": "2020.10.12.20211128v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211128 "}, {"title": "A pilot study of discovery and validation of peritoneal endometriosis biomarkers in peritoneal fluid and serum", "abstract": "Objective: To identify potential serum biomarkers in women with peritoneal endometriosis (PE) by first looking at its source in the peritoneal fluid (PF).  \nDesign: Case-control pilot studies, comprising independent discovery and validation sets.\nSetting: KK Women\u2032s and Children\u2032s Hospital, Singapore.\nPatient(s): Women with laparoscopically confirmed PE and absence of endometriosis (control). \nIntervention(s): None.\nMain Outcome Measure(s): In the discovery set, we used untargeted liquid chromatography-mass spectrometry (LC-MS/MS) metabolomics, multivariable and univariable analyses to generate global metabolomic profiles of PF for endometriosis and to identify potential metabolites that could distinguish PE (n=10) from controls (n=31). Using targeted metabolomics, we validated the identified metabolites in PF and sera of cases (n=16 PE) and controls (n=19). We performed the area under the receiver-operating characteristics curve (AUC) analysis to evaluate the diagnostic performance of PE metabolites.\nResult(s): In the discovery set, PF phosphatidylcholine (34:3) and phenylalanyl-isoleucine were significantly increased in PE than controls groups, with AUC 0.77 (95% confidence interval 0.61-0.92; p=0.018) and AUC 0.98 (0.95-1.02; p<0.001), respectively. In the validation set, phenylalanyl-isoleucine retained discriminatory performance to distinguish PE from controls in both PF (AUC 0.77; 0.61-0.92; p=0.006) and serum samples (AUC 0.81; 0.64-0.99; p=0.004).\nConclusion(s): Our preliminary results propose phenylalanyl-isoleucine as a potential biomarker of PE, which may be used as a minimally-invasive diagnostic biomarker of PE.", "filename": "2020.10.13.20211789v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211789 "}, {"title": "Validation of a Derived International Patient Severity Phenotype to Support COVID-19 Analytics from Electronic Health Record Data", "abstract": "Introduction. The Consortium for Clinical Characterization of COVID-19 by EHR (4CE) includes hundreds of hospitals internationally using a federated computational approach to COVID-19 research using the EHR.\n\nObjective. We sought to develop and validate a standard definition of COVID-19 severity from readily accessible EHR data across the Consortium. \n\nMethods. We developed an EHR-based severity algorithm and validated it on patient hospitalization data from 12 4CE clinical sites against the outcomes of ICU admission and/or death. We also used a machine learning approach to compare selected predictors of severity to the 4CE algorithm at one site.\n\nResults. The 4CE severity algorithm performed with pooled sensitivity of 0.73 and specificity 0.83 for the combined outcome of ICU admission and/or death.  The sensitivity of single code categories for acuity were unacceptably inaccurate - varying by up to 0.65 across sites. A multivariate machine learning approach identified codes resulting in mean AUC 0.956 (95% CI: 0.952, 0.959) compared to 0.903 (95% CI: 0.886, 0.921) using expert-derived codes. Billing codes were poor proxies of ICU admission, with 49% precision and recall compared against chart review at one partner institution.\n\nDiscussion. We developed a proxy measure of severity that proved resilient to coding variability internationally by using a set of 6 code classes.  In contrast, machine-learning approaches may tend to overfit hospital-specific orders.  Manual chart review revealed discrepancies even in the gold standard outcomes, possibly due to pandemic conditions.\n\nConclusion. We developed an EHR-based algorithm for COVID-19 severity and validated it at 12 international sites.", "filename": "2020.10.13.20201855v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20201855 "}, {"title": "Clinical characteristics, symptoms, management and health outcomes in 8,598 pregnant women diagnosed with COVID-19 compared to 27,510 with seasonal influenza in France, Spain and the US: a network cohort analysis", "abstract": "OBJECTIVES: To describe comorbidities, symptoms at presentation, medication use, and 30-day outcomes after a diagnosis of COVID-19 in pregnant women, in comparison to pregnant women with influenza.\n\nDESIGN: Multinational network cohort \n\nSETTING: A total of 6 databases consisting of electronic medical records and claims data from France, Spain, and the United States.\n\nPARTICIPANTS: Pregnant women with \u2265 1 year in contributing databases, diagnosed and/or tested positive, or hospitalized with COVID-19. The influenza cohort was derived from the 2017-2018 influenza season. \n\nOUTCOMES: Baseline patient characteristics, comorbidities and presenting symptoms; 30-day inpatient drug utilization, maternal complications and pregnancy-related outcomes following diagnosis/hospitalization.\n\nRESULTS: 8,598 women diagnosed (2,031 hospitalized) with COVID-19 were included. Hospitalized women had, compared to those diagnosed, a higher prevalence of pre-existing comorbidities including renal impairment (2.2% diagnosed vs 5.1% hospitalized) and anemia (15.5% diagnosed vs 21.3% hospitalized). \n\nThe ten most common inpatient treatments were systemic corticosteroids (29.6%), enoxaparin (24.0%), immunoglobulins (21.4%), famotidine (20.9%), azithromycin (18.1%), heparin (15.8%), ceftriaxone (7.9%), aspirin (7.0%), hydroxychloroquine (5.4%) and amoxicillin (3.5%).\n\nCompared to 27,510 women with influenza, dyspnea and anosmia were more prevalent in those with COVID-19. Women with COVID-19 had higher frequency of cesarean-section (4.4% vs 3.1%), preterm delivery (0.9% vs 0.5%), and poorer maternal outcomes: pneumonia (12.0% vs 2.7%), ARDS (4.0% vs 0.3%) and sepsis (2.1% vs 0.7%). COVID-19 fatality was negligible (N<5 in each database respectively).\n\nCONCLUSIONS: Comorbidities that were more prevalent with COVID-19 hospitalization (compared to COVID-19 diagnosed) in pregnancy included renal impairment and anemia. Multiple medications were used to treat pregnant women hospitalized with COVID-19, some with little evidence of benefit. Anosmia and dyspnea were indicative symptoms of COVID-19 in pregnancy compared to influenza, and may aid differential diagnosis. Despite low fatality, pregnancy and maternal outcomes were worse in COVID-19 than influenza.", "filename": "2020.10.13.20211821v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211821 "}, {"title": "Persistent symptoms after Covid-19: qualitative study of 114 long Covid patients and draft quality criteria for services", "abstract": "Background\nApproximately 10% of patients with Covid-19 experience symptoms beyond 3-4 weeks. Patients call this long Covid. We sought to document the lived experience of such patients, their accounts of accessing and receiving healthcare, and their ideas for improving services.\n\nMethod\nWe held 55 individual interviews and 8 focus groups (n = 59) with people recruited from UK-based long Covid patient support groups, social media and snowballing. We restricted some focus groups to health professionals since they had already self-organised into online communities. Participants were invited to tell their personal stories and comment on other stories. Data were audiotaped, transcribed, anonymised and coded using NVIVO. Analysis incorporated sociological theories of illness, healing, peer support, the clinical relationship, access to care, and service redesign. \n\nResults \nThe sample was 70% female, aged 27-73 years, and comprised White British (74%), Asian (11%), White Other (7%), Black (4%), and Mixed (4%). 27 were doctors and 23 other health professionals. Approximately 10% had been hospitalised. Analysis revealed a confusing illness with many, varied and often relapsing-remitting symptoms and uncertain prognosis; a heavy sense of loss and stigma; difficulty accessing and navigating services; difficulty being taken seriously and achieving a diagnosis; disjointed and siloed care (including inability to access specialist services); variation in standards (e.g. inconsistent criteria for seeing, investigating and referring patients); variable quality of the therapeutic relationship (some participants felt well supported while others described feeling fobbed off); and possible critical events (e.g. deterioration after being unable to access services).  Emotional touch points in participant experiences informed ideas for improving services.\n\nConclusion\nQuality principles for a long Covid service should include ensuring access to care, reducing burden of illness, taking clinical responsibility and providing continuity of care, multi-disciplinary rehabilitation, evidence-based investigation and management, and further development of the knowledge base and clinical services.", "filename": "2020.10.13.20211854v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211854 "}, {"title": "A comparative study of infection and mortality in COVID-19 across countries: A scaling analysis", "abstract": "Analysing infection and mortality data for COVID-19 as a function of days for 54 countries across all continents, we show that there is a simple scaling behaviour connecting these two quantities for any given nation when the data is segmented over few ranges of dates covering the most rapid spread of the pandemic and the recovery, wherever achieved. This scaling is described by two parameters, one representing a shift along the time axis and the other is a normalisation factor, providing a reliable definition of the mortality rate for each country in a given period. The number of segments for any country required in our analyses turns out to be surprisingly few with as many as 16 out of 54 countries being described by a single segment and no country requiring more than three segments. Estimates of the shift and mortality for these 54 countries in different periods show large spreads ranging over 0-16 days and 0.45-19.96%, respectively. Shift and mortality are found to be inversely correlated. Analyses of number of tests carried out for detecting COVID-19 and the number of infections detected due to such tests suggest that an effective way to increase the shift, and therefore, decrease mortality, is to increase number of tests per infection detected. This points to the need of a dynamic management of testing that should accelerate with the rise of the pandemic; it also suggests a basis for adjusting variations in the testing patterns in different geographical locations within a given country.", "filename": "2020.10.13.20212175v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212175 "}, {"title": "Frontline healthcare workers' experiences with personal protective equipment during the COVID-19 pandemic in the UK: a rapid qualitative appraisal", "abstract": "Objectives \nTo report frontline healthcare workers' (HCWs) experiences with personal protective equipment (PPE) during the COVID-19 pandemic in the UK. To understand HCWs' fears and concerns surrounding PPE, their experiences following its guidance and how these affected their perceived ability to deliver care during the COVID-19 pandemic. \n\nMethods\nA rapid qualitative appraisal study combining three sources of data: semi-structured in-depth telephone interviews with frontline HCWs (n=46), media reports (n=39 newspaper articles and 145,000 social media posts) and government PPE policies (n=25). HCWs interviewed were from secondary care, primary care and specialist community clinics. Media and policy data were from across the UK. \n\nResults\nA major concern was running out of PPE, putting HCWs and patients at risk of infection. Following national-level guidance was often not feasible when there were shortages, leading to re-use and improvisation of PPE. Frequently changing guidelines generated confusion and distrust. PPE was reserved for high-risk secondary care settings and this translated into HCWs outside these settings feeling inadequately protected. Participants were concerned about inequitable access to PPE for community, lower seniority, female and ethnic minority HCWs. Participants continued delivering care despite the physical discomfort, practical problems and communication barriers associated with PPE use.\nConclusion\nThis study found that frontline HCWs persisted in caring for their patients despite multiple challenges including inappropriate provision of PPE, inadequate training and inconsistent guidance. In order to effectively care for patients during the COVID-19 pandemic, frontline HCWs need appropriate provision of PPE, training in its use, as well as comprehensive and consistent guidance. These needs must be addressed in order to protect the health and well-being of the most valuable healthcare resource in the COVID-19 pandemic: our HCWs.", "filename": "2020.10.12.20211482v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211482 "}, {"title": "Countering the potential re-emergence of a deadly infectious disease - information warfare, identifying strategic threats, launching countermeasures", "abstract": "Eradicated infectious diseases like smallpox can re-emerge through accident or designs of bioterrorists, and perpetrate heavy casualties. Currently, only a small percentage of the populace is vaccinated, and their protection is likely to have waned. Most therefore are susceptible today. And when the disease re-emerges the susceptible individuals may be manipulated by disinformation on Social Media to refuse vaccines. Thus, a combination of countermeasures consisting of antiviral drugs and vaccines and a range of policies for their application need to be investigated. Opinions as to receptivity of vaccines evolve with time through social exchanges over networks that overlap with but are not identical to the disease propagation networks. These couple the spread of the biological and information contagion and necessitate a joint investigation of the two. Towards these, we develop a computationally tractable metapopulation epidemiological model that captures the joint spatio-temporal evolution of smallpox and opinion dynamics. The computations based on the model show that opinion dynamics has a substantial impact on the fatality count. Towards understanding how perpetrators are likely to seed the infection we identify a) the initial distribution of infected individuals that maximize the overall fatality count regardless of mobility patterns, and b) which habitation structures are more vulnerable to outbreaks. We assess the relative efficacy of different countermeasures and conclude that a combination of vaccines and drugs minimizes the fatalities, and by itself, for smallpox, drugs reduce fatalities more than the vaccine. Accordingly, we assess the efficacies of three separate policies for administering the drugs and identify the best among them for various parameter combinations. When the availability of the drug is finite, we show that increase in its supply substantially reduces the overall fatality. Our findings lead to policy recommendations for public health and urban design authorities towards thwarting smallpox and other infectious disease outbreaks.", "filename": "2020.10.13.20211680v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211680 "}, {"title": "Whole genome sequencing delineates regulatory and novel genic variants in childhood cardiomyopathy", "abstract": "Cardiomyopathy (CMP) is a heritable genetic disorder. Protein-coding variants account for 20 to 30 percent of cases. The contribution of variants in noncoding DNA elements that regulate gene expression has not been explored. We performed whole genome sequencing (WGS) of 228 unrelated CMP families. Besides pathogenic protein coding variants in known CMP genes, 5% cases harbored rare loss of function variants in novel cardiac genes, with NRAP and FHOD3 being strong candidates. WGS also revealed a high burden of high risk variants in promoters and enhancers of CMP genes in an additional 20 percent cases (Odds ratio 2.14, 95 percent CI 1.60-2.86, p equals 5.26E-07 vs 1326 controls) with genes involved in alpha-dystroglycan glycosylation (FKTN, DTNA) and desmosomal signaling (DSC2, DSG2) specifically enriched for regulatory variants (False discovery rate less than 0.03). These findings were independently replicated in the Genomics England CMP cohort (n=1266). The functional effect of non-coding variants on transcription was functionally validated in patient myocardium and reporter assays in human cardiomyocytes, and that of novel gene variants in zebrafish knockouts. Our results show that functionally active variants in novel genes and in regulatory elements of CMP genes contribute strongly to the genomic etiology of childhood-onset CMP.", "filename": "2020.10.12.20211474v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211474 "}, {"title": "A delayed modulation of solar radiation on the COVID-19 transmission reflects an incubation period", "abstract": "Laboratory experiments have revealed the meteorological sensitivity of the virus of the coronavirus disease 2019 (COVID-19). However, no consensus has been reached about how the meteorological conditions modulate the virus transmission as it is constrained more often by non-meteorological factors. Here, we find that the non-meteorological factors constrain statistically-least the growth rate of cumulative confirmed cases in a country when the cases arrive around 2500-3000. The least-constrained growth rate correlates with the near-surface ultraviolet flux and temperature significantly (correlation coefficients r=-0.55\u00b10.08 and -0.45\u00b10.08 at p 10-5, respectively). In response to increases of 1W/m2 ultraviolet and 1\u00b0C temperature, the growth rate decreases by 0.33\u00b1.11%  and 0.18\u00b1.08% per day, respectively. The response to the ultraviolet flux exhibits a delay by about 7 days, providing an independent measure of the incubation period. Our quantifications imply a seasonality of COVID-19 and a high risk of a pandemic resurgence in the upcoming boreal winter, suggesting a need for seasonal adaption in public policies.", "filename": "2020.10.13.20183111v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20183111 "}, {"title": "Healthcare workers with mild / asymptomatic SARS-CoV-2 infection show T cell responses and neutralising antibodies after the first wave", "abstract": "Studies of adaptive immunity to SARS-CoV-2 include characterisation of lethal, severe and mild cases. Understanding how long immunity lasts in people who have had mild or asymptomatic infection is crucial. Healthcare worker (HCW) cohorts exposed to and infected by SARS-CoV-2 during the early stages of the pandemic are an invaluable resource to study this question. The UK COVIDsortium is a longitudinal, London hospital HCW cohort, followed from the time of UK lockdown; weekly PCR, serology and symptom diaries allowed capture of asymptomatic infection around the time of onset, so duration of immunity could be tracked. Here, we conduct a cross-sectional, case-control, sub-study of 136 HCW at 16-18 weeks after UK lockdown, with 76 having had laboratory-confirmed SARS-CoV-2 mild or asymptomatic infection. Neutralising antibodies (nAb) were present in 90% of infected HCW sampled after the first wave; titres, likely to correlate with functional protection, were present in 66% at 16-18 weeks. T cell responses tended to be lower in asymptomatic infected HCW than those reporting case-definition symptoms of COVID-19, while nAb titres were maintained irrespective of symptoms. T cell and antibody responses were discordant. HCW lacking nAb also showed undetectable T cells to Spike protein but had T cells of other specificities. Our findings suggest that the majority of HCW with mild or asymptomatic SARS-CoV-2 infection carry nAb complemented by multi-specific T cell responses for at least 4 months after mild or asymptomatic SARS-CoV-2 infection.", "filename": "2020.10.13.20211763v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211763 "}, {"title": "Is there a resistance-threshold for macrolide consumption? Positive evidence from an ecological analysis of resistance data from Streptococcus pneumoniae, Treponema pallidum and Mycoplasma genitalium", "abstract": "Abstract\n\nBackground\nIf we were to keep macrolide consumption below a certain threshold, would this reduce the probability of macrolide resistance emerging? No study that we are aware of has addressed this question.\n\nMethods\nWe assessed at a country level if there was a macrolide consumption threshold for the selection of a prevalence of macrolide resistance of over 5% in Streptococcus pneumoniae, Treponema pallidum and Mycoplasma genitalium.   \n\nResults\nWe found evidence for a macrolide consumption threshold of 1.3 defined daily doses per 1000 inhabitants per day (DID) for M. genitalium, 1.8 DID for T. pallidum and 2.3 DID for S. pneumoniae.   \n\nConclusions\nOur results provide further motivation for macrolide stewardship campaigns that strive to reduce macrolide consumption to levels below at least 2 DID.", "filename": "2020.10.13.20212043v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212043 "}, {"title": "Return to University Campuses Associated with 9% Increase in New COVID-19 Case Rate", "abstract": "The vast majority of colleges and universities across the United States are bringing students back for in-person instruction in the midst of the COVID-19 pandemic, despite the absence of an effective vaccine or other anti-viral therapeutic treatment. Using data from the New York Times and the American Community Survey, we assess the effect of this return to campus on viral case growth in counties with a significant college student population (what we term college counties) relative to non-college counties. We find a significant surge of 9% in new cases in a 21-day time frame in college counties, a finding consistent across U.S. Census divisions. These results suggest the need for institutions of higher education and the communities where these institutions reside work together quickly and effectively to mitigate viral transmission and to prevent overwhelming local healthcare infrastructure in college counties.", "filename": "2020.10.13.20212183v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212183 "}, {"title": "Epidemiologial Analysis of Patients Presenting to a West London District General Hospital Requiring Admission with Covid-19", "abstract": "Background: Coronavirus has lead to significant morbidity and mortality both within the UK and worldwide. We hypothesise there are local clusters of coronavirus which would therefore be amenable to targeted public health measures.  \nMethods: This is a retrospective, observational case series conducted in a West London District General Hospital. All patients admitted to hospital with a radiological or microbiological diagnosis of Covid-19 were included (children under 16 years were excluded). Consecutive sampling was used and baseline characteristics including age, sex, postcode and final patient outcome were collected from the electronic health records. Patient origin postcode was plotted to a map of the local area and an online cloud based mapping analysis system was used to generate heat maps and case density maps which were compared to living base layers. The primary outcome was identification of local clusters of cases of coronavirus. Secondary outcome was identification of population characteristics that may provide evidence for more targetted public health intervention in a second wave. \nResults: Local clusters of infection were identified within the target population. These appeared to correlate with higher indices of deprivation, poorer overall health and high household occupancy suggesting a role for public health measures to target these areas.\nConclusion: There is a role for targeted public health measures in tackling the spread of coronavirus, paying particular attention to those who live in more deprived areas.", "filename": "2020.10.13.20212126v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212126 "}, {"title": "Does autism protect against COVID quarantine effects?", "abstract": "Introduction: COVID-19 outbreak has imposed an eight-week confinement in France. During this period, children and their families were exposed to a full-time home life. The aim of this study was to assess the emotional experience and tolerance of children with autism spectrum disorder (ASD) in this particular context. \nMethod: A clinical survey was proposed to parents and rated by professionals once a week during the quarantine period in France. 95 autistic children followed by the child and adolescent psychiatry department of Tours university hospital were assessed from the 18th of March to the 8th of May. The following clinical points were investigated: child anxiety, family anxiety, behavior problems, impact on sleep, impact on appetite, impact on school work, family tension, confinement intolerance, difficulties to follow a schedule, isolation behavior. \nResults: Despite minor changes in family anxiety and school work, no difference was highlighted between clinical scores collected at the beginning and at the end of this period. ASD children with or without intellectual disability had non-significant clinical changes during quarantine. This evolution was also independent of the accommodation type (house or apartment) and the parental status (relationship, separated or isolated). \nConclusion: The sameness dimension in autism and parents adaptation may be involved in this clinical stability during COVID confinement. Moreover, specialized tools and support provided by professionals could have participated to these outcomes and must be regularly promoted in order to help families in this still difficult period.", "filename": "2020.10.13.20212118v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20212118 "}, {"title": "What is the evidence for transmission of COVID-19 by children in schools? A living systematic review", "abstract": "ABSTRACT\n\nBackground: It is of paramount importance to understand the transmission of SARS-CoV-2 in schools, which could support the decision-making about educational facilities closure or re-opening with effective prevention and control measures in place.\n\nMethods: We conducted a systematic review and meta-analysis to investigate the extent of SARS-CoV-2 transmission in schools. We performed risk of bias evaluation of all included studies using the Newcastle- Ottawa Scale (NOS).\n\nResults: 2,178 articles were retrieved and 11 studies were included. Five cohort studies reported a combined 22 student and 21 staff index cases that exposed 3,345 contacts with 18 transmissions [overall infection attack rate (IAR): 0.08% (95% CI: 0.00%-0.86%)]. IARs for students and school staff were 0.15% (95% CI: 0.00%-0.93%) and 0.70% (95% CI: 0.00%-3.56%) respectively. Six cross-sectional studies reported 639 SARS-CoV-2 positive cases in 6,682 study participants tested [overall SARS-CoV-2 positivity rate: 8.00% (95% CI: 2.17%-16.95%)]. SARS-CoV-2 positivity rate was estimated to be 8.74% (95% CI: 2.34%-18.53%) among students, compared to 13.68% (95% CI: 1.68%-33.89%) among school staff. Gender differences were not found for secondary infection (OR: 1.44, 95% CI: 0.50-4.14, P= 0.49) and SARS-CoV-2 positivity (OR: 0.90, 95% CI: 0.72-1.13, P= 0.36) in schools. Fever, cough, dyspnea, ageusia, anosmia, rhinitis, sore throat, headache, myalgia, asthenia, and diarrhoea were all associated with the detection of SARS-CoV-2 antibodies (based on two studies). Overall, study quality was judged to be poor with risk of performance and attrition bias, limiting the confidence in the results.\n\nConclusions: There is limited high-quality evidence available to quantify the extent of SARS-CoV-2 transmission in schools or to compare it to community transmission. Emerging evidence suggests lower IAR and SARS-CoV-2 positivity rate in students compared to school staff. Future prospective and adequately controlled cohort studies are necessary to confirm this finding.", "filename": "2020.10.11.20210658v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210658 "}, {"title": "Measurement of small droplet aerosol concentrations in public spaces using handheld particle counters", "abstract": "We investigate the role of aerosols in the transmission of SARS-CoV-2 in public spaces. Direct measurement of aerosol concentrations however has proven technically difficult; we propose the use of handheld particle counters as a novel and easily applicable method to measure aerosol concentrations. This allow us to perform measurements in typical public spaces, each differing in volume, number of people and ventilation rate. These data are used to estimate the relation between aerosol persistence time and the risk of infection with SARS-CoV-2.", "filename": "2020.10.13.20211839v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211839 "}, {"title": "Systematic analysis of electronic health records identifies drugs reducing risk of COVID-19 hospitalization and severity", "abstract": "Background\nSARS-Cov-2 is a new virus causing a pandemic of primarily respiratory illness designated as Coronavirus Disease 2019 (COVID-19). This disease is associated with excess mortality, particularly among the elderly, raising concerns for public health. It is crucial to identify whether existing medications could protect against adverse outcomes of COVID-19 infection.\nMethods\nWe performed a population-based study among members of Clalit Health Services (CHS), the largest healthcare provider in Israel. CHS centrally manages electronic health records (EHR) including medication purchases for over 4.5 million insurees. Since the disease outbreak through October 10, 2020, 8,681 adult patients aged between 18 and 95 have been hospitalized for COVID-19, among them 3,777 in severe condition. Two case-control matched cohorts were assembled to assess which drugs taken by patients in the month preceding a SARS-CoV-2 positive test affected risks of COVID-19 hospitalization and disease severity. Significance of the associations was assessed using Fisher's exact test and Benjamini-Hochberg correction for multiple testing.\nFindings\nWe identified several drugs and products sold in pharmacies that are significantly associated with reduced odds ratios of SARS-CoV-2 hospitalization and disease severity: notably ubiquinone (OR:0.25, p<0.001), ezetimibe (OR=0.51, P<0.001), rosuvastatin (OR=0.75, p<0.001) and flecainide (OR=0.30, p<0.01). Additionally, acquisition of surgical masks, latex gloves and several ophthalmological products, including eye wipes were associated with decreased risk for hospitalization. \nInterpretation\nUbiquinone, ezetimibe and rosuvastatin, all related to the cholesterol synthesis pathway, are associated with a protective effect against COVID-19 complications. These medications are associated with reduced hospitalization rate and decreased severity in hospitalized patients. These findings set the basis for specific prospective randomized control trials that should be carried out to carefully assess their protective effects.", "filename": "2020.10.13.20211953v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211953 "}, {"title": "Background and concurrent factors predicting non-adherence to public health preventive measures during the chronic phase of the COVID-19 pandemic", "abstract": "To determine factors that predict non-adherence to preventive measures for COVID-19 during the chronic phase of the pandemic, a cross-sectional, general population survey was conducted in Israel. Sociodemographic, health-related, behavioral, and COVID-19-related characteristics were collected. Among 2055 participants, non-adherence was associated with male gender, young age, bachelorhood, being employed, lower decrease in income, low physical activity, psychological distress, ADHD symptoms, past risk-taking and anti-social behavior, low pro-sociality, perceived social norms favoring non-adherence, low perceived risk of COVID-19, low perceived efficacy of the preventive measures, and high perceived costs of adherence to the preventive measures. There appears to be a need for setting out and communicating preventive measures to specifically targeted at-risk populations.", "filename": "2020.10.13.20211904v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211904 "}, {"title": "Prone positioning of non-intubated patients with COVID-19 - A Systematic Review and Meta-analysis", "abstract": "Purpose: Several studies have reported adopting prone positioning (PP) in non-intubated patients with COVID-19-related hypoxaemic respiratory failure. This systematic review and meta-analysis evaluated the impact of PP on oxygenation and clinical outcomes.\nMethods: We searched PubMed, Embase and COVID-19 living systematic review from December1st 2019 to July23rd 2020. We included studies that reported using PP in hypoxaemic, non-intubated adult COVID-19 patients. Primary outcome measure was the weighted mean difference (MD) in oxygenation parameters (PaO2/FiO2, PaO2 or SpO2) pre and post-PP.\nResults: Fifteen single arm observational studies reporting PP in 449 patients were included. Substantial heterogeneity was noted in terms of, location within hospital where PP was instituted, respiratory supports, frequency and duration of PP. Significant improvement in oxygenation was reported post-PP: PaO2/FiO2, (MD 37.6, 95%CI 18.8, 56.5); PaO2, , (MD 30.4 mmHg, 95%CI 10.9, 49.9); and SpO2, (MD 5.8%, 95%CI 3.7, 7.9). Patients with a pre-PP PaO2/FiO2 \u2264150 experienced greater oxygenation improvements compared with those with a pre-PP PaO2/FiO2 >150 (MD 40.5, 95%CI -3.5, 84.6) vs. 37, 95%CI 17.1, 56.9). Respiratory rate decreased post-PP (MD -2.9, 95%CI -5.4, -0.4). Overall intubation and mortality rates were 21% (90/426) and 26% (101/390) respectively. No major adverse events were reported. \nConclusions: Despite significant variability in frequency and duration of PP and respiratory supports, PP was associated with improvements in oxygenation parameters without any reported serious adverse events. Major limitation being lack of control arm and adjustment for confounders. Clinical trials are required to determine the effect of awake PP on patient-centred outcomes.", "filename": "2020.10.12.20211748v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211748 "}, {"title": "Symptom-based testing in a compartmental model of COVID-19", "abstract": "Testing and isolation of cases is an  important component of our strategies to fight SARS-CoV-2. In this work, we consider a compartmental model for COVID-19 including a nonlinear term representing symptom-based testing. We analyze how the considered clinical spectrum of symptoms and the testing rate affect the outcome and the severity of the outbreak.", "filename": "2020.10.11.20211037v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20211037 "}, {"title": "Precautionary breaks: planned, limited duration circuit breaks to control the prevalence of COVID-19", "abstract": "The  COVID-19  pandemic  in  the  UK  has  been  characterised  by  periods  of  exponential  growth  and decline, as different non-pharmaceutical interventions (NPIs) are brought into play.  During the early uncontrolled phase of the outbreak (early March 2020) there was a period of prolonged exponential growth with epidemiological observations such as hospitalisation doubling every 3-4 days (growth rate r\u22480.2).   The  enforcement  of  strict  lockdown  measures  led  to  a  noticeable  decline  in  all  epidemic quantities (r\u2248-0.06) that slowed during the summer as control measures were relaxed (r\u2248-0.02). Since August, infections, hospitalisations and deaths have been rising (precise estimation of the cur-rent  growth  rate  is  difficult  due  to  extreme  regional  heterogeneity  and  temporal  lags  between  the different epidemiological observations) and various NPIs have been applied locally throughout the UK in response.\n\nControlling any rise in infection is a compromise between public health and societal costs, with more stringent NPIs reducing cases but damaging the economy and restricting freedoms.  Currently, NPI imposition  is  made  in  response  to  the  epidemiological  state,  are  of  indefinite  length  and  are  often imposed at short notice, greatly increasing the negative impact.  An alternative approach is to consider planned, limited duration periods of strict NPIs aiming to purposefully reduce prevalence before such emergency NPIs are required.  These 'precautionary breaks' may offer a means of keeping control of the epidemic, while their fixed duration and the forewarning may limit their society impact. Here, using simple analysis and age-structured models matched to the unfolding UK epidemic, we investigate the action of precautionary breaks.  In particular we consider their impact on the prevalence of infection, as well as the total number of predicted hospitalisations and deaths.  We find that precautionary breaks provide the biggest gains when the growth rate is low, but offer a much needed brake on increasing infection when the growth rate is higher, potentially allowing other measures (such as contact tracing)to regain control.", "filename": "2020.10.13.20211813v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211813 "}, {"title": "The HIV/STI Epidemic Potential of Dynamic Sexual Networks of Men Who Have Sex With Men in Atlanta and San Francisco", "abstract": "Background: The potential speed through which a pathogen may circulate in a network is a function of network connectivity. Network features like degree (number of ongoing partnerships) determine the cross-sectional network connectivity. The overall transmission potential of a pathogen involves connectivity over time, which can be measured using the forward reachable path (FRP). We modeled dynamic sexual networks of MSM in San Francisco and Atlanta to estimate the FRP as a predictor of HIV/STI epidemic potential. Methods: We used exponential random graph models to obtain parameter estimates for each city's sexual network and then simulated the complete networks over time. The FRP was estimated in each city overall and stratified by demographics. Results: The overall mean and median FRPs were higher in San Francisco than in Atlanta, suggesting a greater epidemic potential for HIV and STIs in San Francisco. At one year, in both cities, the average FRP among casual partnerships was highest in the youngest age group and lowest in the oldest age group, contrasting with the cross-sectional network parameters we estimated, where the youngest age category had the lowest mean degree and the oldest age category had the highest mean degree. Conclusions: The FRP results correspond to the observed STI epidemics but not HIV epidemics between the cities. In San Francisco, rates of HIV have been declining over the last few years, whereas they have been steady in Atlanta. The FRP by age group resulted in fundamentally different conclusions about connectivity in the network compared with the cross-sectional network measures.", "filename": "2020.10.12.20211540v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211540 "}, {"title": "Automated chest radiograph diagnosis: A Twofer for tuberculosis and Covid-19", "abstract": "Coronavirus disease (Covid 19) and Tuberculosis (TB) are two challenges the world is facing. TB is a pandemic which has challenged mankind for ages and Covid 19 is a recent onset fast spreading pandemic. We study these two conditions with focus on Artificial Intelligence (AI) based imaging, the role of digital chest x-ray and utility of end to end platform to improve turnaround times. Using artificial intelligence assisted technology for triage and creation of structured radiology reports using an end to end platform can ensure quick diagnosis. Changing dynamics of TB screening in the times of Covid 19 pandemic have resulted in bottlenecks for TB diagnosis. The paper tries to outline two types of use cases, one is COVID-19 screening in a hospital-based scenario and the other is TB screening project in mobile van setting and discusses the learning of these models which have both used AI for prescreening and generating structured radiology reports.", "filename": "2020.10.13.20178483v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20178483 "}, {"title": "Preventing COVID-19 spread in closed facilities by regular testing of employees \u2013 an efficient intervention in long-term care facilities and prisons", "abstract": "Background: Draconic control measures were introduced to contain the global COVID-19 pandemic, many of which have been controversial, particularly the comprehensive use of diagnostic tests. Regular testing of high-risk individuals (pre-existing conditions, older than 60 years of age) has been suggested by public health authorities. The WHO suggested the use of routine screening of residents, employees, and visitors of long-term care facilities (LTCF) to protect the resident risk group. Similar suggestions have been made by the WHO for other closed facilities including incarceration facilities (e.g., prisons or jails), where in parts of the US, accelerated release of approved inmates is taken as a measure to mitigate COVID-19. Methods and findings:  Here, the simulation model underlying the pandemic preparedness tool CovidSim 1.1 (http://covidsim.eu/) is extended to investigate the effect of  regularly testing of employees in order to protect immobile resident risk groups in closed facilities. The reduction in the number of infections and deaths within the risk group are investigated as well as the potential economic gain resulting from savings in COVID-19 related treatment costs in comparison to costs resulting from the testing interventions. Our simulations are adjusted to reflect the situation of LTCFs in the Federal Republic of Germany. The probability is nearly one that COVID-19 spreads into closed facilities due to contact with infected employees even under strict confinement of visitors in a pandemic scenario without targeted protective measures. Regular screening of all employees by PCR tests provides a significant reduction of COVID-19 cases and related deaths in LTCFs. While the frequency of testing (testing rate) and the quality of tests have noticeable effects, the waiting time for obtaining test results (ranging from 12 up to 96 hours) hardly impacts the outcome. The results suggest that testing every two weeks with low-quality  tests and a processing time of up to 96 hours yields a strong reduction in the number of cases. Rough estimates suggest a significant economic gain. Conclusions: The introduction of COVID-19 in closed facilities is unavoidable without thorough screening of persons that can introduce the disease into the facility. These measures provide an economically meaningful way to protect vulnerable risk groups characterized by an elevated risk of severe infections in closed facilities, in which contact-reducing measures are difficult to implement due to imminent unavoidable close human-to-human contacts.", "filename": "2020.10.12.20211573v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211573 "}, {"title": "Use of antivirals and antibiotics for COVID-19 in Mexico City: A Real-World Multicenter Cohort Study", "abstract": "We aimed to characterize real-world use of antivirals and antibiotics in patients with COVID-19 and their associations with mortality. We conducted a real-world retrospective cohort study in 688 primary-to-tertiary medical units in Mexico City; 395,343 patients were evaluated for suspected COVID-19 between February 24 and September 14, 2020. All patients with a positive RT-PCR for SARS-CoV-2 (n=137,012) were included; those receiving unspecified antivirals (n=137), excluded, and groups of antivirals with <30 patients (n=20), eliminated. Survival and mortality risk analyses were done for patients receiving antivirals, antibiotics, both, or none (exposition groups). 136,855 patients were analyzed; mean age 44.2 (SD:16.8) years; 51.3% were men. 16.6% received an antiviral (3%), antibiotic (10%), or both (3.6%). More symptomatic patients received antivirals and antibiotics more often. Antivirals studied were Oseltamivir (n=8414), Amantadine (n=319), Lopinavir-Ritonavir (n=100), Rimantadine (n=61), Zanamivir (n=39), and Acyclovir (n=36). Survival with antivirals (73.7%, P<.001) and antibiotics (85.8%, P<.001) was lower than no antiviral/antibiotic (93.6%) in the general population. Increased risk of death was observed with antivirals in ambulatory (HR=4.7, 95%CI:3.94-5.62) and non-critical (HR=2.03, 95%CI:1.86-2.21) patients; no benefit in hospitalized and critical patients. Oseltamivir was associated with increased mortality in the general population (HR=1.72, 95%CI:1.61-1.84), ambulatory (HR=4.79, 95%CI:4.01-5.75), non-critical (HR=2.05, 95%CI:1.88-2.23), and pregnancy (HR=8.35, 95%CI:1.77-39.30). Antibiotics were a protective factor in hospitalized (HR=0.81, 95%CI:0.77-0.86) and critical patients (HR=0.67, 95%CI:0.63-0.72), but a risk factor in the general population (HR=1.13, 95%CI:1.08-1.19) and children and adolescents (HR=4.22, 95%CI:2.01-8.86). In conclusion, oseltamivir was associated with increased mortality or no benefit in all groups. Common antivirals for COVID-19 should be avoided. Antibiotics may increase survival in hospitalized and critical patients. Vaccination history and rapid differentiation of etiologic agent will be key to promptly initiate or avoid antivirals during the COVID-19-influenza season.", "filename": "2020.10.13.20211797v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211797 "}, {"title": "Genome-wide association study identifies five risk loci for pernicious anemia and implicates the role of HLA-DR15 haplotype", "abstract": "Pernicious anemia is a rare condition characterized by vitamin B12 deficiency anemia due to lack of intrinsic factor, often caused by autoimmune gastritis. Patients with pernicious anemia have a higher incidence of other autoimmune disorders, such as type 1 diabetes, vitiligo and autoimmune thyroid issues. Therefore, the disease has a clear autoimmune basis, although the genetic susceptibility factors have thus far remained poorly studied. We conducted a genome-wide association study meta-analysis in 2,166 cases and 659,516 European controls from population-based biobanks and identified genome-wide significant signals in or near the PTPN22 (rs6679677, p=1.91 x 10-24, OR=1.63), PNPT1 (rs12616502, p=3.14 x 10-8, OR=1.70), HLA-DQB1 (rs28414666, p=1.40 x 10-16, OR=1.38), IL2RA (rs2476491, p=1.90 x 10-8, OR=1.22) and AIRE (rs74203920, p=2.33 x 10-9, OR=1.83) genes, thus providing the first robust associations between pernicious anemia and genetic risk factors. We further mapped the susceptibility in the HLA region to the HLA-DR15 haplotype. Analysis of associated diagnoses and disease trajectories confirm the association between pernicious anemia and thyroid issues, vitiligo, gastritis, stomach cancer, osteoporosis and other diagnoses.", "filename": "2020.10.13.20211912v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211912 "}, {"title": "Tracking the Progression & Influence of Beta-Amyloid Plaques Using Percolation Centrality and Collective Influence Algorithm: A Study using PET images", "abstract": "Network analysis allows investigators to explore the many facets of brain networks, particularly the proliferation of disease using graph theory to model the disease movement. The disruption in brain networks in Alzheimer's disease (AD) is due to the abnormal accumulation of beta-amyloid plaques and tau protein tangles. In this study, the potential use of percolation centrality to study the movement of beta-amyloid plaques, as a feature of given PET image-based networks, is studied. The PET image-based network construction is possible using the public access database - Alzheimer's Disease Neuroimaging Initiative, which provided 1522 scans, of which 429 are of AD patients, 583 of patients with mild cognitive impairment, and 510 of cognitively normal. For each image, the Julich atlas provides 121 regions of interest/network nodes. Additionally, the influential nodes for each scan are calculated using the collective influence algorithm. Through this study, it is possible to use percolation centrality values to indicate the regions of interest that reflect the disease's spread and show potential use for early AD diagnosis. Analysis of variance (ANOVA) shows the regions of interest for which percolation centrality is a valid measure, irrespective of the tracer type. A multivariate linear regression between the percolation centrality values for each of the nodes and psychometric assessment scores reveals that models Mini-Mental State Examination (MMSE) scores performed better than ones with Neuropsychiatric Inventory Questionnaire (NPIQ) scores as the target variable. Similar to ANOVA, the multivariate linear regression yields regions of interest for which percolation centrality is a good differentiator. Finally, a ranking of the regions of interest is made based on the collective influence algorithm to indicate the anatomical areas strongly influencing the beta-amyloid network.", "filename": "2020.10.12.20211607v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211607 "}, {"title": "Nonspecific blood tests as proxies for COVID-19 hospitalization: are there plausible associations after excluding noisy predictors?", "abstract": "This study applied causal criteria in directed acyclic graphs for handling covariates in associations for prognosis of severe COVID-19 (Corona virus disease 19) cases. To identify nonspecific blood tests and risk factors as predictors of hospitalization due to COVID-19, one has to exclude noisy predictors by comparing the concordance statistics (AUC) for positive and negative cases of SARS-CoV-2 (acute respiratory syndrome coronavirus 2). Predictors with significant AUC at negative stratum should be either controlled for their confounders or eliminated (when confounders are unavailable). Models were classified according to the difference of AUC between strata. The framework was applied to an open database with 5644 patients from Hospital Israelita Albert Einstein in Brazil with SARS-CoV-2 RT-PCR (Reverse Transcription - Polymerase Chain Reaction) exam. C-reactive Protein (CRP) was a noisy predictor: hospitalization could have happen due to causes other than COVID-19 even when SARS-CoV-2 RT-PCR is positive and CRP is reactive, as most cases are asymptomatic to mild. Candidates of characteristic response from moderate to severe inflammation of COVID-19 were: combinations of eosinophils, monocytes and neutrophils, with age as risk factor; and creatinine, as risk factor, sharpens the odds ratio of the model with monocytes, neutrophils, and age.", "filename": "2020.10.12.20211557v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211557 "}, {"title": "Real World SOF/VEL/VOX Retreatment Outcomes and Viral Resistance Analysis for HCV Patients with Prior Failure to DAAs", "abstract": "Sustained viral response (SVR) rates to first-line Direct Acting Antiviral (DAA) therapy for hepatitis C virus (HCV) infection routinely exceed 95%. However, a small number of patients require retreatment. Sofosbuvir, velpatasvir and voxilaprevir (SOF/VEL/VOX) is a potent DAA combination primarily used for the retreatment of patients failed by first line DAA therapies.  Here we evaluate retreatment outcomes and the effects of resistance associated substitutions (RAS) in a real-world cohort, including the largest number of genotype (GT)3 infected patients, to date. 144 patients from the UK were retreated with SOF/VEL/VOX following virologic failure with first-line DAA treatment regimens. Full-length HCV genome, next-generation sequencing was performed prior to retreatment with SOF/VEL/VOX. HCV subtypes were assigned and RAS relevant to each genotype were identified (15% read cut-off). GT1a and GT3a were the two most common subtypes in the cohort, each making up 38% (GT1a n=55, GT3a n=54) of the cohort. 40% (n=58) of patients had liver cirrhosis of whom 7% (n=4) were decompensated, 10% (n=14) had hepatocellular carcinoma (HCC) and 8% (n=12) had received a liver transplant prior to retreatment. The overall re-treatment SVR12 rate was 90% (129/144). On univariate analysis, GT3 infection (50/62; SVR=81%, p=0.009), cirrhosis (47/58; SVR=81% , p=0.01) and prior treatment with SOF/VEL(12/17; SVR=71%, p=0.02) or SOF + DCV (14/19; SVR=74%, p=0.012) were all significantly associated with retreatment failure, but existence of pre retreatment RAS was not when the genotype of the virus is taken into account. The lower SVR rates achieved in patients retreated with SOF/VEL/VOX for patients with GT3 infection, cirrhosis and prior treatment with SOF/VEL or SOF/DCV has important implications for both patients and HCV elimination strategies.", "filename": "2020.10.13.20211862v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211862 "}, {"title": "Less severe course of COVID-19 is associated with elevated levels of antibodies against seasonal human coronaviruses OC43 and HKU1 (HCoV OC43, HCoV HKU1)", "abstract": "The clinical course of COVID-19 is very heterogeneous: Most infected individuals can be managed in an outpatient setting, but a substantial proportion of patients requires intensive care, resulting in a high rate of fatalities. Recently, an association between contact to small children and mild course of COVID-19 was reported. We performed an observational study to assess the impact of previous infections with seasonal coronaviruses on COVID-19 severity. 60 patients with confirmed COVID-19 infections were included (age 30 - 82 years; 52 males, 8 females): 19 inpatients with critical disease, 16 inpatients with severe or moderate disease and 25 outpatients (age and gender matched to inpatients). Patients with critical disease had significantly lower levels of HCoV OC43- (p=0.016) and HCoV HKU1-specific (p=0.023) antibodies at the first encounter compared to other COVID-19 patients. Our results indicate that previous infections with seasonal coronaviruses might protect against a severe course of disease. This finding should be validated in other settings and could contribute to identify persons at risk before an infection.", "filename": "2020.10.12.20211599v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211599 "}, {"title": "What Treatment Outcomes Matter Most? A Q-study of Outcome Priority Profiles Among Youth with Lived Experience of Depression", "abstract": "Objective: Over the past years, interest in youth perspectives on what constitutes an important outcome in the treatment of depression has been growing, but limited attention has been given to heterogeneity in outcome priorities and minority viewpoints. These are important to consider for person-centered outcome tracking in clinical practice, or when conducting clinical trials targeting specific populations. This study used Q-methodology to identify outcome priority profiles amongst youths with lived experience of service use for depression. \n\nMethod: A purposive sample of 28 youths (aged 16-21 years) rank-ordered 35 outcomes by importance and completed brief semi-structured interviews eliciting their sorting rationales. By-person principal component analysis was used to identify outcome priority profiles based on all Q-sort configurations. Priority profiles were described and interpreted with reference to the qualitative interview data.\n\nResults: Four distinct outcome priority profiles were identified: 'symptom reduction and enhanced well-being'; 'improved coping and self-management'; 'better understanding past and present'; and 'less interference with daily life'. All four profiles prioritized outcomes related to improved mood and affect over other outcome concepts. Beyond these core outcomes, profiles differed in the level of importance assigned to learning practical coping skills, processing experiences, finding safe ways to articulate emotions, and reduced interference of depression with life and identity.\n\nConclusion: As part of a person-centered approach to care delivery, care providers should routinely engage young people in conversation and shared decision-making about the types of change they would like to prioritize and track during treatment, beyond a common core of consensus outcomes.", "filename": "2020.10.12.20210468v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210468 "}, {"title": "Implementing a Telemedicine Curriculum for Internal Medicine Residents during a Pandemic: The Cleveland Clinic Experience", "abstract": "Introduction\nTelemedicine is an important element of healthcare. However, until the COVID-19 pandemic, training in telemedicine was not a substantial element of most residency programs. Social distancing measures changed this. The Cleveland Clinic Internal Medicine Residency Program (IMRP) is one of the largest programs in the United States, which made the task of developing and adopting an effective, expedited telemedicine curriculum challenging. Our goal was to implement a system for teaching telemedicine care skills and supervising the care provided by residents during virtual visits. \n\nStudy Design\nThis study was started in April 2020. We developed and implemented a resident-led curriculum and training program for providing telemedicine care in less than five weeks. This entailed creating a formal training program for residents, creating a resource guide for the different video communication tools, and training preceptors to safely supervise care in this new paradigm. We also created an assessment instrument in our education evaluation system that allows residents to receive feedback on their performance during virtual appointments.\n\nResults\nOver 2000 virtual visits were performed by residents in a span of 10 weeks. Of 148 residents, 38% responded to the pre-participation survey. A majority had no prior telemedicine experience and expressed only slight comfort with the modality. \n\nDiscussion\nThrough collaboration with experienced residents and faculty, we expeditiously developed an enhancement to our ambulatory care curriculum to teach residents how to provide virtual care and help faculty with supervision. We share our insights on this experience for other residency programs to utilize.", "filename": "2020.10.12.20211136v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211136 "}, {"title": "A Highly Generalizable Natural Language Processing Algorithm for the Diagnosis of Pulmonary Embolism from Radiology Reports", "abstract": "Though sophisticated algorithms have been developed for the classification of free-text radiology reports for pulmonary embolism (PE), their overall generalizability remains unvalidated given limitations in sample size and data homogeneity. We developed and validated a highly generalizable deep-learning based NLP algorithm for this purpose with data sourced from over 2,000 hospital sites and 500 radiologists. The algorithm achieved an AUCROC of 0.995 on chest angiography studies and 0.994 on non-angiography studies for the presence or absence of PE. The high accuracy achieved on this large and heterogeneous dataset allows for the possibility of application in large multi-center radiology practices as well as for deployment at novel sites without significant degradation in performance.", "filename": "2020.10.13.20211961v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211961 "}, {"title": "Funding and COVID-19 Research Priorities - Are the research needs for Africa being met?", "abstract": "Introduction\nEmerging data from Africa indicates remarkably low numbers of reported COVID-19 deaths despite high levels of disease transmission. However evolution of these trends as the pandemic progresses remains unknown. More certain are the devastating long-term impacts of the pandemic on health and development evident globally. Research tailored to the unique needs of African countries is crucial.\nUKCDR and GloPID-R have launched a tracker of funded COVID-19 projects mapped to the WHO research priorities and research priorities of Africa and less-resourced countries and published a baseline analysis of a Living Systematic Review (LSR) of these projects. \nMethods \nIn-depth analyses of the baseline LSR for COVID-19 funded research projects in Africa (as of 15th July 2020) to determine the funding landscape and alignment of the projects to research priorities of relevance to Africa. \nResults \nThe limited COVID-19 related research across Africa appears to be supported mainly by international funding, especially from Europe, although with notably limited funding from United States-based funders. At the time of this analysis no research projects funded by an African-based funder were identified in the tracker although there are several active funding calls geared at research in Africa and there may be funding data which has not been made publicly available.\nMany projects mapped to the WHO research priorities and 5 particular gaps in research funding were identified namely: investigating the role of children in COVID-19 transmission; effective modes of community engagement; health systems research; communication of uncertainties surrounding mother-to-child transmission of COVID-19; and identifying ways to promote international cooperation. Capacity strengthening was identified as a dominant theme in funded research project plans.\nConclusions\nWe found significantly lower funding investments in COVID-19 research in Africa compared to High-Income Countries, seven months into the pandemic, indicating a paucity of research targeting the research priorities of relevance to Africa.", "filename": "2020.10.12.20211565v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211565 "}, {"title": "Antivenom accessibility impacts mortality and severity of Brazilian snake 2 envenomation: a geospatial information systems analysis", "abstract": "Background\nIn 2017, the World Health Organization declared the snakebite envenomation as a neglected tropical disease. Annually, snakebite envenomation causes approximately 400,000 permanent disabilities and 95,000 deaths worldwide. People with the greatest risk of envenomation lack access to adequate health care, including treatment with antivenom. We developed na analysis of accessibility to antivenom in Brazil in order to verify the impacts on mortality. \nMethods and Findings\nInformation about number of accidents, deaths, antivenom, medical assistance, and species, were retrieved from the Brazilian Health Informatics Department (DATASUS) from 2010 to 2015 and analyzed using geostatistics to evaluate the association between snakebite acidentes and mortality. An Spatial analysis using Global Morans I was performed in order to verify the presence of spatiality as an independent variable to the distribution of the accidents. In addition, we also tested three different analysis of regression using Ordinary Least Square  (OLS), Spatial Error, and Geographically Weighed Regression (GWR), together with the information obtained from the DATASUS and sociodemographic indicators, to verify the spatial-temporal distribution of envenomation cases and time to reach the healthcare centers. The regression presenting the lowest Akaike Criterion Information (AIC), highest adjusted R2, and variables with p < 0.05 was selected to represent our model. Lastly, the accessibility index was performed using 2-step floating catchment area based on the amount of hospital beds and inhabitants. This study revealed 141,039 cases of snakebites, 598 deaths, and mortality rate of 3.13 per 1,000,000 inhabitants. Moreover, GWR presented the best fit (AIC = 55477.56; adjusted R2 = 0.55) and showed that illiteracy, income, percentage of urban population, percentage of antivenom, accessibility index for hospital beds with antivenom, proportion of cases with more than 3 hours to reach healthcare are correlated with the mortality rate by snakebite (p < 0.05). \nConclusion\nThis study identified regions affected by snakebite and how the accessibility to antivenom treatment plays an important role in the mortality in Brazil. Public interventions can located to those most vulnerable regions in order to improve the accident outcome.", "filename": "2020.10.13.20211730v1", "doi": "doi: https://doi.org/10.1101/2020.10.13.20211730 "}, {"title": "Using Satellite Images and Deep Learning to Identify Associations Between County-Level Mortality and Neighborhood Features", "abstract": "What is the relationship between mortality and satellite images as elucidated through the use of Convolutional Neural Networks? \n\nBackground: Following a century of increase, life expectancy in the United States has stagnated and begun to decline in recent decades. Using satellite images and street view images, prior work has demonstrated associations of the built environment with income, education, access to care and health factors such as obesity. However, assessment of learned image feature relationships with variation in crude mortality rate across the United States has been lacking. We sought to investigate if county-level mortality rates in the U.S. could be predicted from satellite images. \n\nMethods: Satellite images were extracted with the Google Static Maps application programming interface for 430 counties representing approximately 68.9% of the US population. A convolutional neural network was trained using crude mortality rates for each county in 2015 to predict mortality. Learned image features were interpreted using Shapley Additive Feature Explanations, clustered, and compared to mortality and its associated covariate predictors. \n\nResults: Predicted mortality from satellite images in a held-out test set of counties was strongly correlated to the true crude mortality rate (Pearson r=0.72). Learned image features were clustered, and we identified 10 clusters that were associated with education, income, geographical region, race and age. Direct prediction of mortality using a deep learning model across a cross-section of 430 U.S. counties identified key features in the environment (e.g. sidewalks, driveways and hiking trails) associated with lower mortality. \n\nConclusions: The application of deep learning techniques to remotely-sensed features of the built environment can serve as a useful predictor of mortality in the United States. Although we identified features that were largely associated with demographic information, future modeling approaches that directly identify image features associated with health-related outcomes have the potential to inform targeted public health interventions.", "filename": "2020.10.12.20211755v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211755 "}, {"title": "Predicting Olfactory Loss In Chronic Rhinosinusitis Using Machine Learning", "abstract": "Objective\nCompare machine learning (ML) based predictive analytics methods compared to traditional logistic regression in classification of olfactory dysfunction in chronic rhinosinusitis (CRS-OD), and identify predictors within a large multi-institutional cohort of refractory CRS patients.\n\nMethods\nAdult CRS patients enrolled in a prospective, multi-institutional, observational cohort study were assessed for baseline CRS-OD using a smell identification test (SIT) or brief SIT (bSIT). Four different ML methods were compared to traditional logistic regression for classification of CRS normosmics versus CRS-OD.\n\nResults \nData were collected for 611 study participants who met inclusion criteria between April 2011 and July 2015. 34% of enrolled patients demonstrated olfactory loss on objective testing. Differences between CRS normosmics and those with smell loss included objective disease measures (CT and endoscopy scores), age, sex, prior surgeries, socioeconomic status, steroid use, polyp presence, asthma, and aspirin sensitivity. Most ML methods outperformed traditional logistic regression in terms of predictive ability. Top predictors include known factors reported in the literature, as well as several socioeconomic factors.\n\nConclusion \nOlfactory dysfunction is a variable phenomenon within a large multicenter cohort of refractory CRS patients. ML methods outperform traditional logistic regression in classification of normosmia versus smell loss in CRS, and are able to include numerous risk factors into prediction models. These results carry implications for basic science and clinical research in hyposmia secondary to sinonasal disease, the most common cause of persistent olfactory loss in the general population.", "filename": "2020.10.12.20210500v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210500 "}, {"title": "Early Crowdfunding Response to the COVID-19 Pandemic", "abstract": "Background: As the number of COVID-19 cases increased precipitously in the US, policymakers and health officials marshalled their pandemic responses. As the economic impacts multiplied, anecdotal reports noted the increased use of online crowdfunding to defray these costs. We examined the online crowdfunding response in the early stage of the COVID-19 pandemic in the US.\nMethods: On May 16, 2020, we extracted all available data available on US campaigns created between January 1 and May 10, 2020 on GoFundMe and identified the subset of COVID-related campaigns using keywords relevant to the COVID-19 pandemic. We explored incidence of COVID-related campaigns by geography, by category, and over time and compared campaign characteristics to non-COVID-related campaigns after March 11 when the pandemic was declared. \nResults: We found that there was a substantial increase in overall GoFundMe online crowdfunding campaigns in March, largely attributable to COVID-related campaigns. However, as the COVID-19 pandemic persisted and progressed, the number of campaigns per COVID-19 cases declined more than tenfold across all states. COVID-related campaigns raised more money, had a longer narrative description, and were more likely to be shared on Facebook than other campaigns in the study period.\nConclusions: Online crowdfunding appears to be a transient stopgap, predicated on the novelty of an emergency rather than the true sustained need of a community. Rather, crowdfunding activity is likely an early marker for communities in acute distress that could be used by governments and aid organizations to guide disaster relief and policy.", "filename": "2020.10.12.20211532v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211532 "}, {"title": "The link between CS gas exposure and menstrual cycle issues among female Yellow Vest protesters in France", "abstract": "CS teargas is one of the most used tools for crowd-control worldwide. Exposure to CS teargas is known to have consequences on protesters health (i.e. eye, skin irritation, respiratory problems), but recent concerns have been raised over its potential gender-specific effects. Indeed, field and clinical observations report cases of menstrual cycle issues among female protesters following high exposure to teargas. The hypothesis of a link between teargas exposure and menstrual cycle issues is plausible from a physiological standpoint, but has not yet been empirically investigated. Using data from a cross-sectional study on Yellow Vests protesters health in France, we examined the relationship between exposure to teargas and menstrual cycle issues among female protesters (n = 145). Analyses suggested a positive link between exposure and menstrual cycle perturbations. These results constitute first and preliminary evidence that CS teargas may be linked with menstrual cycle among women, which need corroboration given the importance of this issue. We call for further research on the potential effects of CS teargas on womens reproductive system.", "filename": "2020.10.11.20210955v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210955 "}, {"title": "How Policies on Restaurants, Bars, Nightclubs, Masks, Schools, and Travel Influenced Swiss COVID-19 Reproduction Ratios", "abstract": "The role of complete lockdowns in reducing the reproduction ratios (Rt) of COVID-19 is now established. However, the persisting reality in many countries is no longer a complete lockdown, but restrictions of varying degrees using different choices of Non-pharmaceutical interaction (NPI) policies. A scientific basis for understanding the effectiveness of these graded NPI policies in reducing the Rt is urgently needed to address the concerns on personal liberties and economic activities. In this work, we develop a systematic relation between the degrees of NPIs implemented by the 26 cantons in Switzerland during March 9 to September 13 and their respective contributions to the Rt. Using a machine learning framework, we find that Rt which should ideally be lower than 1.0, has significant contributions in the post-lockdown scenario from the different activities - restaurants (0.0523 (CI. 0.0517-0.0528)), bars (0.030 (CI. 0.029-0.030)), and nightclubs (0.154 (CI. 0.154-0.156)). Activities which keep the land-borders open (0.177 (CI. 0.175-0.178)), and tourism related activities contributed comparably 0.177 (CI. 0.175-0.178). However, international flights with a quarantine did not add further to the Rt of the cantons. The requirement of masks in public transport and secondary schools contributed to an overall 0.025 (CI. 0.018-0.030) reduction in Rt, compared to the baseline usage even when there are no mandates. Although causal relations are not guaranteed by the model framework, it nevertheless provides a fine-grained justification for the relative merits of choice and the degree of the NPIs and a data-driven strategy for mitigating Rt.", "filename": "2020.10.11.20210641v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210641 "}, {"title": "Evaluation of statistical methods used in the analysis of interrupted time series studies: a simulation study", "abstract": "Interrupted time series (ITS) studies are frequently used to evaluate the effects of population level interventions or exposures. To our knowledge, no studies have compared the performance of different statistical methods for this design. We simulated data to compare the performance of a set of statistical methods under a range of scenarios which included different level and slope changes, varying lengths of series and magnitudes of autocorrelation. We also examined the performance of the Durbin-Watson (DW) test for detecting autocorrelation. All methods yielded unbiased estimates of the level and slope changes over all scenarios. The magnitude of autocorrelation was underestimated by all methods, however, restricted maximum likelihood (REML) yielded the least biased\nestimates. Underestimation of autocorrelation led to standard errors that were too small and coverage less than the nominal 95%. All methods performed better with longer time series, except for ordinary least squares (OLS) in the presence of autocorrelation and Newey-West\nfor high values of autocorrelation. The DW test for the presence of autocorrelation performed poorly except for long series and large autocorrelation. From the methods evaluated, OLS was the preferred method in series with fewer than 12 points, while in longer series, REML was preferred. The DW test should not be relied upon to detect autocorrelation, except when the series is long. Care is needed when interpreting results from all methods, given confidence intervals will generally be too narrow. Further research is required to develop better performing methods for ITS, especially for short series.", "filename": "2020.10.12.20211706v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211706 "}, {"title": "Rapid detection of SARS-CoV-2 antibodies in oral fluids", "abstract": "Current commercially available methods for reliably detecting antibodies against SARS-CoV-2 remain expensive and inaccessible due to the need for whole blood collection by highly trained phlebotomists using personal protective equipment (PPE). We evaluated an antibody detection approach utilizing the OraSure Technologies' Oral Antibody Collection Device (OACD) and their proprietary SARS-CoV-2 total antibody detection enzyme-linked immunosorbent assay (ELISA). We found that the OraSure test for total antibody detection in oral fluid had comparable sensitivity and specificity to serum-based ELISAs while presenting a more affordable and accessible system with the potential for self-collection.", "filename": "2020.10.12.20210609v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210609 "}, {"title": "News Coverage and Drug Shortages during the COVID-19 Pandemic", "abstract": "Several drugs repurposed as COVID-19 treatment are in short supply. We collect data from MediaCloud and Google Health Trends about eight drugs proposed for repurposing as COVID-19 treatments and reported to be in shortage by the U.S. Food and Drug Administration from January 1, 2020 through June 30, 2020. We find that news media coverage could have contributed to shortages due to hoarding by individuals and stockpiling by institutions, and that search trends appear to accurately discriminate between individual hoarding and institutional stockpiling.", "filename": "2020.10.12.20211656v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211656 "}, {"title": "The alternative complement pathway is activated in protoporphyria patients during sun exposure.", "abstract": "The homeostasis of tissues in chronic disease is an important function of the alternative pathway (AP) of the complement system (CS). However, if not controlled, it may also be detrimental to healthy cells. \nProtoporphyria (PP) is a rare disease that causes photosensitivity at the visible light due to the accumulation of Protoporphyrin-IX in the dermis. The aim of this study was to deep the knowledge about the involvement of AP in PP photoreaction.\nGlobal radiation and UV data were provided from regional agency of environmental protection (ARPA). Properdin, Factor H (FH) and C5 levels were assessed in the serum collected during winter and summer from 19 PP patients and 13 controls. .\nProperdin in winter and summer reflected a positive increase compared to controls. The values in summer were higher than winter. The C5 results were altered only in summer. The outcome was reversed for FH: in the winter, it was higher compared to the summer. A positive correlation was reported between properdin and C3 in summer; a negative tendency between Factor B (FB) and FH was detected. \nThis study substantiated the differential involvement of AP depending on the increase in light exposure during the season, which was demonstrated with ARPA data. The enhanced systemic response could justify the malaise sensation of patients after long light exposure and can be exploited to elucidate the new therapeutic approach.", "filename": "2020.10.12.20210344v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210344 "}, {"title": "Increased brain volume from cereal, decreased brain volume from coffee -- shared genetic determinants and impacts on cognitive function, body mass index (BMI) and other metabolic measures: cohort study of UK Biobank participants", "abstract": "Objective: To explore how different diets may affect human brain development and if genetic and environmental factors play a part. \nDesign: Cohort study.\nSetting: UK Biobank data were collected from 22 centres across the UK.\nParticipants: Only white British individuals free of Alzheimer's or dementia diseases were included in the study, where 336517 participants had quality-controlled genetic data, and 18879 participants had qualified brain MRI data.\nMain outcome measures: Grey matter volume, intake of cereal and coffee, body mass index and blood cholesterol level.\nResults: We investigated diet effects in the UK Biobank data and discovered anti-correlated brain-wide grey matter volume (GMV)-association patterns between coffee and cereal intake, coincidence with their anti-correlated genetic constructs. These genetic factors may further affect people's lifestyle habits and body/blood fat levels through the mediation of cereal/coffee intake, and the brain-wide expression pattern of gene CPLX3, a dedicated marker of subplate neurons that regulate cortical development and plasticity, may underlie the shared GMV-association patterns among the coffee/cereal intake and cognitive functions. \nConclusions: Our findings revealed that high-cereal and low-coffee diets shared similar brain and genetic constructs, leading to long-term beneficial associations regarding cognitive, BMI and other metabolic measures. This study has important implications for public health, especially during the pandemic, given the poorer outcomes of COVID-19 patients with greater BMIs.", "filename": "2020.10.11.20210781v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210781 "}, {"title": "Using Automated-Machine Learning to Predict COVID-19 Patient Survival: Identify Influential Biomarkers", "abstract": "Background: In a pandemic, it is important for clinicians to stratify patients and decide who receives limited medical resources. In this study, we used automated machine learning (autoML) to develop and compare between multiple machine learning (ML) models that predict the chance of patient survival from COVID-19 infection and identified the best-performing model. In addition, we investigated which biomarkers are the most influential in generating an accurate model. We believe an ML model such as this could be a useful tool for clinicians stratifying hospitalized SARS-CoV-2 patients.\n\nMethods: The data was retrospectively collected from Clinical Looking Glass (CLG) on all patients testing positive for COVID-19 through a nasopharyngeal specimen by real-time RT-PCR and admitted between 3/1/2020-7/3/2020 (4376 patients) at our institution. We collected 47 biomarkers from each patient within 36 hours before or after the index time: RT-PCR positivity, and tracked whether a patient survived or not for one month following this time. We utilized the autoML from H2O.ai, an open source package for R language. The autoML generated 20 ML models and ranked them by area under the precision-recall curve (AUCPR) on the test set. We selected the best model (model_var_47) and chose a threshold probability that maximized F2 score to make a binary classifier: dead or alive. Subsequently, we ranked the relative importance of variables that generated model_var_47 and chose the 10 most influential variables. Next, we reran the autoML with these 10 variables and likewise selected the model with the best AUCPR on the test set (model_var_10). Again, threshold probability that maximized F2 score for model_var_10 was chosen to make a binary classifier. We calculated and compared the sensitivity, specificity, and positive predicate value (PPV) for model_var_10 and model_var_47.\n\nResults: The best model that autoML generated using all 47 variables was the stacked ensemble model of all models (AUCPR = 0.836). The most influential variables were: systolic and diastolic blood pressure, age, respiratory rate, pulse oximetry, blood urea nitrogen, lactate dehydrogenase, d-dimer, troponin, and glucose. When the autoML was retrained with these 10 most important variables, it did not significantly affect the performance (AUCPR= 0.828). For the binary classifiers, sensitivity, specificity, and PPV of model_var_47 was 83.6%, 87.7%, and 69.8% respectively, while for model_var_10 they were 90.9%, 71.1%, and 51.8% respectively.  \n\nConclusions: By using autoML, we developed high-performing models that predict patient mortality from COVID-19 infection. In addition, we identified the most important biomarkers correlated with mortality. This ML model can be used as a decision supporting tool for medical practitioners to efficiently triage COVID-19 infected patients. From our literature review, this will be the largest COVID-19 patient cohort to train ML models and the first to utilize autoML. The COVID-19 survival calculator based on this study can be found at https://www.tsubomitech.com/.\n\nKeywords: Automated machine learning; COVID-19; Biomarkers; Ranking; Decision support tool.\n\nCorresponding author: Kenji Ikemura (kikemura@montefiore.org)", "filename": "2020.10.12.20211086v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211086 "}, {"title": "Indolent Presentations of Leukemic Lung Disease in Acute Myeloid Leukemia", "abstract": "Background: Patients with active acute myelogenous leukemia (AML) are at risk for leukemic infiltration (LI) into the lung and acute tumor lysis pneumopathy (ATLP) following chemotherapy. Fulminant presentations of these leukemic lung diseases are well-described, but indolent forms have not yet been studied. Therefore, we sought to elucidate the clinical features of mild-to-moderate LI and ATLP.\n\nMethods: A retrospective cohort analysis was performed on 51 hospitalized patients with AML, circulating blast count \u22653%, non-critical illness, and receipt of bronchoscopy between 2015-2019. Diagnoses of LI and ATLP were made via retrospective chart review by a multidisciplinary team of physicians.\n\nResults: 19 cases of leukemic lung disease were identified: 14 with LI and 5 with ATLP. The clinical presentations closely resembled pneumonia, with the majority demonstrating respiratory symptoms (63%), hypoxemia (63%), fever (84%), and pulmonary opacities (100%). All patients were presumptively diagnosed with infection, leading to an average of 18 days of broad-spectrum antibiotic therapy and multiple instances of delayed chemotherapy in treatment candidates. Although most patients were near the end-of-life (90% died within 1 year), transitions to comfort care were infrequent (25%) and hospitalizations were protracted (median 25 days). \n\nConclusions: LI and ATLP are common yet under-recognized pulmonary complications in patients with active AML. When presenting indolently, these conditions are difficult to distinguish from lung infection, leading to missed diagnosis, inappropriate antibiosis, chemotherapy deferrals, and prolonged hospitalizations. Greater awareness and consensus definitions of LI and ATLP are therefore needed to improve care of this population.", "filename": "2020.10.12.20211276v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211276 "}, {"title": "Sepsis Recording in Primary Care Electronic Health Records, Linked Hospital Episodes and Mortality Records: Population-based Cohort Study in England", "abstract": "Objectives: Sepsis is a growing concern for health systems, but the epidemiology of sepsis is poorly characterised. We evaluated sepsis recording across primary care electronic records, hospital episodes and mortality registrations.\nMethods and Findings: Cohort study including 378 general practices in England from Clinical Practice Research Datalink (CPRD) GOLD database from 2002 to 2017 with 36,209,676 patient-years of follow-up with linked Hospital Episode Statistics (HES) and Office for National Statistics (ONS) mortality registrations. Incident sepsis episodes were identified for each source. Concurrent records from different sources were identified and age-standardised and age-specific incidence rates compared. Logistic regression analysis evaluated associations of gender, age-group, fifth of deprivation and period of diagnosis with concurrent sepsis recording.\nThere were 20,206 first episodes of sepsis from primary care, 20,278 from HES and 13,972 from ONS. There were 4,117 (20%) first HES sepsis events and 2,438 (17%) mortality records concurrent with incident primary care sepsis records within 30 days.  Concurrent HES and primary care records of sepsis within 30 days before or after first diagnosis were higher at younger or older ages and for patients with the most recent period of diagnosis with those diagnosed during 2007:2011 less likely to have a concurrent HES record given CPRD compared to those diagnosed during 2012 to 2017 (odd ratio 0.65, 95% confidence interval 0.60 to 0.70). At age 85 and older, primary care incidence was 5.22 per 1,000 patient years (95% CI 1.75 to 11.97) in men and 3.55 (0.87 to 9.58) in women which increased to 10.09 (4.86 to 18.51) for men and 7.22 (2.96 to 14.72) for women after inclusion of all three sources. \nConclusion: Explicit recording of sepsis is inconsistent across healthcare sectors with a high proportion of non-concurrent records. Incidence estimates are higher when linked data are analysed.", "filename": "2020.10.12.20211326v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211326 "}, {"title": "Antimicrobial resistance surveillance: can we estimate resistance in bloodstream infections from other types of specimen?", "abstract": "Background: Antimicrobial resistance (AMR) is a major global health threat. Standard approaches to AMR surveillance through susceptibility testing of isolates from blood cultures are difficult in low- and middle-income countries (LMIC), where lack of laboratory capacity prevents routine patient-level antimicrobial susceptibility testing, and systematic testing of invasive specimens may not be feasible. Other specimen types could provide an alternative but effective approach to surveillance, but the relationship between resistance prevalence in these and bloodstream infections has not been systematically evaluated.\n\nMethods: We used data from Oxfordshire, UK, 1998-2018, to investigate associations between resistance rates in Escherichia coli and Staphylococcus aureus isolates from blood and other specimens, comparing proportions resistant in each calendar year using time series cross-correlations, for multiple antibiotics. We also compared the proportion of resistant isolates from blood versus other specimens across drug-years, overall and across four arbitrary resistance categories (<5%, 5-10%, 10-20%, >20%). We repeated analysis across four high-income and 12 middle-income countries, and in three hospitals/programmes in LMICs.\n\nFindings: 8102 E. coli bloodstream infections, 322087 E. coli urinary tract infections, 6952 S. aureus bloodstream infections and 112074 S. aureus non-sterile site cultures were included from Oxfordshire. Resistance trends over time in isolates from blood versus other specimens were strongly correlated (maximum cross-correlation 0.51-0.99 with strongest associations between proportions in the same year for 18/27 pathogen-drug combinations). Resistance prevalence was broadly congruent across drug-years for each species, particularly allowing for uncertainty in estimation. 207/312 (66%) species-drug-years had resistance prevalence in other specimen types within +/-5% of that blood isolates, and 276/312 (88%) within +/-10%. 215/312 (69%) species-drug-years were in the same resistance category for blood and other specimen types; 305 (98%) were the same or adjacent resistance categorisation. Results were similar across multiple countries in high- and middle-income settings, and the three LMIC hospitals/programmes.\n\nInterpretation: Resistance in bloodstream and other less invasive infections are strongly related, suggesting the latter could be a surveillance tool for AMR in LMICs. These infection sites are easier to sample and cheaper to obtain the necessary numbers of susceptibility tests, thus providing more cost-effective evidence for decisions including empiric antibiotic recommendations.", "filename": "2020.10.12.20211243v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211243 "}, {"title": "Caregiver-mediated interventions to support self-regulation among infants and young children (0-5): A protocol for a realist review", "abstract": "Abstract\nBackground and Objectives. Self-regulation is a modifiable protective factor for lifespan mental and physical health outcomes. Early caregiver-mediated interventions to promote infant and child regulatory outcomes prevent long-term developmental, emotional, and behavioural difficulties and improve outcomes such as school readiness, educational achievement, and economic success. To harness the population health promise of these programmes, there is a need for more nuanced understanding of the impact of these interventions. The aim of this realist review is to understand how, why, under which circumstances, and for whom, early caregiver-mediated interventions improve infant and child self-regulation. The specific research questions guiding this review were based on consultation with families and community organizations that provide early childhood and family services. \nDesign, Methods and Analysis: Realist reviews take a theory-driven and iterative approach to evidence synthesis, structured around continuous refinement of a programme theory. Programme theories specify context-mechanism-outcome configurations to explain what works, for whom, under which circumstances, and how. Our initial programme theory is based on prior work in this field and will be refined through searching peer-reviewed and grey literature to identify relevant evidence. A working group, comprising service users, community organization representatives, representatives from specific populations, clinicians, and review team members will be formed to guide the evidence synthesis and interpretation, as well as the development and dissemination of recommendations based on the findings of the review. The review will involve searching: (1) electronic databases (e.g. EMBASE, Medline, PsycInfo), (2) connected papers, articles and citations, and (3) grey literature. Decisions to include evidence will be guided by judgements about their contribution to the programme theory and will be made by the research team, with input from the working group as required. Evidence synthesis will be reported using the RAMESES guidelines and disseminated through peer-reviewed publication. \nTrial registration number: The protocol is registered with Open Science Framework https://osf.io/5ce2z/registrations", "filename": "2020.10.12.20211300v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211300 "}, {"title": "The Characteristic of Auditory Function and Cochlear Synaptopathy in a Noise-exposed Cohort: A Cross-sectional Study", "abstract": "Objectives: To determine whether noise-induced cochlear synaptopathy occurs in humans.\nDesign: Young workers with occupational noise-exposure from a shipyard were recruited for participation in the current study. Age-matched workers in the same shipyard who had no noise-exposure were enrolled in the control group. The speech-in-noise scores, gap detection thresholds and SP/AP values were tested and compared between the two groups. The correlations of both the speech-in-noise scores and the gap detection threshold with the SP/AP value were calculated and analyzed. \nResults: Our results demonstrated that even within the normal auditory threshold, individuals with occupational noise exposure showed lower speech-in-noise scores and higher gap detection threshold and SP/AP values. Speech-in-noise score was correlated SP/AP value. The electrocochleography values showed no significant correlation with the gap detection threshold. \nConclusion: The result confirmed that noise-induced cochlear synaptopathy occurs in humans with occupational noise exposure. However, they also implied that the mechanism of cochlear synaptopathy in humans is more complicated than that in experimental animals.\nKey words: Cochlear synaptopathy; Hidden hearing loss; Occupational noise exposure; Speech-in-noise; Gap detection threshold", "filename": "2020.09.27.20202481v2", "doi": "doi: https://doi.org/10.1101/2020.09.27.20202481 "}, {"title": "SARS-CoV-2 sequencing reveals rapid transmission from college student clusters resulting in morbidity and deaths in vulnerable populations", "abstract": "College reopening decisions during the SARS-CoV-2 pandemic represent a trade-off between competing risks to students, faculty and staff, and college finances. Additionally, risks taken in reopening colleges can impose significant burdens on individuals living in surrounding communities. Many colleges that reopened for in-person instruction have reported frequent SARS-CoV-2 outbreaks. La Crosse County, Wisconsin experienced a substantial SARS-CoV-2 outbreak (2,002 cases in September 2020) that coincided with the return to in-person instruction at three local academic institutions. Genomic sequencing of SARS-CoV-2 cases in La Crosse during that period found rapid expansion of two viral substrains. Although the majority of cases were among college-age individuals, from a total of 111 genomes sequenced we identified rapid transmission of the virus into more vulnerable populations. Eight sampled genomes represented two independent transmission events into two skilled nursing facilities, resulting in two fatalities. Our study highlights the very significant risks imposed by college administrator reopening decisions, not just on college-associated populations, but on vulnerable individuals in surrounding communities.", "filename": "2020.10.12.20210294v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210294 "}, {"title": "Pathophysiology-based subphenotyping of individuals at elevated risk for type 2 diabetes", "abstract": "The state of intermediate hyperglycemia is indicative of elevated risk of developing type 2 diabetes. However, the current definition of prediabetes neither reflects subphenotypes of pathophysiology of type 2 diabetes nor is it predictive of future metabolic trajectories. We used partitioning on variables derived from oral glucose tolerance tests, MRI measured body fat distribution, liver fat content, and genetic risk in a cohort of extensively phenotyped individuals who are at increased risk for type 2 diabetes to identify six distinct clusters of subphenotypes. Three of the identified subphenotypes have increased glycemia (clusters 3, 5 and 6), but only individuals in clusters 5 and 3 have immanent diabetes risks. By contrast, those in cluster 6 have moderate risk of type 2 diabetes, but an increased risk of kidney disease and all-cause mortality. Findings were replicated in an independent cohort using simple anthropomorphic and glycemic constructs. This proof-of-concept study demonstrates that pathophysiological heterogeneity exists before diagnosis of type 2 diabetes and highlights a group of individuals who have an increased risk of complications without rapid progression to overt type 2 diabetes.", "filename": "2020.10.12.20210062v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210062 "}, {"title": "Bangla Technique of Laparoscopic Cholecystectomy: a Novel, Safe and Cost-effective modification of American and French Techniques", "abstract": "Background: Laparoscopic cholecystectomy (LC) can be performed by following either of the two approaches proposed by the American and the French school. The two approaches have comparable operative times, but use different arrangements for the patients and operators positions, and sites for port insertions.\nThe aim of the present paper is to describe an alternative to the American and the French approaches, referred to as the Bangla technique, which uses a standard four port approach but requires the presence of only one assistant along with the surgeon. It is hoped that the Bangla technique will improve surgery outcomes for gallbladder disease patients and encourage healthcare professionals in resource-poor settings to adopt minimally invasive/laparoscopic approaches to surgical problems.\nMethods: The sample consisted of a total of 280 gallbladder disease retrospective observational cases (of which 21 were children between 6 and 16 years of age) who were treated with the Bangla technique at the South Point Hospital Chittagong, Bangladesh, between January 2018 and February 2020.  \nResults: Surgery data showed that using the Bangla technique, the average operating time and average operation theater time were36.25 and 45.9 minutes, respectively. Of the patients, 86% left the hospital on the same day of operation, while the remaining left the following day. In 91.7% of the cases, there were no complications, while content leakage and bleeding occurred in 6.7% and 1.4% cases, respectively.\nConclusion: The proposed LC technique will benefit infection prevention and control by reducing the number of personnel in the operation theatre (one assistant and the surgeon) and, as such, reducing surgery-related expenses, which can be further decreased by using only one monitor. More so, the Bangla technique can be combined with the cystic artery sparing technique to reduce the risk of intraoperative bleeding and injury to the common bile duct.", "filename": "2020.10.08.20209056v2", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209056 "}, {"title": "Polyester Nasal Swabs Collected in a Dry Tube are a Robust and Inexpensive, Minimal Self-Collection Kit for SARS-CoV-2 Testing", "abstract": "Background\n\nPolyester nasal swabs stored in saline or in a dry tube were evaluated as an alternative to foam nasal swabs for SARS-CoV-2 testing by reverse transcription quantitative polymerase chain reaction (RT-qPCR) since they may be inexpensively manufactured at high capacity.\n\nMethods\n\nSurrogate clinical specimens were prepared by inoculating foam and polyester nasal swabs with residual SARS-CoV-2 positive clinical specimens diluted in porcine or human matrix. Dry swab elution with phosphate buffered saline (PBS) was evaluated by vortex, swab swirling, and passive methodologies. Surrogate and clinical nasal specimen stability were evaluated at refrigerated (4C) and elevated temperatures (40C for 12 hours, 32C hold) through 72 hours.\n\nResults\n\nPolyester swabs demonstrated equivalent performance to foam swabs for detection of low and high SARS-CoV-2 viral loads. Dry swab elution performed with PBS and mechanical disruption by vortex resulted in nearly complete quantitative recovery of virus. Dry polyester and foam surrogate specimens were stable through 72 hours both when refrigerated and after high temperature excursion, which simulated specimen transport without cold chain. Similarly, clinical specimens collected with polyester swabs and stored dry were stable through 72 hours in the presence and absence of cold chain. Polyester surrogate specimens stored in saline were stable through 72 hours refrigerated but only through 48 hours at elevated temperatures.\n\nConclusions\n\nPolyester nasal swabs stored in dry collection tubes comprise a robust and inexpensive self-collection method for SARS-CoV-2 viral load testing, which is stable under conditions required for home collection and shipment to the laboratory.", "filename": "2020.10.09.20210302v2", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210302 "}, {"title": "Network Graph Representation of COVID-19 Scientific Publications to Aid Knowledge Discovery", "abstract": "Introduction:  Numerous scientific journal articles have been rapidly published related to COVID-19 making navigation and understanding of relationships difficult.  \n\nMethods: A graph network was constructed from the publicly available CORD-19 database of COVID-19-related publications using an engine leveraging medical knowledgebases to identify discrete medical concepts and an open source tool (Gephi) used to visualise the network.\n\nResults: The network shows connections between disease, medication and procedures identified from title and abstracts of 195,958 COVID-19 related publications (CORD-19 Dataset). Connections between terms with few publications, those unconnected to the main network and those irrelevant were not displayed. Nodes were coloured by knowledgebase and node size related to the number of publications containing the term. The dataset and visualisations made publicly accessible via a webtool.\n\nConclusion: Knowledge management approaches (text mining and graph networks) can effectively allow rapid navigation and exploration of entity interrelationships to improve understanding of diseases such as COVID-19.", "filename": "2020.10.12.20211342v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211342 "}, {"title": "Understanding the Los Angeles County Coronavirus Epidemic: The Critical Role of Intrahousehold Transmission", "abstract": "We tracked the course of the COVID-19 epidemic among the approximately 300 communities comprising Los Angeles County. The epidemic, we found, had three distinct phases. During Phase I, from early March through about April 4, initial seeding of infection in relatively affluent areas was followed by radial geographic extension to adjoining communities. During Phase II, which continued to about July 11, COVID-19 cases continued to rise at a slower rate, and became increasingly concentrated in four geographic foci of infection across the county. This phase saw changes in two indicators of social mobility: the proportion of location-tracked smartphones staying at home, and the number of smartphones visiting a gym. For both indicators, those communities with a larger reduction in social mobility during April reported fewer new COVID-19 cases in May. During Phase III, COVID-19 incidence only gradually declined, remaining as high as the incidence seen at the end of Phase I. Across communities, the prevalence of households at high risk for intergenerational transmission was strongly correlated with the persistence of continued COVID-19 propagation. This association was even stronger in those communities with a higher rate of gym attendance in Phase II. The map of the prevalence of at-risk households in Los Angeles County coincided strikingly with the map of cumulative COVID-19 incidence. These findings, taken together, support the critical role of household structure in the persistent propagation of COVID-19 infections in Los Angeles County. Public health policy needs to be reoriented from a focus on protecting the individual to a focus on protecting the household.", "filename": "2020.10.11.20211045v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20211045 "}, {"title": "A Comparative Study of Dentists' Ability to Detect Enamel-only Proximal Caries in Bitewing Radiographs With and Without the use of AssistDent\u00ae Artificial Intelligence Software", "abstract": "Enamel-only proximal caries, if detected, can be reversed by non-invasive treatments. Dental bitewing radiograph analysis is central to diagnosis and treatment planning and, when used to detect enamel-only proximal caries, it is an important tool in minimum intervention and preventive dentistry. However, the subtle patterns of enamel-only proximal caries visible in bitewing radiographs are difficult to detect and often missed by dental practitioners. This study measures the ability of dentists to detect enamel-only proximal caries in bitewing radiographs with and without the use of AssistDent@[reg] Artificial Intelligence (AI) software. \n23 dentists were randomly divided into a control arm, in which no Artificial Intelligence assistance was provided, and an experimental arm in which Artificial Intelligence assistance provided on-screen prompts for potential locations of enamel-only proximal caries. All participants analysed a set of 24 bitewings, gathered from one dental hospital and 11 general dental practices, which had previously been analysed independently by a panel of 5 dento-maxillofacial radiologists and 1 professor of restorative dentistry who, between them, identified a total of 65 enamel-only carious lesions and 241 healthy proximal surfaces. \nResults demonstrate that dentists using the assistive software found 75.8% of the enamel-only proximal caries compared to a 44.3% detection rate in the control group. This represents an absolute increase of 31.5% (relative increase in sensitivity of 71%). Participants in the experimental group incorrectly identified 14.6% of the healthy surfaces as having enamel-only proximal caries compared to 3.7% in the control group, an absolute increase of 10.9% (relative decrease in specificity of 11%). \nT-test analysis demonstrated a statistically significant difference (p@[lt]0.01) between the two arms in sensitivity (true positive caries detection rate) and specificity (false positive rate).\nWe conclude that AssistDent\u00ae Artificial Intelligence software significantly improves dentists' ability to detect enamel-only proximal caries, with only a slight increase in false positives, and could be considered as a tool to support minimum intervention and preventive dentistry in general practice.", "filename": "2020.10.12.20211292v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211292 "}, {"title": "CORRELATION BETWEEN SARS-COV-2 ANTIBODY SCREENING BY IMMUNOASSAY AND NEUTRALIZING ANTIBODY TESTING", "abstract": "Background: Passive antibody therapy with convalescent plasma (CP) represents a promising alternative for the treatment of SARS CoV 2 infection. The efficacy of CP therapy has been associated with high titers of neutralizing antibodies (nAbs) in the plasma of recovered patients, but the assays for quantifying nAbs are not widely available. Our goal was to develop a strategy to predict high titers of nAbs based on the results of anti-SARS CoV 2 immunoassays and the clinical characteristics of the CP potential donors. \nMethods: Two hundred and fourteen CP donors were enrolled and tested for the presence of anti-SARS CoV 2 antibodies using two commercial immunoassays (IA): Anti SARS CoV 2 ELISA IgG EUROIMMUN and Anti SARS CoV 2 Chemiluminescence IgG Abbott. In parallel, quantification of neutralizing antibodies (nAbs) was performed using the Cytopathic effect-based virus neutralization test (CPE VNT). Three criteria for identifying donors with high titers of nAbs (more than 160) were tested:  Criterion1: Curve ROC Method;  Criterion 2: Conditional decision tree considering only the results from the IA and Criterion 3: Conditional decision tree including both the IA results and the clinical variables. \nResults: The performance of Abbott and EUROIMMUN immunoassays was similar referring to both S/CO and predictive value for identifying nAbs titers more than 1:160. Regarding the three studied criteria for identifying CP donors with high nAbs titers (more than 1:160): 1)  Criterion 1 showed 76.1% accuracy when the S/CO cut-off of 4.65 was used, 2) Criterion 2 presented 76.1% accuracy if the S/CO more than 4.57 was applied and 3) Criterion 3 had 71.6% accuracy if either S/CO more than 4.57 or S/CO between 2.68 and 4.57 and the last COVID-19-related symptoms occurred less than 19 days from donor recruiting were used. \nConclusion: The results of SARS-CoV-2 immunoassays (S/CO) can be used to predict high nAbs titers of potential CP donors. This study has proposed three different criteria for identifying donors with more than 160 nAbs titer based on either solely S/CO results or S/CO together with clinical variables, all with high efficacy and accuracy.", "filename": "2020.10.11.20210005v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210005 "}, {"title": "Derivation and validation of a triage tool for acutely ill adults with suspected COVID-19: The PRIEST observational cohort study", "abstract": "Objectives\nWe aimed to derive and validate a triage tool, based on clinical assessment alone, for predicting adverse outcome in acutely ill adults with suspected COVID-19 infection.\n\nMethods\nWe undertook a mixed prospective and retrospective observational cohort study in 70 emergency departments across the United Kingdom (UK). We collected presenting data from 22445 people attending with suspected COVID-19 between 26 March 2020 and 28 May 2020. The primary outcome was death or organ support (respiratory, cardiovascular, or renal) by record review at 30 days. We split the cohort into derivation and validation sets, developed a clinical score based on the coefficients from multivariable analysis using the derivation set, and the estimated discriminant performance using the validation set.\n\nResults\nWe analysed 11773 derivation and 9118 validation cases. Multivariable analysis identified that age, sex, respiratory rate, systolic blood pressure, oxygen saturation/inspired oxygen ratio, performance status, history of renal impairment, and respiratory distress were retained in analyses restricted to the ten or fewer predictors. We used findings from multivariable analysis and clinical judgement to develop a score based on the NEWS2 score, age, sex, and performance status. This had a c-statistic of 0.80 (95% confidence interval 0.79-0.81) in the validation cohort and predicted adverse outcome with sensitivity 0.98 (0.97-0.98) and specificity 0.38 (0.38-0.39) for scores above four points.\n\nConclusion\nA clinical score based on NEWS2, age, sex, and performance status predicts adverse outcome with good discrimination in adults with suspected COVID-19 and can be used to support decision-making in emergency care.", "filename": "2020.10.12.20209809v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20209809 "}, {"title": "Prioritisation of population groups with the most interactions for COVID-19 vaccination can substantially reduce total fatalities", "abstract": "The rapid development of vaccines against the SARS-CoV-2 virus is an unprecedented achievement. Once vaccines become mass produced, they will have to be distributed to almost the entire population to prevent deaths and permit prompt economic recovery. The necessity to vaccinate a large number of people in a short period of time, and possibly with insufficient vaccine doses to cover most, creates in itself a new challenge for governments and health authorities: which population groups (by age or other criteria) should be targeted first and what sequence must be followed, if any at all, to achieve the minimum number of fatalities? In this work, we demonstrate the importance and impact of optimally planning the priorities for vaccine deployment by population groups using a modified SEIR-type model for the COVID-19 outbreak considering age-related groups. Finding the absolute guaranteed best solution of the mathematical optimisation problem may be hard, if even possible, and would likely require intense computational resources for every possible case study scenario. In this work, several strategies are evaluated and compared, in an attempt to approach the most effective possible vaccination priority sequence in an example case study using demographic and epidemiological data from Spain. The minimum total fatalities at the end of the vaccination campaign is the objective pursued. The population groups classifications are established based on relevant differences in mortality (due to their age) and risk-related behaviour such as their number of daily person-to-person interactions. Assuming a capacity limited constant vaccination rate, vaccination distribution strategies were evaluated for different vaccine effectiveness levels and different percentages of final vaccine population coverage. Our results unambiguously show how planning vaccination by priority groups can achieve dramatic reductions in total fatalities (more than 70% in some cases) compared to no prioritisation. The results also indicate in all cases, for all vaccine effectiveness and coverage values evaluated, that the criteria for groups vaccination priority should not be those with the highest mortality but rather those the highest number of daily person-to-person interactions. Strikingly, our results show in all cases, that prioritisation of groups with the highest mortality but less social interactions, may lead to significantly larger numbers of final total fatalities, even higher as if no group priorities were established at all. The explanation, clearly displayed by the mechanistic model, is that vaccination avoids infections that reduce mortality not only from the vaccinated group itself but also from the projected secondary and subsequent infections inflicted on the rest of the population by those vaccinated in that group. Precisely this amplification effect (exponential nature of the curve) appears to cause the larger reduction in total fatalities if the groups with the most interactions are vaccinated first. The possible contradiction of these results with some published recommendations highlight the importance of conducting an open comprehensive and rigorous analysis of this problem leaving behind any subjective preconceptions.", "filename": "2020.10.12.20211094v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211094 "}, {"title": "Evaluation of different stool extraction methods for metabolomics measurements in human fecal samples", "abstract": "Background: Measurements of metabolomics in human stool samples is of great interest for a broad range of applications in biomedical research including early detection of colorectal neoplasms. But due to the complexity of metabolites there is no consensus on how to process samples for stool metabolomics measurements to obtain a broad coverage of hydrophilic and hydrophobic substances.\nMethods: We used frozen stool samples (50mg) from healthy study participants. Stool samples were processed after thawing using 8 different processing protocols and different solvents. Metabolites were measured afterwards using the Mxp Quant 500 kit (Biocrates). The best performing protocol was subsequently applied to compare stool samples of participants with different dietary habits.\nResults: In this study, we were able to determine up to 340 metabolites of various chemical classes extracted from stool samples of healthy study participants with 8 different protocols. Polar metabolites such as amino acids could be measured with each method while other metabolite classes, particular lipid species, are more dependent on the solvent or combination of solvents used. Only a small number of triglycerides or acylcarnitines were detected in human feces. Extraction efficiency was higher for protocols using isopropanol or those using ethanol or methanol and MTBE including an evaporation and concentration than for other protocols. We detected significant fecal metabolite differences between vegetarians, semi-vegetarians and non-vegetarians. \nConclusion: For the evaluation of metabolites in fecal samples we found protocols using solvents like isopropanol and those using ethanol or methanol and MTBE including an evaporation and concentration step to be superior over others tested in this study.", "filename": "2020.10.12.20209767v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20209767 "}, {"title": "School education during the SARS-CoV-2 pandemic - Which concept is safe, feasible and environmentally sound?", "abstract": "The future belongs to children and they need education to shape the future with foresight and intention. Children therefore have the right to education, according to Article 29 of the UN Convention on the Rights of the Child. However, professional education is not everything, because children must also experience their strengths and weaknesses together and educate each other to be responsible and considerate people, so that they become socially valuable personalities. Only in this way can they shape the future in a peaceful and humane way. Therefore, attending school is essential. However, children also have the right to protection and care by their parents and the state, because the welfare of the child must also be given priority in accordance with Article 3 of the UN Convention on the Rights of the Child. The question is therefore how schooling in community schools can be realized during the SARS-CoV-2 pandemic without exposing children to an unnecessary risk of infection. It is not only about the children, because if the children are at risk, then so are their parents and grandparents and ultimately society as a whole. There are numerous concepts that promise safety in schools during the pandemic. When selecting concepts, the costs must of course be weighed against the benefits. People rightly expect an efficient use of resources. This means that either the set goal is achieved with the least possible resources or that the available resources are used to achieve the greatest possible approximation to the goal. In addition to the financial resources, however, the long-term consequences for the state, the economy, the population and the environment under the pressure of the pandemic must also be taken into account. Social cohesion and democracy must not be jeopardized either. Various protection concepts are currently under discussion. Often the advantages are overstated and the disadvantages concealed. Furthermore, some arguments are based on assumptions that are not true. The aim of this study is to provide a comparative assessment of the main protection concepts and to demonstrate, with the help of experimental analyses, the extent to which the protection concepts are effective. We will show that a comparatively high level of safety against infection in classrooms can be technically ensured without exposing children to masks. At the same time, the protection concept makes economic sense and the burden on the environment is comparatively low, so that infection prevention and climate protection do not have to be weighed against each other, because infection prevention and climate protection are political and social goals that have to be achieved together.", "filename": "2020.10.12.20211219v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211219 "}, {"title": "Scrutiny for Child Abuse and Neglect During the COVID-19 Pandemic", "abstract": "The extant infrastructure for child abuse surveillance, dependent on reporting by schools and healthcare professionals, has been disrupted by the pandemic. Using Google Trends and MediaCloud data, we find a drop in Internet searches and news reports about child abuse and neglect during the pandemic, which may reflect decreased scrutiny.", "filename": "2020.10.12.20210997v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20210997 "}, {"title": "COVID-19 in Italy: targeted testing as a proxy of limited health care facilities and a key to reducing hospitalization rate and the death toll.", "abstract": "The novel Coronavirus SARS-CoV-2 (CoV) has induced a worldwide pandemic, notably in Italy, one of the worst-hit countries in Europe, which witnessed a death toll unseen in the recent past. There are potentially many factors, such as infections from undetected index cases, early vs late testing strategies, limited health care facilities etc., that might have aggravated the COVID-19 situation in Italy. We developed a COVID-19 specific infection epidemic model composed of susceptible (S), exposed (E), carrier (C), infected (I), recovery (R) and dead (D) (SECIRD), specifically parameterized for Italy to disentangle the impact of these factors and their implications on infection dynamics to help planning an effective control strategy for a possible second wave. Our model discriminates between detected infected and undetected individuals who played a crucial role in the disease spreading and is not well addressed by classical SEIR-like transmission models. We first estimated the number of undetected infections through a Bayesian Markov Chain Monte Carlo (MCMC) framework, which ranges from ~7 to ~22 fold higher than reported infections, depending upon regions. We exploited this information to evaluate the impact of the undetected component on the evolution of the pandemic and the benefits of an enhanced testing strategy. In high testing regions like Veneto, 18% of all infections resulted in hospitalization, while for Lombardia and Piemonte, it is 25% and 27%, respectively. We investigated the impact of an overwhelmed health care system upon death toll by applying hospital and intensive care unit (ICU) capacities in the SECIRD model, and we estimated a 10% reduction in death in Lombardia, the worst hit region, if a higher number of hospital facilities had been available since the beginning. Adopting a combined strategy of rapid early and targeted testing (~10 fold) with increased hospital capacity would help in avoiding bottlenecks affecting the health care system. Our results demonstrate that the early testing would have a strong impact on the overall hospital accessibility and, hence, upon death toll (~20% to 50% reduction) and could have mitigated the lack of facilities at the crucial middle stage of the epidemic.", "filename": "2020.10.12.20211169v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211169 "}, {"title": "Predictors of mortality in hospitalized COVID-19 patients in Athens, Greece", "abstract": "Background: The epidemic of COVID-19 has rapidly spread worldwide, with millions of confirmed cases and related deaths. Numerous efforts are being made to clarify how the infection progresses and potential factors associated with disease severity and mortality. We investigated the mortality in Greek hospitalized COVID-19 patients and also the predictors of this mortality. \nMethods: Study population included 512 COVID-19 patients admitted to the hospitals of the Attica region of Greece. Patients demographic characteristics, comorbidities, allergies, previous vaccination for seasonal influenza virus, admission to ICU, intubation, and death were recorded. Potential predictors of in-hospital mortality were identified by regression analysis. \nResults: The mean age of hospitalized patients was 60.4 years, and was higher in patients who deceased. The most common comorbidities were respiratory diseases, hypertension, gastrointestinal disorders, dyslipidemia, mental health diseases, asthma, diabetes mellitus and cardiovascular diseases. The need for ICU care and intubation was significantly higher among patients who died. The mortality rate was 15.8% (81 out of 512). Age \u226565 years, cancer, chronic kidney disease, endocrine diseases, central nervous system disorders, anemia, and intubation were independently associated with increased in-hospital mortality, while allergies and previous influenza vaccination were associated with decreased in-hospital mortality.\nConclusion: Our finding of a beneficial effect of allergies and influenza vaccination against COVID-19 infection merits further investigation, as it may shed light in the mechanisms underlying disease progression and severity. Most importantly, it may assist in the implementation of efficient protective measures and public healthcare policies.", "filename": "2020.10.12.20211193v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211193 "}, {"title": "High and increasing prevalence of SARS-CoV-2 swab positivity in England during end September beginning October 2020: REACT-1 round 5 updated report", "abstract": "Background\nREACT-1 is quantifying  prevalence of SARS-CoV-2 infection among random samples of the population in England based on PCR testing of self-administered nose and throat swabs. Here we report results from the fifth round of observations for swabs collected from the 18th September to 5th October 2020. This report updates and should be read alongside our round 5 interim report.\nMethods\nRepresentative samples of the population aged 5 years and over in England with sample size ranging from 120,000 to 175,000 people at each round. Prevalence of PCR-confirmed  SARS-CoV-2 infection, estimation of reproduction number (R) and time trends between and within rounds using exponential growth or decay models.\nResults\n175,000 volunteers tested across England between 18th September and 5th October. Findings show a national prevalence of 0.60% (95% confidence interval 0.55%, 0.71%) and doubling of the virus every 29 (17, 84) days in England corresponding to an estimated national R of 1.16 (1.05, 1.27). These results correspond to 1 in 170 people currently swab-positive for the virus and approximately 45,000 new infections each day. At regional level, the highest prevalence is in the North West, Yorkshire and The Humber and the North East with strongest regional growth in North West, Yorkshire and The Humber and West Midlands.\nConclusion\nRapid growth has led to high prevalence of SARS-CoV-2 virus in England, with highest rates in the North of England. Prevalence has increased in all age groups, including those at highest risk. Improved compliance with existing policy and, as necessary, additional interventions are required to control the spread of SARS-CoV-2 in the community and limit the numbers of hospital admissions and deaths from COVID-19.", "filename": "2020.10.12.20211227v1", "doi": "doi: https://doi.org/10.1101/2020.10.12.20211227 "}, {"title": "Should international borders re-open? The impact of travel restrictions on COVID-19 importation risk", "abstract": "Novel coronavirus disease (COVID-19) has spread across the world at an unprecedented pace, reaching over 200 countries and territories in less than three months. In response, many governments denied entry to travellers arriving from various countries affected by the virus. While several industries continue to experience economic losses due to the imposed interventions, it is unclear whether the different travel restrictions were successful in reducing COVID-19 importations. Here we develop a comprehensive framework to model daily COVID-19 importations, considering different travel bans. We quantify the temporal effects of the restrictions and elucidate the relationship between incidence rates in other countries, travel flows and the expected number of importations into the country under investigation. As a cases study, we evaluate the travel bans enforced by the Australian government. We find that international travel bans in Australia lowered COVID-19 importations by 87.68% (83.39 - 91.35) between January and June 2020. The presented framework can further be used to gain insights into how many importations to expect should borders re-open. Authorities may consider the presented information when planning a phased re-opening of international borders.", "filename": "2020.10.11.20211060v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20211060 "}, {"title": "High Food Insecurity in Latinx Families and Associated COVID-19 Infection in the Greater Bay Area, California", "abstract": "Background:  Food insecurity impacts nearly one-in-four Latinx households in the United States and has been exacerbated by the novel coronavirus or COVID-19 pandemic.  \nMethods: We examined the impact of COVID-19 on household and child food security in three preexisting, longitudinal, Latinx urban cohorts in the San Francisco Bay Area (N=375 households, 1,875 individuals). Households were initially recruited during pregnancy and postpartum at Zuckerberg San Francisco General Hospital (ZSFG) and UCSF Benioff prior to the COVID-19 pandemic.  For this COVID sub-study, participants responded to a 15-minute telephonic interview. Participants answered 18 questions from the US Food Security Food Module (US HFSSM), described food consumption, housing and employment status, and history of COVID-19 infection as per community or hospital-based testing. Food security and insecurity levels were compared with prior year metrics.  Results:  We found low levels of household food security in Latinx families (by cohort:  29.2%; 34.2%; 60.0%) and child food security (56.9%; 54.1%; 78.0%) with differences between cohorts explained by self-reported levels of education and employment status. Food security levels were much lower than those reported previously in two cohorts where data had been recorded from prior years.  Reported history of COVID-19 infection in households was 4.8% (95% Confidence Interval (CI); 1.5-14.3%); 7.2% (95%CI; 3.6-13.9%) and 3.5% (95%CI; 1.7-7.2%) by cohort and was associated with food insecurity in the two larger cohorts (p=0.03; p=0.01 respectively).  Conclusions:   Latinx families in the Bay Area with children are experiencing a sharp rise in food insecurity levels during the COVID-19 epidemic.  Food insecurity, similar to other indices of poverty, is associated with increased risk for COVID-19 infection.  Comprehensive interventions are needed to address food insecurity in Latinx populations and further studies are needed to better assess independent associations between household food insecurity, poor nutritional health and risk of COVID-19 infection.", "filename": "2020.10.11.20210906v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210906 "}, {"title": "Association between TM6SF2 rs58542926 T/C gene polymorphism and significant liver fibrosis: A meta-analysis", "abstract": "Aim: To further explore the association between Transmembrane 6 superfamily member 2(TM6SF2) rs58542926 T/C gene polymorphism and hepatic fibrosis.\nMaterials and Methods: In this study the MEDLINE, PubMed, EMBASE, and CENTRAL databases were queried from inception to March 21, 2020. According to inclusion and exclusion criteria; case control studies assessing the relationship between TM6SF2 rs58542926 T/C gene polymorphism and significant liver fibrosis were selected. NOS scale was used to evaluate the included literature. Stata 12.0 software was used for data analysis.\nResults: In this meta analysis: a total of 7 articles, including 2286 patients were included. Statistical analysis showed that the TM6SF2 gene polymorphism was  associated with significant liver fibrosis in the allele contrast, recessive dominant models (T vs. C, OR=1.292, 95%CI 1.035-1.611, P=0.023; TT vs. CT+CC, OR=2.829, 95%CI 1.101-7.267, P=0.031). No significant publication bias was found after Egger\u2032s test.", "filename": "2020.10.11.20210690v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210690 "}, {"title": "alpha4beta2* Nicotinic Cholinergic Receptor Target Engagement in Parkinson Disease", "abstract": "Objective:  Attentional function deficits secondary to degeneration of brain cholinergic systems are significant contributors to gait-balance deficits in Parkinson disease (PD).  To assess whether alpha4beta2* nicotinic acetylcholine receptor (nAChR) stimulation improves attention and gait-balance function, we performed a target engagement study of the alpha4beta2* nAChR partial agonist varenicline.\nMethods:  Non-demented PD participants with cholinergic deficits were identified with [18F]fluoroethoxybenzamicol positron emission tomography (PET).  alpha4beta2* nAChR occupancy after subacute oral varenicline treatment was measured with [18F]flubatine PET.  With a dose selected from the receptor occupancy experiment, varenicline effects on gait, balance, and cognition were assessed in a double-masked placebo-controlled crossover study.  Primary endpoints were normal pace gait speed and a measure of postural stability.\nResults:  Varenicline, 0.25 mg per day, 0.25 mg b.i.d., 0.5 mg b.i.d., and 1.0 mg b.i.d., produced 60% - 70% receptor occupancy, with 0.5 mg po b.i.d chosen for the crossover study.  Thirty-three (of thirty-four) participants, completed the crossover study with excellent tolerability.  Varenicline had no impact on the postural stability measure and resulted in slower normal pace gait speed.  Varenicline reduced distraction effects under dual task gait conditions and improved performance on a sustained attention test.  In 28 participants in whom treatment compliance was confirmed by plasma varenicline measurements, we obtained identical conclusions.  \nInterpretation:  Varenicline occupied a significant fraction of alpha4beta2* nicotinic acetylcholine receptors, was tolerated well, enhanced attentional function, and improved dual task gait performance. alpha4beta2* nicotinic agonists may be useful in mitigating gait and balance disorders in PD.", "filename": "2020.10.11.20210914v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210914 "}, {"title": "Evaluating Short-term Forecast among Different Epidemiological Models under a Bayesian Framework", "abstract": "Forecasting of COVID-19 daily confirmed cases has been one of the several challenges posed on the governments and health sectors on a global scale.  To facilitate informed public health decisions, the concerned parties rely on short-term daily projections generated via predictive modeling. We calibrate stochastic variants of growth models and the standard SIR model into one Bayesian framework to evaluate their short-term forecasts. In summary, it was noted that none of the models proved to be golden standards across all the regions in their entirety, while all outperformed ARIMA in a predictive capacity as well as in terms of interpretability.", "filename": "2020.10.11.20210971v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210971 "}, {"title": "Awareness, Perception and Practice Of COVID 19 Prevention among Residents of a State in the South-South Region Of Nigeria: Implications for Public Health Control Efforts", "abstract": "ABSTRACT\nBackground\nThis research explored awareness, perception, and practice of COVID 19 prevention among residents of communities in all the local government areas (districts) in Rivers State during the early stages of the pandemic response. \nDesign\nThis was a descriptive cross-sectional survey which employed an interviewer-administered four-page questionnaire built into the Open Data Kit application for android phones. Knowledge and practice scores were computed by scoring every correct response/action as 1 and wrong responses as 0. Knowledge was graded as excellent for scores of \u226580%, good for scores of 50-79% and poor for scores of <50%. Respondents who washed all critical parts of the hand were categorized as having correct handwashing practice. \nSetting\nRivers State in the South-South region of Nigeria had recorded over 2000 cases of COVID 19 as of 18th August 2020, ranking 5th among the high burden states in Nigeria. As with any epidemic of an infectious nature, panic, fear, and misconceptions are rife. Risk communication utilizes multi-faceted activities geared towards facilitating correct and consistent knowledge and prevention practice.\nParticipants\nStudy involved 1,294 adult community residents in the 23 districts of the state.\nResults\nThe respondents were aged between 18 and 80 years with average age of 39.6 years (SD = 11.9 years). A total of 710 (54.9%) were male, 476 (36.8%) were unemployed with 685 (52.9%) having secondary education. Almost all respondents 1,271 (98.2%) had heard about COVID 19. The three most common sources of information about COVID 19 were radio jingles 1102 (86.7%), television adverts 940 (74.0%) and announcements in Church 612 (48.2%). Overall, 608 (47.0%) of the respondents had poor knowledge of COVID 19. About 1167 (90.2%) of the respondents who were aware of COVID 19 acknowledged that COVID 19 is a problem in the state while 443 (34.9%) respondents believed they were unlikely contract the virus. Only 505 (39.0%) of the respondents washed all critical parts of the hand correctly.\nConclusion\nRisk communication interventions during pandemics need to be based on an understanding of the gaps in knowledge, attitude, perceptions, and practice. Broadcast media has a pivotal role to play in risk communication for behaviour change for the control of current and future epidemics in this population.", "filename": "2020.10.11.20210864v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210864 "}, {"title": "COVID-19 behavioural insights study: Preliminary findings from Finland, April-May, 2020", "abstract": "The COVID-19 monitoring behavioural insights study was conducted from April-May 2020 in Finland. Respondents reported feeling confident protecting themselves against COVID-19 infection. Worries shifted from overloading the health system (mean value 5.5 [95% CI: 5.4-5.6]) to mental health concerns (mean value 5.3 [95% CI 5.2-5.4]). Maintaining physical distancing from families and friends decreased by 7% and 6%. Respondents mostly agreed that if a vaccine would become available, they would get it. The decrease in acceptance of recommended measures needs further analysis, but current results provide evidence to support the response.", "filename": "2020.10.11.20210724v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210724 "}, {"title": "Symptoms associated with SARS-CoV-2 infection in a community-based population: Results from an epidemiological study", "abstract": "Background: Studies examining symptoms of COVID-19 are primarily descriptive and measured among hospitalized individuals. Understanding symptoms of SARS-CoV-2 infection may improve clinical screening, particularly during flu season. We sought to identify key symptoms and symptom combinations in a community-based population.\nMethods: We pooled statewide, community-based cohorts of individuals aged 12 and older screened for SARS-CoV-2 infection in April and June 2020. Main outcome was SARS-CoV-2 positivity. We calculated sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) for individual symptoms as well as symptom combinations. We further employed multivariable logistic regression and exploratory factor analysis (EFA) to examine symptoms and combinations associated with SARS-CoV-2 infection.\nResults: Among 8214 individuals screened, 368 individuals (4.5%) were RT-PCR positive for SARS-CoV-2. Although two-thirds of symptoms were highly specific (>90.0%), most symptoms individually possessed a PPV <50.0%. The individual symptoms most greatly associated with SARS-CoV-2 positivity were fever (OR=5.34, p<0.001), anosmia (OR=4.08, p<0.001), ageusia (OR=2.38, p=0.006), and cough (OR=2.86, p<0.001). Results from EFA identified two primary symptom clusters most associated with SARS-CoV-2 infection: (1) ageusia, anosmia, and fever; and (2) shortness of breath, cough, and chest pain. Moreover, being non-white (13.6% vs. 2.3%, p<0.001), Hispanic (27.9% vs. 2.5%, p<0.001), or living in an Urban area (5.4% vs. 3.8%, p<0.001) was associated with infection.\nConclusions: When laboratory testing is not readily accessible, symptoms can help distinguish SARS-CoV-2 infection from other respiratory viruses. Symptoms should further be structured in clinical documentation to support identification of new cases and mitigation of disease spread by public health. These symptoms, derived from mildly infected individuals, can also inform vaccine and therapeutic clinical trials.", "filename": "2020.10.11.20210922v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210922 "}, {"title": "The revelation of Novel Mutations in Human Luteinizing Hormone Beta Subunit Related to Polycystic Ovary Syndrome among Sudanese Women", "abstract": "Introduction: Polycystic ovary syndrome (POCS) is a mystery disorder with mysterious multiple players characterized by their mystic effects on disease pathophysiology resulting in various phenotypic pictures among the PCOS population. The Luteinizing hormone beta subunit (LH-B) (protein ID P01229) is a gonadotropin hormone secreted from the anterior pituitary belongs to the glycoprotein family, mapped on (chr19p13.3) and consists of three exons. It has a central role in promoting ovulation via stimulation of ovarian steroidogenesis.                                                                                    \nObjectives: This is a prospective laboratory-based cross-sectional study to determine genetic mutations associate with polycystic ovary syndrome (PCOS) among (30) Sudanese families ((cases n=35 families, 90 females, and (controls n= 11 families, 30 females) in Khartoum State, Sudan. \nMethods: Quantitative Enzyme-Linked Immuno-Sorbent Assay (ELISA), enzymatic methods, and polymerase chain reaction (PCR) used to analyze both the biochemical parameters and polymorphism detection followed by Sanger sequencing for genotyping in addition to bioinformatics software for protein structure and function.   \nResults: All the biochemical parameters levels of (FBG, LH, Testosterone, Insulin, and lipid profile) elevated from the control group were statistically significant except for the serum FSH (cases=5.4\u00b14.6, controls=5.3\u00b12.8) and PRL ((cases=12.4\u00b18.2, controls=8.0\u00b16.1)) which were statistically insignificant p=0.94 and p=0.06. After Sanger sequencing; (5) single nucleotide polymorphisms ((rs5030775, A18T), rs746167425, R22K), (rs1800447, W28R), (rs35270001, H30R) and (rs34349826, I35T)) located on (exon 2) of the LH beta gene was statistically significant with serum LH, Testosterone, and insulin levels among PCOS families. \nConclusion: This is the first molecular identification of a family-based study in Sudan exploring the genetic of the LHB gene and interrelated its serum level with PCOS manifestation. The revelation of these mutations will give a clue to the genetic inheritance mode links and might explain the abnormal poor response of controlled ovarian stimulation tests in some PCOS women.", "filename": "2020.10.11.20208926v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20208926 "}, {"title": "SARS-CoV-2 (COVID-19) infection in pregnant women: characterization of symptoms and syndromes predictive of disease and severity through real-time, remote participatory epidemiology.", "abstract": "Objective: To test whether pregnant and non-pregnant women differ in COVID-19 symptom profile and severity. To extend previous investigations on hospitalized pregnant women to those who did not require hospitalization.\nDesign: Observational study prospectively collecting longitudinal (smartphone application interface) and cross-sectional (web-based survey) data.\nSetting: Community-based self-participatory citizen surveillance in the United Kingdom, Sweden and the United States of America.\nPopulation: Two female community-based cohorts aged 18-44 years. The discovery cohort was drawn from 1,170,315 UK, Sweden and USA women (79 pregnant tested positive) who self-reported status and symptoms longitudinally via smartphone. The replication cohort included 1,344,966 USA women (134 pregnant tested positive) who provided cross-sectional self-reports. \nMethods: Pregnant and non-pregnant were compared for frequencies of symptoms and events, including SARS-CoV-2 testing and hospitalization rates. Multivariable regression was used to investigate symptoms severity and comorbidity effects.\nResults: Pregnant and non-pregnant women positive for SARS-CoV-2 infection were not different in syndromic severity. Pregnant were more likely to have received testing than non-pregnant, despite reporting fewer symptoms. Pre-existing lung disease was most closely associated with the syndromic severity in pregnant hospitalized women. Heart and kidney diseases and diabetes increased risk. The most frequent symptoms among all non-hospitalized women were anosmia [63% pregnant, 92% non-pregnant] and headache [72%, 62%]. Cardiopulmonary symptoms, including persistent cough [80%] and chest pain [73%], were more frequent among pregnant women who were hospitalized. \nConclusions: Symptom characteristics and severity were comparable among pregnant and non-pregnant women, except for gastrointestinal symptoms. Consistent with observations in non-pregnant populations, lung disease and diabetes were associated with increased risk of more severe SARS-CoV-2 infection during pregnancy.", "filename": "2020.08.17.20161760v2", "doi": "doi: https://doi.org/10.1101/2020.08.17.20161760 "}, {"title": "COVID-19 superspreading in cities versus the countryside", "abstract": "So  far,  the  COVID-19  pandemic  has  been  characterised  by  an  initial  rapid  rise  in  new  cases followed by a peak and a more erratic behaviour that varies between regions.  This is not easy to reproduce with traditional SIR models, which predict a more symmetric epidemic.  Here, we argue that superspreaders and population heterogeneity are the core factors explaining this discrepancy. We do so through an agent-based lattice model of a disease spreading in a heterogeneous population.We predict that an epidemic driven by superspreaders will spread rapidly in cities, but not in the countryside where the sparse population limits the maximal number of secondary infections.  This suggests that mitigation strategies should include restrictions on venues where people meet a largenumber of strangers.  Furthermore,  mitigating the epidemic in cities and in the countryside may require different levels of restrictions.", "filename": "2020.09.04.20188359v2", "doi": "doi: https://doi.org/10.1101/2020.09.04.20188359 "}, {"title": "COVID-19 Preprints and Their Publishing Rate: An Improved Method", "abstract": "Abstract\nContext: As the COVID-19 pandemic persists around the world, the scientific community continues to produce and circulate knowledge on the deadly disease at an unprecedented rate. During the early stage of the pandemic, preprints represented nearly 40% of all English-language COVID-19 scientific corpus (6,000+ preprints | 16,000+ articles). As of mid-August 2020, that proportion dropped to around 28% (13,000+ preprints | 49,000+ articles). Nevertheless, preprint servers remain a key engine in the efficient dissemination of scientific work on this infectious disease. But, giving the uncertified nature of the scientific manuscripts curated on preprint repositories, their integration to the global ecosystem of scientific communication is not without creating serious tensions. This is especially the case for biomedical knowledge since the dissemination of bad science can have widespread societal consequences.\nScope: In this paper, I propose a robust method that allows the repeated monitoring and measuring of COVID-19 preprints' publication rate. I also introduce a new API called Upload-or-Publish. It is a free micro-API service that enables a client to query a specific preprint manuscript's publication status and associated meta-data using a unique ID. The beta-version is currently working and deployed.\nData: I use Covid-19 Open Research Dataset (CORD-19) to calculate COVID-19 preprint corpus' conversion rate to peer-reviewed articles. CORD-19 dataset includes 10,454 preprints from arXiv, bioRxiv, and medRxiv. \nMethods: I utilize conditional fuzzy logic to link preprints with their published counterparts. My approach is an important departure from previous studies that rely exclusively on bio/medRxiv API to ascertain preprints' publication status. \nFindings: As expected, the findings suggest a positive relationship between the time elapsed since preprints' first server upload and preprints harboring a published status. For instance, as of mid-September, close to 50% of preprints uploaded in January were published in peer-review venues. That figure is at 29% for preprints uploaded in April, and 5% for preprints uploaded in August. As this is an ongoing project, it will continue to track the publication rates of preprints over time.", "filename": "2020.09.04.20188771v4", "doi": "doi: https://doi.org/10.1101/2020.09.04.20188771 "}, {"title": "A Deep Learning Based Cardiac Cine Segmentation Framework for Clinicians - Transfer Learning Application to 7T", "abstract": "Artificial neural networks show promising performance in automatic segmentation of cardiac MRI. However, training requires large amounts of annotated data and generalization to different vendors, field strengths, sequence parameters, and pathologies is limited. Transfer learning addresses this challenge, but recommendations regarding type and amount of required data is lacking. In this study we assess data requirements for transfer learning to experimental cardiac MRI at 7T where the segmentation task can be challenging. In addition, we provide guidelines, tools, and annotated data to enable transfer learning approaches by other researchers and clinicians. A publicly available segmentation model was used to annotate a publicly available dataset. This labelled dataset was subsequently used to train a neural network for segmentation of left ventricle and myocardium in cardiac cine MRI. The network is used as starting point for transfer learning to 7T cine data of healthy volunteers (n=22; 7873 images). Structured and random data subsets of different sizes were used to systematically assess data require-ments for successful transfer learning. On 7T cardiac cine images the initial model achieved DICE(LV)=0.835 and DICE(MY)=0.670. Transfer learning using 7T cine data and ImageNet weight initialization improved model performance to DICE(LV)=0.900 and DICE(MY)=0.791. Using only end-systolic and end-diastolic images reduced training data by 90%, with no negative impact on segmentation performance (DICE(LV)=0.908, DICE(MY)=0.805). This work demonstrates and quantifies the benefits of transfer learning for cardiac cine image segmentation. We provide practical guidelines for researchers planning transfer learning projects in cardiac MRI and make data, models and code publicly available.", "filename": "2020.06.15.20131656v2", "doi": "doi: https://doi.org/10.1101/2020.06.15.20131656 "}, {"title": "Transmission of SARS-CoV-2 from Children and Adolescents", "abstract": "A better understanding of SARS-CoV-2 transmission from children and adolescents is crucial for informing public health mitigation strategies. We conducted a retrospective cohort study among household contacts of primary cases defined as children and adolescents aged 7-19 years with laboratory evidence of SARS-CoV-2 infection acquired during an overnight camp outbreak. Among household contacts, we defined secondary cases using the Council of State and Territorial Epidemiologists definition. Among 526 household contacts of 224 primary cases, 48 secondary cases were identified, corresponding to a secondary attack rate of 9% (95% confidence interval [CI], 7%-12%). Our findings show that children and adolescents can transmit SARS-CoV-2 to adult contacts and other children in a household setting.", "filename": "2020.10.10.20210492v2", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210492 "}, {"title": "The effect of a specialist paramedic primary care rotation on appropriate non-conveyance decisions: a controlled interrupted time series analysis", "abstract": "Introduction\nNHS ambulance service conveyance rates in the UK are almost 70%, despite an increase in non-emergency cases. This is increasing the demands on crowded emergency departments (ED) and contributes to increased ambulance turnaround times. Yorkshire Ambulance Service introduced a specialist paramedic (SP) role to try and address this, but non-conveyance rates in this group have not been as high as expected.\n\nMethods\nWe conducted a controlled interrupted time series analysis of appropriate non-conveyance rates in the 12 months before and after an SP primary care placement, using matched groups of patients cared for by SPs and control paramedics. A costing analysis examined the average cost per appropriate non-conveyance and the cost-effectiveness ratio between groups.\n\nResults\nBetween June 2017 and December 2019 there were 7349 incidents attended by intervention group SPs and eligible for inclusion. Following removal of cases with missing data, 5537/7349 (75.3%) cases remained. Post-placement, the intervention group demonstrated an increase in appropriate non-conveyance rate by 35.0% (95%CI 23.8-46.2%, p<0.001) and a reduction in the trend of appropriate non-conveyance relative to the control group of -1.2% (95%CI -2.8-0.5%, p=0.156).\n\nPost-placement, the cost per appropriate non-conveyance for intervention paramedics was a mean of GBP509.42 (95% bootstrapped CI GBP485.94-GBP535.41) versus GBP1124.41 (95% bootstrapped CI GBP1041.89-GBP1218.31) for the control group. This represents a mean saving of GBP615 per appropriate non-conveyance (95% bootstrapped CI GBP545.31-GBP686.69) for SPs compared to the control group, and a cost-effectiveness ratio of GBP1758.89 per percentage increase in appropriate non-conveyance (95% bootstrapped CI GBP1477.76-GBP2133.08).\n\nConclusion\nIn this single UK NHS ambulance service study, we found a clinically important and statistically significant increase in appropriate non-conveyance rates by specialist paramedics who had completed a 10-week GP placement. This improvement persisted for the 12-month period following the placement and demonstrated cost savings compared to usual care.", "filename": "2020.08.06.20169334v2", "doi": "doi: https://doi.org/10.1101/2020.08.06.20169334 "}, {"title": "Tracing and testing the COVID-19 contact chain: cost-benefit tradeoffs", "abstract": "Traditional contact tracing for COVID-19 tests the direct contacts of those who test positive even if the contacts do not show any symptom. But, why should the testing stop at direct contacts, and not test secondary, tertiary contacts or even contacts further down? The question arises because by the time an infected individual is tested the infection starting from him may have infected a chain of individuals. One deterrent in testing long chains of individuals right away may be that it substantially increases the testing load, or does it? We investigate the costs and benefits of testing the contact chain of an individual who tests positive. For this investigation, we utilize multiple human contact networks, spanning two real-world data sets of spatio-temporal records of human presence over certain periods of time, as also networks of a classical synthetic variety. Over the diverse set of contact patterns, we discover that testing the contact chain can both substantially reduce over time both the cumulative infection count and the testing load. We consider elements of human behavior that enhance the spread of the disease and lower the efficacy of testing strategies, and show that testing the contact chain enhances the resilience to adverse impacts of these elements. We also discover a phenomenon of diminishing return beyond a threshold value on the depth of the chain to be tested in one go, the threshold then provides the most desirable tradeoff between benefit in terms of reducing the cumulative infection count, enhancing resilience to adverse impacts of human behavior, and cost in terms of increasing the testing load.", "filename": "2020.10.01.20205047v2", "doi": "doi: https://doi.org/10.1101/2020.10.01.20205047 "}, {"title": "Living alone, loneliness and lack of emotional support as predictors of suicide and self-harm: a nine-year follow up of the UK Biobank cohort", "abstract": "Background: The association between loneliness and suicide is poorly understood. We investigated how living alone, loneliness and emotional support were related to suicide and self-harm in a longitudinal design.\nMethods: Between 2006 and 2010 UK Biobank recruited and assessed in detail over 0.5 million people in middle age. Data were linked to prospective hospital admission and mortality records. Adjusted Cox regression models were used to investigate relationships between living arrangements, loneliness and emotional support, and both suicide and self-harm as outcomes.\nResults: For men, both living alone (Hazard Ratio (HR) 2.16, 95%CI 1.51-3.09) and living with non-partners (HR 1.80, 95%CI 1.08-3.00) were associated with death by suicide, independently of loneliness, which had a modest relationship with suicide (HR 1.43, 95%CI 0.1.01-2.03). For women, there was no evidence that living arrangements, loneliness or emotional support were associated with death by suicide. Associations between living alone and self-harm were explained by health for women, and by health, loneliness and emotional support for men. In fully adjusted models, loneliness was associated with hospital admissions for self-harm in both women (HR 1.89, 95%CI 1.57-2.28) and men (HR 1.74, 95%CI 1.40-2.16).\nLimitations: Loneliness and emotional support were operationalized using single item measures. \nConclusions: For men - but not for women - living alone or living with a non-partner increased the risk of suicide, a finding not explained by subjective loneliness. Overall, loneliness may be more important as a risk factor for self-harm than for suicide. Loneliness also appears to lessen the protective associations of cohabitation.", "filename": "19008458v3", "doi": "doi: https://doi.org/10.1101/19008458 "}, {"title": "Prevalence and Outcomes in COVID-19 patients with AKI: A meta-analysis", "abstract": "Objectives: The coronavirus strain first reported in December 2019 (COVID-19) has spread rapidly worldwide, posing a seriously risk to human health. This meta-analysis aims to shed much-needed light on the relationship between COVID-19 and AKI, and provide a stronger evidence base to support both further research and clinical application.\nMethods: Two authors independently performed a literature search using PubMed, Web of Science, Embase, and Cochrane Library. Then the incidence of AKI, incidence of RRT required, the mortality rate with AKI and the risk of death with AKI during a COVID-19 infection were statistically analyzed using Open Meta-Analyst software, from which conclusions are derived. \nResults: The incidence of AKI in hospitalized patients with the COVID-19 infection remains low, only about 3.8%; the in-hospital mortality rate with AKI in COVID-19 infected patients reaches up to 86.8%; the odds of death with AKI in COVID-19 infected patients is about 24.2 times higher than those without AKI.\nConclusions: The occurrence of AKI during a COVID-19 infection should be considered a strong red flag with regards to the patient's risk of death. Additional studies are still required to support the conclusions derived herein and to explore the AKI mechanism during a COVID-19 infection.", "filename": "2020.04.29.20079038v3", "doi": "doi: https://doi.org/10.1101/2020.04.29.20079038 "}, {"title": "Predicted Infection Risk for Aerosol Transmission of SARS-CoV-2", "abstract": "Currently, airborne transmission is seen as the most important transmission path for SARS-CoV-2. In this investigation, models of other researchers with the aim to predict an infection risk for exposed persons in a room through aerosols emitted by an infectious case-patient were extended. As a novelty parameters or boundary conditions, namely the non-stationarity of aerosol and the half life of aerosolized virus, were included and a new method for determining the quanta emission rate based on measurements of the particle emission rate and respiratory rate at different types of activities was implemented.\nAs a second step, the model was applied to twelve outbreaks to compare the predicted infection risk with the observed attack rate. To estimate a 'credible interval' of the predicted infection risk the quanta emission rate, the respiratory rate as well as the air volume flow were varied.\nIn nine out of twelve outbreaks, the calculated predicted infection risk via aerosols was found to be in the range the attack rate (with the variation of the boundary conditions) and reasons for the observed larger divergence were discussed. \nThe validation was considered successful and therefore, the use of the model could be recommended to predict the risk of an infection via aerosols in given situations. Furthermore, appropriate preventive measures can be designed.", "filename": "2020.10.08.20209106v2", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209106 "}, {"title": "FORECASTING COMBINATION OF HIERARCHICAL TIME SERIES: A NOVEL METHOD WITH AN APPLICATION TO COVID-19", "abstract": "Multiple, hierarchically organized time series are routinely submitted to the forecaster upon request to provide estimates of their future values, regardless\nthe level occupied in the hierarchy. In this paper, a novel method for the prediction of hierarchically structured time series will be presented. The idea is to enhance the quality of the predictions obtained using a technique of the type forecast reconciliation, by applying this procedure to a set of optimally combined predictions, generated by different statistical models. The goodness of the proposed method will be evaluated using the official time series related to the number of people tested positive to the SARS-CoV-2 in each of the Italian regions, between February 24th 2020 and August 31th 2020.", "filename": "2020.10.11.20210799v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210799 "}, {"title": "Synthesising artificial patient-level data for Open Science - an evaluation of five methods", "abstract": "Background\n\nOpen science is a movement seeking to make scientific research accessible to all, including publication of code and data. Publishing patient-level data may, however, compromise the confidentiality of that data if there is any significant risk that data may later be associated with individuals. Use of synthetic data offers the potential to be able to release data that may be used to evaluate methods or perform preliminary research without risk to patient confidentiality.\n\nMethods\n\nWe have tested five synthetic data methods:\n\n1. A technique based on Principal Component Analysis (PCA) which samples data from distributions derived from the transformed data.\n\n2. Synthetic Minority Oversampling Technique, SMOTE which is based on interpolation between near neighbours.\n\n3. Generative Adversarial Network, GAN, an artificial neural network approach with competing networks - a discriminator network trained to distinguish between synthetic and real data. , and a generator network trained to produce data that can fool the discriminator network.\n\n4. CT-GAN, a refinement of GANs specifically for the production of structured tabular synthetic data.\n5. Variational Auto Encoders, VAE, a method of encoding data in a reduced number of dimensions, and sampling from distributions based on the encoded dimensions.\n\nTwo data sets are used to evaluate the methods:\n\n1. The Wisconsin Breast Cancer data set, a histology data set where all features are continuous variables.\n\n2. A stroke thrombolysis pathway data set, a data set describing characteristics for patients where a decision is made whether to treat with clot-busting medication. Features are mostly categorical, binary, or integers.\n\nMethods are evaluated in three ways:\n\n1. The ability of synthetic data to train a logistic regression classification model.\n\n2. A comparison of means and standard deviations between original and synthetic data.\n\n3. A comparison of covariance between features in the original and synthetic data.\n\nResults\n\nUsing the Wisconsin Breast Cancer data set, the original data gave 98% accuracy in a logistic regression classification model. Synthetic data sets gave between 93% and 99% accuracy. Performance (best to worst) was SMOTE > PCA > GAN > CT-GAN = VAE. All methods produced a high accuracy in reproducng original data means and stabdard deviations (all R-square > 0.96 for all methods and data classes). CT-GAN and VAE suffered a significant loss of covariance between features in the synthetic data sets. Using the Stroke Pathway data set, the original data gave 82% accuracy in a logistic regression classification model. Synthetic data sets gave between 66% and 82% accuracy. Performance (best to worst) was SMOTE > PCA > CT-GAN > GAN > VAE. CT-GAN and VAE suffered loss of covariance between features in the synthetic data sets, though less pronounced than with the Wisconsin Breast Cancer data set.\n\nConclusions\n\nThe pilot work described here shows, as proof of concept, that synthetic data may be produced, which is of sufficient quality to publish with open methodology, to allow people to better understand and test methodology. The quality of the synthetic data also gives promise of data sets that may be used for screening of ideas, or for research project (perhaps especially in an education setting). More work is required to further refine and test methods across a broader range of patient-level data sets.", "filename": "2020.10.09.20210138v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210138 "}, {"title": "MIGRATION, INFECTIOUS DISEASES AND DRUG ADDICTION IN RUSSIA", "abstract": "The aim of the paper is to analyze the possible impact of various aspects of internal and external migration in regions of Russia on the prevalence of the following social dangerous diseases: HIV, active tuberculosis, syphilis, drug addiction, acute and chronic viral hepatitis B and C. We analyzed the papers that concern the impact of migration on the health of the host territory population. The main research methods are econometric and correlation analysis. We constructed panel models for each disease. The models tested various socioeconomic indicators (including education level, cash income, housing improvements and the incidence of alcoholism), as well as climatic, geographical and demographic indicators. Influence of disease incidence in the neighbouring regions is also considered. Five various indicators of migration were tested. They characterize labour immigration, internal and external migration inflows to the regions and share of people born outside the region. We tried to track changes of factors that influence spread of diseases over time. It allowed us to correct the conclusions drawn earlier. In the course of the research, positive significant statistical correlation of the following indicators of migration and disease incidence was established: \n1)\tforeign citizens employment and incidence of syphilis in 2005;\n2)\tshare of internal migrants and incidence of drug addiction in 2005;\n3)\tforeign citizens employment and incidence of drug addiction in 2006-2016;\n4)\tforeign citizens inflow and detection of chronic viral hepatitis in 2010;\n5)\tforeign citizens inflow and detection of acute hepatitis C in 2011-2016.", "filename": "2020.10.09.20209791v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209791 "}, {"title": "Group Testing with Homophily to Curb Epidemics with Asymptomatic Carriers", "abstract": "The global fight against COVID-19 is plagued by asymptomatic transmission and false negatives. Group testing is increasingly recognized as necessary to fight this epidemic. I examine the gains from considering heterogeneous interpersonal interactions (homophily), which induce potential contamination, when designing testing pools. Homophily can be identified ex ante at a scale commensurate with pool size, so that the risk of contamination is higher within a well-designed pool than with an outsider. This makes it possible to overcome the usual information-theoretic limits of group testing which rely on an implicit homogeneity assumption. More importantly, group testing with homophily detects asymptomatic carriers that would be missed even by exhaustive individual testing because of false negatives. Such a strategy should be implemented at least at a weekly frequency to fit the time profile of test positivity. It can be used either to avoid unnecessary lockdowns or to make lockdowns more efficient.", "filename": "2020.10.09.20210260v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210260 "}, {"title": "Predicting mortality of individual COVID-19 patients: A multicenter Dutch cohort", "abstract": "Objective: Develop and validate models that predict mortality of SARS-CoV-2 infected patients admitted to the hospital.\nDesign: Retrospective cohort study\nSetting: A multicenter cohort across ten Dutch hospitals including patients from February 27 to June 8 2020.\nParticipants: SARS-CoV-2 positive patients (age \u2265 18) admitted to the hospital.\nMain Outcome Measures: 21-day mortality evaluated by the area under the receiver operatory curve (AUC), sensitivity, specificity, positive predictive value and negative predictive value. The predictive value of age was explored by comparison with age-based rules used in practice and by excluding age from analysis.\nResults: 2273 patients were included, of whom 516 had died or discharged to palliative care within 21 days after admission. Five feature sets, including premorbid, clinical presentation and laboratory & radiology values, were derived from 80 features. Additionally, an ANOVA-based data-driven feature selection selected the ten features with the highest F-values: age, number of home medications, urea nitrogen, lactate dehydrogenase, albumin, oxygen saturation (%), oxygen saturation is measured on room air, oxygen saturation is measured on oxygen therapy, blood gas pH and history of chronic cardiac disease. A linear logistic regression (LR) and non-linear tree-based gradient boosting (XGB) algorithm fitted the data with an AUC of 0.81 (95% confidence interval 0.77 to 0.85) and 0.82 (0.79 to 0.85), respectively, using the ten selected features. Both models outperformed age-based decision rules used in practice (AUC of 0.69, 0.65 to 0.74 for age > 70).  Furthermore, performance remained stable when excluding age as predictor (AUC of 0.78, 0.75 to 0.81)\nConclusion: Both models showed excellent performance and had better test characteristics than age-based decision rules, using ten admission features readily available in Dutch hospitals. The models hold promise to aid decision making during a hospital bed shortage.", "filename": "2020.10.10.20210591v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210591 "}, {"title": "Gargle-Direct: Extraction-Free Detection of SARS-CoV-2 using Real-time PCR (RT-qPCR) of Saline Gargle Rinse Samples", "abstract": "Background: Saline mouth rinse/gargle samples have recently been shown to be a suitable option for swab-independent self-collection for SARS-CoV-2 diagnosis. We sought to evaluate a simplified process for direct reverse transcriptase PCR(RT-qPCR) testing of this novel sample type and to compare performance with routine RT-qPCR using automated nucleic acid extraction. Methods: Clinical saline mouth rinse/gargle samples were subjected to automated nucleic acid extraction (standard method), followed by RT-qPCR using three assays including the FDA authorized US-CDCs N1/N2 assay, which was the reference standard for determining sensitivity/specificity. For extraction-free workflow, an aliquot of each gargle sample underwent viral heat inactivation at 65 \u00b0C for 20 minutes followed by RT-qPCR testing, without an intermediate extraction step. An in-house validated RT-qPCR lab developed test (LDT), targeting the SARS-CoV-2, S/ORF8 genes (SORP triplex assay) and the N1/N2 US-CDC assay was used to evaluate the extraction-free protocol. To improve the analytical sensitivity, we developed a single-tube hemi-nested (STHN) version of the SORP triplex assay. Results: A total of 38 SARS-CoV-2 positive and 75 negative saline mouth rinse/gargle samples were included in this evaluation. A 100% concordance in detection rate was obtained between the standard method and the extraction-free approach for the SORP assay. An average increase of +2.63 to +5.74 of the cycle threshold (CT) values was observed for both the SORP and N1/N2 assay when extraction-free was compared between the standard method. The average \u0394CT [(\u0394CT=CT(Direct PCR)-CT(Extracted RNA)], for each of the gene targets were: S (\u0394CT= +4.24), ORF8 (\u0394CT=+2.63), N1 (\u0394CT=+2.74) and N2 (\u0394CT=+5.74). The \u0394CT for the STHN SORP assay was +1.51 and -2.05 for the S and ORF8 targets respectively, when extracted method was compared to the standard method. Conclusion: Our Gargle-Direct SARS-CoV-2 method is operationally simple, minimizes pre-analytical sample processing and is potentially implementable by most molecular diagnostic laboratories. The empirical demonstration of single-tube hemi-nested RT-qPCR, to specifically address and alleviate the widely-acknowledged problem of reduced analytical sensitivity of detection of extraction-free templates, should help diagnostic laboratories in choosing Gargle-Direct protocol for high-throughput testing.", "filename": "2020.10.09.20203430v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20203430 "}, {"title": "Antibody-dependent enhancement (ADE) of SARS-CoV-2 infection in recovered COVID-19 patients: studies based on cellular and structural biology analysis", "abstract": "Antibody-dependent enhancement (ADE) has been reported in several virus infections including dengue fever virus, severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) coronavirus infection. To study whether ADE is involved in COVID-19 infections, in vitro pseudotyped SARS-CoV-2 entry into Raji cells, K562 cells, and primary B cells mediated by plasma from recovered COVID-19 patients were employed as models. The enhancement of SARS-CoV-2 entry into cells was more commonly detected in plasma from severely-affected elderly patients with high titers of SARS-CoV-2 spike protein-specific antibodies. Cellular entry was mediated via the engagement of Fc\u03b3RII receptor through virus-cell membrane fusion, but not by endocytosis. Peptide array scanning analyses showed that antibodies which promote SARS-CoV-2 infection targeted the variable regions of the RBD domain. To further characterize the association between the spike-specific antibody and ADE, an RBD-specific monoclonal antibody (7F3) was isolated from a recovered patient, which potently inhibited SARS-Cov-2 infection of ACE-2 expressing cells and also mediated ADE in Raji cells. Site-directed mutagenesis the spike RBD domain reduced the neutralization activity of 7F3, but did not abolish its binding to the RBD domain. Structural analysis using cryo-electron microscopy (Cryo-EM) revealed that 7F3 binds to spike proteins at a shift-angled pattern with one up and two down RBDs, resulting in partial overlapping with the receptor binding motif (RBM), while a neutralizing monoclonal antibody that lacked ADE activity binds to spike proteins with three up RBDs, resulting in complete overlapping with RBM. Our results revealed that ADE mediated by SARS-CoV-2 spike-specific antibodies could result from binding to the receptor in slightly different pattern from antibodies mediating neutralizations. Studies on ADE using antibodies from recovered patients via cell biology and structural biology technology could be of use for developing novel therapeutic and preventive measures for control of COVID-19 infection.\n\u2003", "filename": "2020.10.08.20209114v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209114 "}, {"title": "Antimicrobial Resistance, Evidences on Irrational Anti-microbial Prescribing and Consumption during COVID-19 Pandemic and Possible Mitigation Strategies: A Bangladesh Perspective", "abstract": "There are evidences that show increased antimicrobial consumption among COVID 19 patients. This has increased the burden on worsening situation of antimicrobial resistance (AMR) throughout the world. Bangladesh, one of the countries with highest numbers of COVID 19 cases, without effective regulation of antimicrobial prescription may suffer in future with study results showing a significant proportion of participants taking antimicrobial without proper indication and prescription from physicians. Suggested mitigation strategies include  strict regulation of over the counter (OTC) antimicrobial prescription, testing biochemical marker such as procalcitonin prior to initiation of antimicrobial therapy, introduction of color coded and tightly sealed bottled antimicrobial drugs, massive campaigning on social media, effective utilization of telemedicine and finally, raising awareness among physicians and patients regarding judicial use of antimicrobial.", "filename": "2020.10.09.20210377v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210377 "}, {"title": "COVID-19 trends in Colombian regions with the highest disease burden", "abstract": "Introduction: COVID-19 pandemic is currently the most significant global public health challenge, with more than 31 million cases reported to date. Colombia first reported COVID-19 cases in the country by early March 2020, and six months later it has reached ~750,471 clinical cases, with significant regional differences in morbidity, mortality, and hospitalization rates. \nAims: Identify population characteristics and hospital capacity in the 13 municipalities with the highest disease notification and examine differences in cumulative reported cases, hospitalization, and mortality rates that may explain the regional differences.\nMaterials and methods: A multi-group ecological study was performed based on the information available from public databases. Notification of cases, hospitalization, and crude mortality and age-adjusted rates were calculated.\nResults: The municipalities with the highest COVID-1 burden at different times during the study period displayed significant differences in population density and the proportion of elderly inhabitants, indigenous and afro descendants minorities; indices of unsatisfied basic needs and multidimensional poverty index, as well as the number of hospital beds. Likewise, essential variations in notification rates, hospitalization, and mortality were observed. The highest age-adjusted of reported cases (4,219 cases) and mortality (230.4 cases) rates were found in Leticia, the lowest general hospitalization rates in Buenaventura (37.5 cases) and the lowest ICU hospitalization rates (0) in Leticia and Tumaco due to a lack of these units in these municipalities.\nConclusion: The probability of getting sick, hospitalized, and dying from COVID-19 appeared closely related to socio-economic, ethnic, and cultural characteristics, and also to hospital bed capacity.", "filename": "2020.10.09.20210187v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210187 "}, {"title": "Development and evaluation of a new IgM/IgG rapid diagnostic test for SARS-CoV-2", "abstract": "There is an urgent need in rapid diagnostic test (RDT) to detect antibodies against SARS-CoV-2. We have developed a rapid and simple point-of-care lateral flow immunoassay (LFIA) detecting IgM and IgG against SARS-CoV-2 in 10 minutes. The aim of this study is to evaluate the diagnostic performance of this RDT. RT-PCR positive plasma samples (n=35) for SARS-CoV-2 and 97 negative control samples were studied. Diagnostic performance of IgG/IgM RDT was assessed using both gold standard RT-PCR and Electro-chemiluminescence immunoassay (ECLIA) Elecsys Anti-SARS-CoV-2 total Ig. Overall, RDT sensitivity was 100% (95% confidence interval [95%CI]: 88-100%) and specificity 93% (95% CI: 85-97%). This IgG/IgM RDT done in plasma displays a high diagnostic accuracy for SARS-CoV-2 IgG/IgM in high COVID-19 prevalence settings. Its use could be considered in the absence of routine diagnostic serology facilities for samples collected between 10 and 180 days after symptoms onset.", "filename": "2020.10.09.20209866v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209866 "}, {"title": "Value CMR: Towards a Comprehensive, Rapid, Cost-Effective Cardiovascular Magnetic Resonance Imaging", "abstract": "CMR is considered the gold standard for measuring heart function, including cardiac volumes and mass. Further, in a single CMR exam, information about cardiac function, structure, tissue composition, and blood flow could be obtained. Nevertheless, CMR is underutilized due to long scanning times, the need for multiple breath-holds, use of a contrast agent, and relatively higher cost compared to echocardiography. \nIn this study, we propose a rapid CMR exam based on recent developments in imaging sequences. The proposed exam is both rapid and provides comprehensive cardiovascular information without the need for a contrast agent or multiple breath-holds. The developed exam includes advanced sequences for evaluating global and regional cardiac functions, myocardial tissue characterization, and flow hemodynamics in the heart, valves, and large vessels. Time-consuming conventional sequences have been replaced by advanced sequences, which resulted in reducing scan time from > 1 hour with conventional CMR exam to <20 minutes with the proposed rapid CMR exam. Specifically, conventional two-dimensional (2D) cine and phase-contrast (PC) sequences have been replaced by optimized three-dimensional (3D)-cine and four-dimensional (4D)-flow sequences, respectively. Compared to 2D cine imaging that requires 12-16 separate breath-holds, the implemented 3D-cine sequence allows for whole heart coverage in 1-2 breath-holds; thus, reducing scan time by 80-90%. Similarly, compared to 2D PC flow imaging that requires multiple breath-holds and the presence of an experienced cardiac operator for precise prescription of the imaging planes, the implemented 4D-flow sequence allows for whole-chest coverage in ~10-minute, free-breathing acquisition without the need for a navigator echo, which makes scan time independent of the patient breathing pattern. Furthermore, conventional myocardial tagging has been replaced by the fast strain-encoding (SENC) sequence, which reduces scan time from one slice per breath-hold to only one slice per heartbeat (~1 second). Finally, T1 and T2 mapping sequences are included in this proposed exam, which allow for myocardial tissue characterization without the need for contrast. The proposed rapid exam has been tested on volunteers and measurements showed good agreement with those from conventional sequences despite the significant reduction in scan time.\nIn conclusion, we propose a rapid, contrast-free, and comprehensive cardiovascular exam that does not require repeated breath-holds or a cardiac experienced operator to run the exam, which would result in improving cost effectiveness of CMR and increasing its adoption in clinical practice.", "filename": "2020.10.09.20204305v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20204305 "}, {"title": "Electroconvulsive Therapy with a Memory Reactivation Intervention for Post-Traumatic Stress Disorder: A Randomized Controlled Trial", "abstract": "Introduction\nPost-traumatic Stress Disorder (PTSD) often does not respond to available treatments. Memories are vulnerable to disruption during reconsolidation, and electroconvulsive therapy (ECT) has amnestic effects. We sought to exploit this phenomenon as a potential treatment for PTSD with a clinical trial of patients with PTSD receiving ECT.  \n\nMethods\nPatients with severe depression with comorbid PTSD referred for ECT treatment were randomly assigned to reactivation of a traumatic or non-traumatic memory using script driven imagery prior to each ECT treatment. Primary outcomes were change in scores on the Modified PTSD Symptom Scale - Self Report (MPSS-SR) and the Clinician-Administered PTSD Scale for DSM-5 (CAPS-5). Assessments were completed by blinded raters. Secondary outcomes included a comparison of the change in heart rate (HR) while listening to the script.\n \nResults\nTwenty-eight participants were randomized, and 25 patients who completed a post-ECT assessment were included in the analysis. No significant group differences were found in the MPSS-SR or CAPS-5 scores from pre-ECT to post-ECT or 3-month follow-ups. However, both groups improved at post-ECT and 3-month follow up. Partial eta squared estimates of effect size showed large effect sizes for all outcomes (\u03b72 > 0.13). Changes in HR were not significantly different between groups or over time.\n \nConclusions\nIn this RCT, ECT paired with pre-treatment traumatic memory reactivation was not more effective for treating PTSD symptoms than ECT alone. While our primary hypothesis was not supported, our data provides further support for the efficacy of ECT for improving symptoms of PTSD with comorbid depression.", "filename": "2020.10.10.20210450v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210450 "}, {"title": "SARS-CoV-2 infects brain astrocytes of COVID-19 patients and impairs neuronal viability", "abstract": "COVID-19 patients may exhibit neuropsychiatric and/or neurological symptoms. We found that anxiety and cognitive impairment are manifested by 28-56% of SARS-CoV-2-infected individuals with mild or no respiratory symptoms and are associated with altered cerebral cortical thickness. Using an independent cohort, we found histopathological signs of brain damage in 19% of individuals who died of COVID-19. All of the affected brain tissues exhibited foci of SARS-CoV-2 infection, particularly in astrocytes. Infection of neural stem cell-derived astrocytes changed energy metabolism, altered key proteins and metabolites used to fuel neurons and for biogenesis of neurotransmitters, and elicited a secretory phenotype that reduces neuronal viability. Our data support the model where SARS-CoV-2 reaches the brain, infects astrocytes and triggers neuropathological changes that contribute to the structural and functional alterations in the brain of COVID-19 patients.", "filename": "2020.10.09.20207464v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20207464 "}, {"title": "Two modes of inhibitory neuronal shutdown distinctly amplify seizures in humans", "abstract": "Inhibitory neurons are critical for normal brain function but dysregulated in disorders such as epilepsy. At least two theories exist for how inhibition may acutely decrease during a seizure: hyperpolarization of fast-spiking (FS) inhibitory neurons by other inhibitory neurons, or depolarization block (DB) of FS neurons resulting in an inability to fire action potentials. Firing rate alone is unable to disambiguate these alternatives. Here, we show that human FS neurons can stop firing due to both hyperpolarization and DB within the same seizure. However, only DB of FS cells is associated with dramatic increases in local seizure amplitude, unobstructed traveling waves, and transient increases in excitatory neuronal firing. This result is independent of seizure etiology or focus. Computational models of DB reproduce the in vivo human biophysics. These methods enable intracellular decoding using only extracellular recordings in humans and explain the otherwise ambiguous inhibitory neuronal control of human seizures.", "filename": "2020.10.09.20204206v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20204206 "}, {"title": "Cardiac Arrhythmias in Patients with COVID-19: A Systematic review and Meta-analysis", "abstract": "Background: \nCardiac arrhythmia cannot be overlooked in patients with coronavirus disease 2019 (COVID-19) as it carries a great influence on the outcomes. Hence, this study aimed to build concrete evidence regarding the incidence of cardiac arrhythmia in patients with COVID-19.\nMethods: \nWe performed a systematic search for trusted databases/search engines including PubMed, Scopus, Cochrane library and web of science. After screening, the relevant data were extracted and the incidences from the different included studies were pooled for meta-analysis.\nResults: \nNine studies were finally included in our study consisting of 1445 patients.  The results of meta-analysis showed that the incidence of arrhythmia in patients with COVID-19 was 19.7% with 95% confidence interval (CI) ranging from 11.7 to 27.6%. There was also a significant heterogeneity (I2\u2009=\u200994.67%).\nConclusion: \nCardiac arrhythmias were highly frequent in patients with COVID-19 and observed in 19.7% of them. Appropriate monitoring by electrocardiogram with accurate and early identification of arrhythmias is important for better management and outcomes.", "filename": "2020.10.09.20209379v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209379 "}, {"title": "The Characteristics of Health Care Workers with COVID-19 and Relationship Between COVID-19 Mortality and BCG/Tuberculosis History: a multi-center study", "abstract": "Background: Today, COVID-19 pandemic has brought countries' health services into sharp focus. Despite the low incidence of cases(1.2%) and high mortality rate(2.4%) among Turkish population, the low mortality rate(0.3%) despite the high incidence(11.5%) declared in healthcare workers drew our group's attention. Therefore, we aimed to report the characteristics of infected health-care workers and investigate the relationship between BCG vaccine and tuberculosis history with COVID-19 mortality in infected health-care worker population.\nMethod: This study was conducted in three hospitals to assess the clinical presentations, disease severity and correlation with BCG vaccine and tuberculous history in COVID-19 positive health-care workers by an online questionnaire platform. The relationship between characteristics and tuberculosis history were investigated according to hospitalization status of the patients.  \nResult: Total of 465 infected healthcare workers included in the study. The rate of history of direct care and contact to tuberculosis patient, presence of previous tuberculosis treatment and BCG scar, presence of radiological infiltrations was significantly higher in hospitalized healthcare workers.  The ratio of direct care and direct contact to the patient with tuberculosis, and presence of family history of tuberculosis were statistically significantly higher in patients with radiological infiltrations.\nConclusion: Although COVID-19 risk and incidence are higher among healthcare workers compared to the normal population due to higher virus load, we think that the lower mortality rate seen in infected healthcare workers results from healthcare workers' frequent exposure to tuberculosis bacillus and the mortality-reducing effects of BCG vaccine, despite the higher hospitalization rate and radiological infiltrations due to over-triggered immune system.", "filename": "2020.10.08.20209403v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209403 "}, {"title": "Back to Basics: Correlates of HIV in a Community Sample of Urban Haiti", "abstract": "Haiti has a 2.2 % HIV prevalence (highest in the Caribbean); this has diminished from over 12% in the past three decades (depending on sex and gender, province, and neighborhood). Preliminary studies indicate that in the Cite Soleil neighborhood of Haiti (HIV prevalence >3%) as in socioeconomically equivalent adjacent neighborhoods, over 50% of girls and women experience non-partner sexual violence (NPSV), typically perpetrated by groups of men. Rates of NPSV against men in those neighborhoods were not available. Coercive sex heightens HIV risk. Accurate HIV knowledge empowers individuals (including survivors of NPSV) to assess personal HIV risk and increases likelihood of getting tested and of determining personal HIV status; thus, accurate HIV knowledge is foundational to behavioral risk reduction for victims in future consensual relationships and to engagement in either the HIV prevention or care continuum.\nBetween March and July 2017, we surveyed individuals 18 years or older (210 women, 257 men), assessing experience of NPSV, HIV knowledge, history of HIV testing, knowledge of HIV status, assessment of self-risk, and sexual risk behaviors. Nearly 30% of men and 24% of women endorsed having experienced NPSV. Knowledge of HIV transmission was low: 90% endorsed HIV myths, e.g. transmission occurs via public toilets, via sharing a glass with or by being exposed to a cough or sneeze from a person living with HIV. High endorsement of these myths contrasted with low endorsement of protective behavior: Only 14.3 % used a condom during consensual sex in the past year. Only 47.9% of the respondents had ever attended an HIV awareness program; 16% of knew their HIV status, although 79% assessed their HIV risk as moderate to high. Results regressing knowledge of HIV testing on participant characteristics indicated that women (OR=2.8), individuals with a partner (OR=2.2), individuals who attended an HIV awareness class (OR=2.1), individuals who knew someone with HIV (OR=3.9), and individuals who had an HIV test (OR=33.5) were more likely to know what an HIV test is. Participants who endorsed experiencing NPSV (OR=0.33) and those who had been diagnosed with an STI (OR=0.44) were less likely to know about HIV testing.\nExperience of NPSV combined with low HIV knowledge, awareness and testing heighten the HIV prevention needs of Cite Soleil residents and underscore the need to return to basics on the road to HIV eradication in that context.", "filename": "2020.10.10.20210476v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210476 "}, {"title": "Age-differences in information flow in executive and sensorimotor brain networks during childhood and adolescence", "abstract": "Objective: Mental disorders often emerge during adolescence, and age-related differences in connection strengths of brain networks (static connectivity) have been identified. However, little is known about the directionality of information flow (directed connectivity) in this period of brain development. \nMethods: We employed dynamic graphical models (DGM) to estimate directed functional connectivity from resting state functional magnetic resonance imaging data on 979 participants aged 6 to 17 years from the healthy brain network (HBN) sample. We tested for effects of age, sex, cognitive abilities and psychopathology on directionality. \nResults: We show robust bi-directionality in information flow between visual-medial and visual-lateral nodes of the network, in line with prior studies in adult samples. Furthermore, we found that age in this developmental sample was associated with directionality of information flow in sensorimotor and executive control networks, yet we did not find associations with cognitive abilities or psychopathology.   \nDiscussion: Our results revealed that directionality in information flow of large-scale brain networks is sensitive to age during adolescence, warranting further studies that may explore trajectories of development in more fine-grained network parcellations and in different populations.", "filename": "2020.10.09.20207936v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20207936 "}, {"title": "Using an Agent-Based Model to Assess K-12 School Re-openings Under Different COVID-19 Spread Scenarios - United States, School Year 2020/21", "abstract": "School-age children play a key role in the spread of airborne viruses like influenza due to the prolonged and close contacts they have in school settings. As a result, school closures and other non-pharmaceutical interventions were recommended as the first line of defense in response to the novel coronavirus pandemic (COVID-19). Assessing school reopening scenarios is a priority for states, administrators, parents, and children in order to balance educational disparities and negative population impacts of COVID-19. To address this challenge, we used an agent-based model that simulates communities across the United States including daycares, primary, and secondary schools to quantify the relative health outcomes of reopening schools. We explored different reopening scenarios including remote learning, in-person school, and several hybrid options that stratify the student population into cohorts (i.e., split cohort) in order to reduce exposure and disease spread. In addition, we assessed the combined impact of reduced in-person attendance in workplaces (e.g., through differing degrees of reliance on telework and/or temporary workplace closings) and school reopening scenarios to quantify the potential impact of additional transmission pathways contributing to COVID-19 spread. Scenarios where split cohorts of students return to school in non-overlapping formats resulted in significant decreases in the clinical attack rate (i.e., the percentage of symptomatic individuals), potentially by as much as 75% . These split cohort scenarios have impacts which are only modestly lesser than the most impactful 100% distance learning scenario. Split cohort scenarios can also significantly avert the number of cases--approximately 60M and 28M--depending on the scenario, at the national scale over the simulated eight-month period. We found the  results of our simulations to be highly dependent on the number of workplaces assumed to be open for in-person business, as well as the initial level of COVID-19 incidence within the simulated community. Our results show that reducing the number of students attending school leads to better health outcomes, and the split cohort option enables part-time in-classroom education while substantially reducing risk. The results of this study can support decisions regarding optimal school reopening strategies that at the population level balance education and the negative health outcomes of COVID-19.", "filename": "2020.10.09.20208876v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20208876 "}, {"title": "Discovering early imaging biomarkers of osteoradionecrosis in oropharyngeal cancer by characterization of temporal changes in computed tomography mandibular radiomic features", "abstract": "Osteoradionecrosis (ORN) is a major side-effect of radiation therapy in oropharyngeal cancer (OPC) patients. In this study, we demonstrate that early prediction of ORN is possible by analyzing the temporal evolution of mandibular subvolumes receiving radiation. For our analysis, we use computed tomography (CT) scans from 21 OPC patients treated with Intensity Modulated Radiation Therapy (IMRT) with subsequent radiographically-proven \u2265 grade II ORN, at three different time points: pre-IMRT, 2-months, and 6-months post-IMRT. For each patient, radiomic features were extracted from a mandibular subvolume that developed ORN and a control subvolume that received the same dose but did not develop ORN. We used a Multivariate Functional Principal Component Analysis (MFPCA) approach to characterize the temporal trajectories of these features. The proposed MFPCA model performs the best at classifying ORN vs Control subvolumes with an area under curve (AUC) = 0.74 (95% confidence interval (C.I.): 0.61-0.90), significantly outperforming existing approaches such as a pre-IMRT features model or a delta model based on changes at intermediate time points, i.e. at 2- and 6-month follow-up. This suggests that temporal trajectories of radiomics features derived from sequential pre- and post-RT CT scans can provide markers that are correlates of RT-induced mandibular injury, and consequently aid in earlier management of ORN.", "filename": "2020.10.09.20208827v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20208827 "}, {"title": "Extracorporeal Blood Purification in moderate and severe COVID-19 patients: a prospective cohort study", "abstract": "Introduction: COVID-19 is characterised by hyperinflammation and coagulopathy. Severe cases often develop respiratory distress, requiring mechanical ventilation and critical cases progressing to ARDS. Control of hyperinflammation has been proposed as a possible therapeutic avenue for COVID-19; extracorporeal blood purification (EBP) modalities offer an attractive mean to ameliorate maladaptive inflammation. \nWith this work, we describe the longitudinal variation of parameters of systemic inflammation in critically ill COVID-19 patients treated with blood purification using AN69ST (oXiris) hemodiafilter. \n\nMethods: We performed a time-series analysis of 44 consecutive COVID-19 cases treated with the AN69ST (oXiris) cytokine adsorbing hemodiafilter; we visualise longitudinal results of biochemical, inflammatory, blood gas- and vital sign parameters.\n\nResults: Blood purification was indicated for suspected hyperinflammation or hypercoagulation, (= CRP > 100 mg/L and/or IL-6 > 40 pg/mL and/or Ferritin > 500 ng/mL and/or Lactate Dehydrogenase > 365 U/L or D-dimers > 2000 ng/mL). \nAll patients were treated with at least 1 cycle extracorporeal continuous venovenous hemofiltration (CVVHF) with cytokine adsorbing hemodiafilter (CAH); of these, 30 severe patients received CVVHF-CAH within 4 - 12 hours of hospitalisation. Another 14 patients admitted with mild-to-moderate symptoms progressed to severe disease and placed on EBP during the course of hospitalisation. The treatment was associated with a reduction of Ferritin, C-reactive protein, Fibrinogen, several inflammatory markers and a resolution of numerous cytopenias. The observed mortality across the cohort was 36.3% across the cohort.\n\nConclusion: Extracorporeal blood purification with cytokine adsorbing hemofilter was associated with a decrease in the acute phase proteins CRP, Ferritin, and resolution of numerous cytopenias. Repetitive hemofiltration has been associated with lower levels of IL-6 in COVID-19 patients.", "filename": "2020.10.10.20210096v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210096 "}, {"title": "Individual-level response adaptive crossover trial design for epilepsy: structure and simulation", "abstract": "Trials of antiseizure medications involve static group assignments for treatments with pre-specified durations. We propose a response-adaptive crossover design using basic statistical assumptions regarding both seizure count and duration of treatment to determine when a participant can change group assignment. We modelled seizure frequency as a Poisson process and estimated the likelihood that seizure frequency had decreased by 50% compares to baseline using both a Bayesian and maximum likelihood approach. We simulated trials to estimate the influence of this design on statistical power and observation duration with each treatment. For patients with 9 baseline seizures in 4 weeks who had no change in seizure frequency, the simulation identified non-response in a median of 16 days. The response-adaptive crossover design resulted in a modest increase in statistical power to identify an effective treatment while maximizing the time in a group producing a response. Only 8% of participants remained in the placebo group for all 90 days of the simulated trials. These example theoretical results can provide quantitative guidance regarding objective criteria to determine non-response in real-time during a controlled clinical trial without revealing the assigned treatment. Implementing a response-adaptive crossover design may both improve statistical power while minimizing participant risk.", "filename": "2020.10.09.20210286v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210286 "}, {"title": "Increased aperiodic gamma power in young boys with Fragile X is associated with better language ability", "abstract": "The lack of identified clinical biomarkers in Fragile X Syndrome (FXS), the most common inherited form of intellectual disability, has limited the successful translation of bench-to-bedside therapeutics. While numerous drugs have shown promise in reversing synaptic and behavioral phenotypes in mouse models of FXS, none have demonstrated clinical efficacy in humans. Electroencephalographic (EEG) measures have been identified as candidate biomarkers as EEG recordings of both adults with FXS and mouse models of FXS consistently exhibit increased resting-state gamma power.  However, the developmental timing of these EEG differences is not known as thus far EEG studies have not focused on young children with FXS. Further, understanding how EEG differences are associated to core symptoms of FXS is crucial to successful use of EEG as a biomarker, and may improve our understanding of the disorder. Resting-state EEG was collected from FXS boys with full mutation of Fmr1 (32-84 months old, n=11) and compared with both age-matched (n=12) and cognitive-matched (n=12) typically developing boys. Power spectra (including aperiodic and periodic components) were compared using non-parametric cluster-based permutation testing. Associations between 30-50Hz gamma power and cognitive, language, and behavioral measures were evaluated using Pearson correlation and linear regression with age as a covariate. FXS participants showed increased power in the beta/gamma range (~25-50Hz) across multiple brain regions. Both a reduction in the aperiodic (1/f) slope and increase in beta/gamma periodic activity contributed to the significant increase in high-frequency power. Increased gamma power, driven by the aperiodic component, was associated with better language ability in the FXS group. No association was observed between gamma power and parent report measures of behavioral challenges, sensory hypersensitivities, or adaptive behaviors. The observed positive association between increased aperiodic gamma power and language supports hypotheses that increased E/I ratios observed in FXS mouse models may reflect beneficial compensation.", "filename": "2020.10.08.20209536v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209536 "}, {"title": "Acceleration of health deficit accumulation in late-life: Evidence of terminal decline in frailty index three years before death in the US Health and Retirement Study", "abstract": "Background: Little is known about within-person frailty index (FI) changes during the last years of life. In this study, we assess whether there is a phase of accelerated health deficit accumulation (terminal health decline) in late-life.\nMaterial and methods: 23,393 observations from up to the last 21 years of life of 5,713 deceased participants of the AHEAD cohort in the Survey of Health and Retirement were assessed. A FI with 32 health deficits was calculated for up to 10 successive biannual assessments (1995-2014), and FI changes according to time-to-death were analyzed with a piecewise linear mixed model with random change points.\nResults: The average normal (pre-terminal) health deficit accumulation rate was 0.01 per year, which increased to 0.05 per year at approximately 3 years before death. Terminal decline began earlier in women and was steeper among men. The accelerated (terminal) rate of health deficit accumulation began at a FI value of 0.29 in the total sample, 0.27 for men, and 0.30 for women.\nConclusion: We found evidence for an observable terminal health decline in the FI following declining physiological reserves and failing repair mechanisms. Our results suggest a conceptually meaningful cut-off value for the continuous FI around 0.30.", "filename": "2020.10.11.20210732v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210732 "}, {"title": "Maternal health care services utilization in the amid of COVID-19 pandemic in West Shoa Zone, Central Ethiopia", "abstract": "The novel coronavirus (COVID-19) is an infectious disease caused by a newly discovered coronavirus. Despite strong efforts that have been taking place to control the pandemic globally, the virus is on the rise in many countries. Hence, this study assessed the maternal health care services utilization in the amid of the COVID-19 pandemic in West Shoa Zone, Central Ethiopia. Community-based cross-sectional study was conducted among 844 pregnant women or those gave birth in the last 6 months before the study. A multi-stage sampling technique was used to select the study participants. The data were collected through face-to-face interview using a semi-structured questionnaire. Logistic regressions were performed to identify the presence of significant associations, and adjusted odds ratio with 95%CI was employed for the strength and directions of association between the independent and outcome variables. A P-value of <0.05 was used to declare statistical significance. The prevalence of maternal health service utilization during the COVID-19 pandemic was 64.8%. The odds of maternal health service utilization was higher among mothers who had primary (AOR=2.16, 95%CI: 1.29-3.60), secondary (AOR=1.97, 95%CI: 1.13-3.44), and college and above education (AOR=2.89, 95%CI: 1.34-6.22) than those who could not read and write. In addition, mothers who did travel 25-74 km (AOR= 0.37, 95%CI: 0.23-0.59) and 75-99 km (AOR= 0.10, 95%CI: 0.05-0.19) to reach health facility had a lower odds of maternal health service utilization than those who did travel < 24 km. Moreover, mothers who earn 1000-2000 (AOR= 3.10, 95%CI: 1.73-5.55) and > 2000 birr (AOR=2.66 95%CI: 1.52-4.64) had higher odds of maternal health service utilization than those who earn <500 birr. Similarly, the odds of utilizing maternal health service were higher among mothers who did not fear COVID-19 infection (AOR= 2.79, 95%CI: 1.85-4.20), who had not had to request permission from husband to visit the health facility (AOR= 7.24, 95%CI: 2.65-19.75), who had practiced COVID-19 prevention measure (AOR=5.82, 95%CI: 3.87-8.75), and used face mask (AOR= 2.06, 95% CI: 1.28-3.31) than their counterpart. Empowering mothers and creating awareness on the COVID-19 prevention is recommended to improve maternal health service utilization during the COVID-19 pandemic.", "filename": "2020.10.09.20210054v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210054 "}, {"title": "Mathematical Modeling of COVID-19 pandemic in the African continent", "abstract": "The present work aims to give a contribution to the understanding of the highly infectious pandemic caused by the COVID-19 in the African continent. The study focuses on the modelling and the forecasting of COVID-19 spread in the most affected African continent, namely: Morocco, Algeria, Tunisia, Egypt and South Africa and for the sake of comparison two of the most affected European country are also considered, namely: France and Italy. To this end, an epidemiological SEIQRDP model is presented, which is an adaptation of the classic SIR model widely used in mathematical epidemiology. In order to better coincide with the preventive measures taken by the governments to deal with the spread of COVID-19, this model considers the quarantine. For the identification of the models parameters, official data of the pandemic up to August 1st, 2020 are considered. The results show that the number of infections due to the use of quarantine is expected to be very low provided the isolation is effective. However, it is increasing in some countries with the early lifting of containment. Finally, the information provided by the SEIQRDP model could help to establish a realistic assessment of the short-term pandemic situation. Moreover, this will help maintain the most appropriate and necessary public health measures after the lockdown lifting.", "filename": "2020.10.10.20210427v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210427 "}, {"title": "Robust test and trace strategies can prevent COVID-19 resurgences: a case study from New South Wales, Australia", "abstract": "Background: The early stages of the COVID-19 pandemic illustrated that SARS-CoV-2, the virus that causes the disease, has the potential to spread exponentially. Therefore, as long as a substantial proportion of the population remains susceptible to infection, the potential for new epidemic waves persists even in settings with low numbers of active COVID-19 infections, unless sufficient countermeasures are in place. In this study, we examine the Australian state of New South Wales, a setting with prolonged low transmission, high mobility, non-universal mask usage, and a well-functioning test-and-trace system. We investigate how vulnerable the state would be to resurgences in COVID-19 transmission under variations in the levels of testing, tracing, and mask usage.\n\nMethods: We use a stochastic agent-based model, calibrated to the New South Wales epidemic and policy environment, to simulate possible epidemic outcomes over October 1 to December 31, 2020, under a range of assumptions about contact tracing efficacy, testing rates, and mask uptake.\n\nResults: We find that the relative impact of masks is greatest when testing and tracing rates are lower (and vice versa). With very high testing rates (90% of people with symptoms, plus 90% of people with a known history of contact with a confirmed case), we estimate that the epidemic would remain under control until at least the end of 2020, with as little as 70-110 new infections estimated over October 1 to December 31 under high mask uptake scenarios, or 340-1400 without masks, depending on the efficacy of community contact tracing. However, across comparable levels of mask uptake and contact tracing, the number of infections over this period would be up to 6 times higher if the testing rate was 80% instead of 90%, 17 times higher if the testing rate was 65%, or more than 100 times higher with a 50% testing rate. \n\nConclusions: Our work suggests that testing, tracing and masks can all be effective means of controlling transmission in dynamic community settings. A multifaceted strategy that combines all three, alongside continued hygiene and distancing protocols, is likely to be the most robust means of controlling community-based transmission of SARS-CoV-2.", "filename": "2020.10.09.20209429v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209429 "}, {"title": "The SIR model estimates incorrectly the basic reproduction number for the covid-19 epidemic", "abstract": "The transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) becomes pandemic, but presents different patterns in the world. To characterize the epi- demic of coronavirus disease 2019 (covid-19) in each countries and regions, mathematical models were formulated aiming the estimation of the basic reproduction number R0. Simple mathematical model, the SIR model, provided lower estimation for R0, ranging from 1.5 to 3.0. However, more elaborate model presented here estimated higher value for R0, 9.24 and 8.0 respectively, for S\u00e3o Paulo State (Brazil) and Spain. Additionally, SIR model estimated R0 using the severe covid-19 cases, which are not participating in the SARS-CoV-2 transmission chain.", "filename": "2020.10.11.20210831v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210831 "}, {"title": "A Mathematical Model and Optimal Control for Listeriosis Disease from Ready-to-Eat Food Products", "abstract": "Abstract: Ready-to-eat food (RTE) are foods that are intended by the producers for direct human consumption without the need for further preparation. The primary source of human Listeriosis is mainly through ingestion of contaminated RTE food products. Thus, implementing control strategies for Listeriosis infectious disease is vital for its management and eradication. In the present study, a deterministic model of Listeriosis disease transmission dynamics with control measures was analyzed. We assumed that humans are infected with Listeriosis\neither through ingestion of contaminated food products or directly with Listeria Monocytogenes in their environment. Equilibrium points of the model in the\nabsence of control measures were determined, and their local asymptotic stability established. We formulate an optimal control problem and analytically give sufficient conditions for the optimality and the transversality conditions for the model with controls. Numerical simulations of the optimal control strategies were performed to illustrate the results. The numerical findings suggest that constant implementation of the joint optimal control measures throughout the modelling\ntime will be more efficacious in controlling or reducing the Listeriosis disease. The results of this study can be used as baseline measures in controlling Listeriosis\ndisease from ready-to-eat food products.", "filename": "2020.10.11.20210856v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210856 "}, {"title": "Characterization of presumptive vancomycin-resistant enterococci recovered during infection control surveillance in Dallas, Texas", "abstract": "Enterococcus faecalis and E. faecium are Gram-positive bacteria that normally inhabit the human gastrointestinal tract. They are also opportunistic pathogens and can cause nosocomial infection outbreaks. To prevent the spread of nosocomial infections, hospitals may rely on screening methods to identify patients colonized with multidrug-resistant organisms including vancomycin-resistant enterococci (VRE). Spectra VRE agar (Remel) contains vancomycin and other medium components that select for VRE and phenotypically differentiate between faecalis and faecium species by colony color. We obtained 66 de-identified rectal swab cultures on Spectra VRE agar that were obtained during routine patient admission surveillance at a Dallas, Texas hospital. We analyzed 90 presumptive VRE from 61 of the Spectra VRE agar cultures using molecular and culture methods. Using ddl typing, 55 were found to be E. faecium and 32 were found to be E. faecalis. While most of the E. faecium were positive for the vanA gene by PCR (52 of 55 strains), few of the E. faecalis were positive for either vanA or vanB (5 of 32 strains). The 27 E. faecalis vanA- and vanB-negative strains could not be recultured on Spectra VRE agar. Overall, we found that Spectra VRE agar performed robustly for the identification of vancomycin-resistant E. faecium, but presumptive false positives were obtained for vancomycin-resistant E. faecalis.", "filename": "2020.10.09.20209569v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209569 "}, {"title": "Estimating epidemiologic dynamics from single cross-sectional viral load distributions", "abstract": "Virologic testing for SARS-CoV-2 has been central to the COVID-19 pandemic response, but interpreting changes in incidence and fraction of positive tests towards understanding the epidemic trajectory is confounded by changes in testing practices. Here, we show that the distribution of viral loads, in the form of Cycle thresholds (Ct), from positive surveillance samples at a single point in time can provide accurate estimation of an epidemic's trajectory, subverting the need for repeated case count measurements which are frequently obscured by changes in testing capacity. We identify a relationship between the population-level cross-sectional distribution of Ct values and the growth rate of the epidemic, demonstrating how the skewness and median of detectable Ct values change purely as a mathematical epidemiologic rule without any change in individual level viral load kinetics or testing. Although at the individual level measurement variation can complicate interpretation of Ct values for clinical use, we show that population-level properties reflect underlying epidemic dynamics. In support of these theoretical findings, we observe a strong relationship between the time-varying effective reproductive number, R(t), and the distribution of Cts among positive surveillance specimens, including median and skewness, measured in Massachusetts over time. We use the observed relationships to derive a novel method that allows accurate inference of epidemic growth rate using the distribution of Ct values observed at a single cross-section in time, which, unlike estimates based on case counts, is less susceptible to biases from delays in test results and from changing testing practices. Our findings suggest that instead of discarding individual Ct values from positive specimens, incorporation of viral loads into public health data streams offers a new approach for real-time resource allocation and assessment of outbreak mitigation strategies, even where repeat incidence data is not available. Ct values or similar viral load data should be regularly reported to public health officials by testing centers and incorporated into monitoring programs.", "filename": "2020.10.08.20204222v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20204222 "}, {"title": "Multi-type branching and graph product theory of infectious disease outbreaks", "abstract": "The heterogeneity of human populations is a major challenge to mathematical descriptions of infectious disease outbreaks. Numerical simulations are therefore deployed to account for the many factors influencing the disease spreading dynamics. Yet, the results from numerical simulations are often as complicated as the reality, leaving us with a sense of confusion about how the different factors account for the simulation results. Here, using a multi-type branching together with a graph tensor product approach, I derive a single equation for the effective reproductive number of an infectious disease outbreak. Using this equation I deconvolute the impact of crowd management, contact heterogeneity, testing, vaccination, mask use and smartphone tracing app use. This equation can be used to gain a basic understanding of infectious disease outbreaks and their simulations.", "filename": "2020.10.09.20210252v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210252 "}, {"title": "Duration of Oxygen Requirement and Predictors in Severe COVID-19 Patients in Ethiopia: A Survival Analysis", "abstract": "Aim: To estimate time to getting off supplemental oxygen therapy and identify predictors among COVID-19 patients admitted to Millennium COVID-19 Care Center in Addis Ababa, Ethiopia.  \nMethods: A prospective observational study was conducted among 244 consecutively admitted COVID-19 patients from July to September, 2020. Frequency tables, KM plots, median survival times and Log-rank test were used to describe the data and compare survival distribution between groups. Cox proportional hazard survival model was used to assess the presence of a statistically significant association between time to getting off supplemental oxygen therapy and the independent variables, where hazard ratio, P-value and 95% CI for hazard ratio were used for testing significance and interpretation of results.\nResults: Median time to getting off supplemental oxygen therapy among the studied population was 6 days. Factors that affect time to getting off supplemental oxygen therapy were age group (HR= 0.522, 95% CI= 0.323, 0.844, p-value=0.008 for \u2265 70 years) and shortness of breath (HR= 0.705, 95% CI= 0.519, 0.959, p-value=0.026).\nConclusions: Average duration of supplemental oxygen therapy requirement among COVID-19 patients was 6 days and being 70 years and older and having shortness of breath were found to be associated with prolonged duration of supplemental oxygen therapy requirement. This result can be used as a guide in planning institutional resource allocation and patient management to provide a well equipped care to prevent complications and death from the disease.", "filename": "2020.10.08.20209122v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209122 "}, {"title": "Successive epidemic waves of cholera in South Sudan, 2014 - 2017", "abstract": "Background\nBetween 2014 and 2017, successive cholera epidemics occurred in South Sudan within the context of civil war, population displacement, flooding, and drought. Understanding the determinants of cholera spread in complex settings like this can provide valuable insights for mitigating future cholera risk. \n\nMethods \nWe analyzed cholera linelist and molecular data to describe the spatio-temporal progression of the epidemics. We explored the role of rainfall, population movement and vaccination campaigns in shaping the explaining incidence and the spatial distribution of reported cases.\n\nFindings\nSouth Sudan experienced three distinct cholera epidemic waves of cholera ranging from 6-18 months with more than 28,000 cases reported and more than 2 million cholera vaccine doses delivered to curb transmission. The 2014 and 2015 epidemics remained spatially limited while the 2016/17 epidemic exploded along the Nile river. Initial cases of each epidemic were reported in or around Juba soon after the start of the rainy season, but we found no evidence that rainfall modulated transmission during each epidemic. All isolates analyzed had similar genotypic and phenotypic characteristics, closely related to sequences from Uganda and Democratic Republic of Congo. The direction of large-scale population movements between counties with cholera outbreaks was consistent with the spatial distribution of outbreaks. As of September 2020, zero cholera cases have been confirmed within South Sudan since 2017. \n\nInterpretation \nThe three epidemic waves were caused by V. cholerae of the same clonal origin despite the periods of no reported cases between waves. While the complex emergency likely shaped some of the observed spatial and temporal patterns of reported cases, the full scope of transmission determinants remains unclear. Timely and well targeted use of cholera vaccine can avert cases and deaths, however, most of the vaccine campaigns occurred after the epidemic peak highlighting the challenges of delivering vaccines quickly in response to an outbreak in settings like South Sudan. These analyses provide a multi-faceted template for examining cholera dynamics through epidemiological, microbiological, climatic, and behavioral lenses. \n\nFunding\nThe Bill and Melinda Gates Foundation", "filename": "2020.10.09.20209262v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209262 "}, {"title": "EVALUATION OF ELEVEN IMMUNOCHROMATOGRAPHIC ASSAYS FOR SARS-CoV-2 DETECTION: INVESTIGATING DENGUE CROSS-REACTION", "abstract": "Background: COVID-19 disease (Coronavirus disease 2019) caused by SARS-CoV-2 (Severe acute respiratory syndrome coronavirus 2) is widespread worldwide, affecting more than 11 million people globally (July 6th, 2020). Diagnostic techniques have been studied in order to contain the pandemic. Immunochromatographic (IC) assays are feasible and low cost alternative for monitoring the spread of COVID-19 in the population. \nMethods: Here we evaluate the sensitivity and specificity of eleven different immunochromatografic tests in 98 serum samples from confirmed cases of COVID-19 through RT-PCR and 100 negative serum samples from blood donors collected in February 2019. Considering the endemic situation of Dengue in Brazil, we also evaluated the cross-reactivity with Dengue using 20 serum samples from patients with confirmed diagnosis for Dengue collected in early 2019 through four different tests. \nResults: Our results demonstrated agreement between immunochromatographic assays and RT-PCR, especially after 10 days since the onset of symptoms. The evaluation of IgG and IgM antibodies combined demonstrated a strong level of agreement (0.85) of IC assays and RT-PCR. It was observed cross-reactivity between Dengue and COVID-19 using four different IC assays for COVID-19 diagnosis. The specificity of IC assays to detected COVID-19 IgM antibodies using Dengue serum samples varied from 80% to 85%; the specificity of IgG detection was 100% and total antibody was 95%. \nConclusions:  We found high sensitivity, specificity and good agreement of IC assays, especially after 10 days onset of symptoms. However, we detected cross-reactivity between Dengue and COVID-19 mainly with IgM antibodies demonstrating the need for better studies about diagnostic techniques for these diseases.", "filename": "2020.10.09.20210039v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210039 "}, {"title": "Strain inheritance and neonatal gut microbiota development: a meta-analysis", "abstract": "As many inflammatory and metabolic disorders have been associated with structural deficits of the human gut microbiota, the principles and mechanisms that govern its initialization and development are of considerable scientific interest and clinical relevance. However, our current understanding of the developing gut microbiota dynamics remains incomplete. We carried out a large-scale, comprehensive meta-analysis of over 1900 available metagenomic shotgun samples from neonates, infants, adolescents, and their families, using our recently introduced SameStr program for strain-level microbiota profiling and the detection of microbial strain transfer and persistence. We found robust associations between gut microbiota composition and age, as well as delivery mode which was measurable for up to two years of life. C-section was associated with increased relative abundances of non-gut species and delayed transition from a predominantly oxygen-tolerant to intolerant microbial community. Unsupervised networks based on shared strain profiles generated family-specific clusters connecting infants, their siblings, parents and grandparents and, in one case, suggested strain transfer between neonates from the same hospital ward, but could also be used to identify potentially mislabeled metagenome samples. Following birth, larger quantities of strains were shared between vaginally born infants and their mothers compared to C-section infants, which further persisted throughout the first year of life and belonged to the same bacterial species as strains that were shared between adults and their parents. Irrespective of delivery type, older children shared strains with their mothers and fathers and, into adulthood, could be accurately distinguished from unrelated sample pairs. Prominent gut commensal bacteria were both among frequently transferred (e.g. Bacteroides and Sutterella) and newly acquired taxa (e.g. Blautia, Faecalibacterium, and Ruminococcus). Our meta-analysis presents a more detailed and comprehensive picture of the highly dynamic neonatal and infant gut microbiota development than previous studies and presents evidence for taxonomic and functional compositional differences early in life between infants born naturally or by C-section, which persist well into adolescence.", "filename": "2020.10.10.20210534v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210534 "}, {"title": "Host transcriptional analysis to improve the diagnosis of group A streptococcal pharyngitis", "abstract": "Current diagnostic methods used to evaluate patients with pharyngitis for the presence of group A Streptococcus (GAS) do not discriminate between acute infection and asymptomatic carriage, potentially resulting in overuse of antibiotics. We hypothesized that host response as measured by the transcriptomic profile of peripheral blood leukocytes could make this distinction, and could also distinguish between GAS and viral infection. We used RNA sequencing to generate whole blood transcriptomes from 37 children, including 10 with acute GAS pharyngitis, 5 with asymptomatic GAS carriage, 3 with adenoviral pharyngitis, 3 with pharyngitis of unknown etiology, and 16 asymptomatic children negative for GAS. Transcriptional profiles from children with symptomatic GAS, GAS carriage, symptomatic adenoviral pharyngitis, and controls were each distinct. Of 15,185 genes with analyzable sequence, 1357 (8.9%) were differentially expressed in the children with symptomatic GAS compared to those with asymptomatic carriage, and 1336 (8.8%) compared to symptomatic adenovirus infection. A panel of 13 genes distinguished between children with acute GAS and all others with 91% accuracy. The gene encoding CD177, a marker of neutrophil activation, had a 152-fold increase in expression in children with acute GAS, and is a potential diagnostic biomarker. We conclude that measurement of host response is highly promising to improve the diagnosis of GAS pharyngitis and could help limit unnecessary antibiotic use.", "filename": "2020.10.10.20209395v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20209395 "}, {"title": "Circulating adipokines in non-obese PCOS patients: a systematic review and meta-analysis", "abstract": "Concentrations of circulating adipokines in non-obese polycystic ovary syndrome (PCOS) patients had been reported in many researches, however, these results were conflicting. The aim of this meta-analysis was to assess whether the levels of circulating adipokines were changed in non-obese PCOS. To identify eligible studies, literature research was performed in the database of PubMed, Embase, Web of Science without the restriction of region, publication or language. Of the total studies found, only 81 met the inclusion criteria. The meta-analysis showed that circulating levels of adiponectin [-0.95 (95% CI, -1.36 to -0.53)] decreased statistically in non-obese PCOS women. On the contrary, circulating levels of chemerin [1.13 (95% CI, 0.08 to 2.18)], leptin [0.47 (95% CI, 0.13 to 0.81)], resistin [0.45 (95% CI, 0.03 to 0.88)] and visfatin [1.38 (95% CI, 0.68 to 2.09)] increased significantly in non-obese PCOS females. Besides, there was no statistically significant change in the circulating levels of apelin [0.32 (95% CI, -1.34 to 1.99), irisin [1.01(95% CI, -0.68 to 2.70), omentin [-0.37(95% CI, -1.05 to 0.31)] and vaspin [0.09(95% CI, -0.14 to 0.32)] in non-obese PCOS patients. Scientific evidence suggested that the levels of circulating adipokines altered in non-obese PCOS patients compared with controls. Independent of the degree of obesity, the abnormal change of circulating adipokines levels might play an important role in the occurrence and development of PCOS.", "filename": "2020.10.11.20210716v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210716 "}, {"title": "Evaluation of saliva sampling procedures for SARS-CoV-2 diagnostics reveals differential sensitivity and association with viral load", "abstract": "Nasopharyngeal sampling has been the preferential collection method for SARS-CoV-2 diagnostics. Alternative sampling procedures that are less invasive and do not require a healthcare professional would be more preferable for patients and health professionals. Saliva collection has been proposed as such a possible alternative sampling procedure. We evaluated the sensitivity of SARS-CoV-2 testing on two different saliva collection devices (spitting versus swabbing) compared to nasopharyngeal swabs in over 2500 individuals that were either symptomatic or had high-risk contacts with infected individuals. We observed an overall poor sensitivity in saliva for SARS-CoV-2 detection (30.8% and 22.4% for spitting and swabbing, respectively). However, when focusing on individuals with medium to high viral load, sensitivity increased substantially (97.0% and 76.7% for spitting and swabbing, respectively), irrespective of symptomatic status. Our results suggest that saliva cannot readily replace nasopharyngeal sampling for SARS-CoV-2 diagnostics but may enable identification of cases with medium to high viral loads.", "filename": "2020.10.06.20207902v1", "doi": "doi: https://doi.org/10.1101/2020.10.06.20207902 "}, {"title": "Heme induces mRNA expression and activation of tissue factor by TLR4 dependent mechanisms", "abstract": "Introduction: Hemolytic diseases such as Sickle Cell Disease (SCD) are characterized by a natural propensity for both arterial and venous thrombosis. Evidence showing that heme can induce tissue factor (TF) expression in endothelial cells and TF-dependent coagulation activation in animal models of SCD suggest that heme can contribute to hypercoagulability in this condition. We recently demonstrated that heme can induce coagulation activation in whole blood of healthy volunteers in a TF-dependent fashion. Methods: Herein, we aimed to evaluate whether this heme-induced coagulation activity was dependent on the expression and/or activation of hematopoietic TF in human mononuclear cells. TF mRNA expression was evaluated by qPCR and TF procoagulant activity was evaluated using a 2-stage assay based on the generation of FXa. Results: Heme was capable of inducing TF expression and activation in a TLR4-dependent pathway. This activity was further amplified after TNF-\u03b1-priming. Conclusion: Our results provide additional evidences on the mechanisms by which heme is involved in the pathogenesis of hypercoagulability in hemolytic diseases.", "filename": "2020.10.09.20210336v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210336 "}, {"title": "Mental health service activity during COVID-19 lockdown among individuals with learning disabilities: South London and Maudsley data on services and mortality from January to July 2020", "abstract": "The lockdown and social distancing policy imposed due to the COVID-19 pandemic is likely to have had a widespread impact on mental healthcare service provision and use. Previous reports from the South London and Maudsley NHS Trust (SLaM; a large mental health service provider for 1.2m residents in South London) highlighted a shift to virtual contacts among those accessing community mental health and home treatment teams and an increase in deaths over the pandemic first wave. However, there is a need to quantify this for individuals with particular vulnerabilities, including those with learning disabilities. Taking advantage of the Clinical Record Interactive Search (CRIS) data resource with 24-hourly updates of electronic mental health records data, this paper describes daily caseloads and contact numbers (face-to-face and virtual) for individuals with learning disabilities across community, specialist, crisis and inpatient services. The report focussed on the period 1st January to 31st July 2020. We also report on daily accepted and discharged trust referrals, total trust caseloads and daily inpatient admissions and discharges for individuals with learning disabilities. In addition, daily deaths are described for all current and previous SLaM service users with learning disabilities over this period. In summary, comparing periods before and after 16th March 2020 there was a shift from face-to-face contacts to virtual contacts across all teams. The largest declines in caseloads and total contacts were seen in Home Treatment Team, Liaison/A&E and Older Adult teams. Reduced accepted referrals and inpatient admissions were observed and there was an 103% increase in average daily deaths in the period after 16th March, compared to the period 1st January to 15th March (or a 282% increase if the 2-month period from 16th March to 15th May was considered alone).", "filename": "2020.10.11.20210625v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210625 "}, {"title": "Heart failure grading using single-lead electrocardiography", "abstract": "Convolutional neural networks (CNNs) applied to electrocardiograms (ECGs) have been showing utility for detecting left ventricular (LV) dysfunction1. Although early detection of reduced LV ejection fraction (rEF) could improve handling of heart failure (HF) with rEF (HFrEF), it is not sufficient to detect HF with preserved EF (HFpEF). Here we developed a CNN algorithm to classify the severity of HF based on single-lead ECG data, irrespective of EF. We trained a CNN using ECG data and the HF classification from 7,865 patients with HF. The CNN achieved an area under the receiver-operating characteristic curve (AUC) of 0.996 for distinguishing patients with HF of various severity from healthy controls. It is anticipated that early detection of HF and therapeutic management of HF patients can be improved by employing this CNN with a single-lead ECG device.", "filename": "2020.10.08.20209700v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209700 "}, {"title": "Associations between governor political affiliation and COVID-19 cases and deaths in the United States", "abstract": "Introduction\nAs the response to the COVID-19 pandemic has become increasingly politicized in the United States (US), political party affiliation of state leaders may contribute to policies affecting the spread of the disease.  We examined differences in COVID-19 infection and death rates stratified by governor party affiliation across the 50 US states and the District of Columbia (DC). \n\nMethods\nWe conducted a longitudinal analysis examining daily COVID-19 incidence and death rates from March 1 to September 30, 2020, for each US state and DC.  We fit a Bayesian negative binomial model to estimate adjusted daily risk ratios (RRs) and posterior intervals (PIs) comparing infection and death rates by gubernatorial (mayoral for DC) party affiliation.  We adjusted for several state-level variables, including population density, age, race, poverty, and health.\n\nResults\nFrom March to early June 2020, Republican-led states had, on average, lower COVID-19 incidence rates compared to Democratic-led states.  However, on June 8, the association reversed, and Republican-led states had higher per capita COVID-19 incidence rates (RR=1.15, 95% PI: 1.02, 1.25).  This trend persisted until September 30 (RR=1.26, 95% PI: 0.96, 1.51).  For death rates, Republican-led states had lower average rates early in the pandemic, but higher rates from July 13 (RR=1.22, 95% PI: 1.03,1.37) to September 30 (RR=1.74, 95% PI: 1.20, 2.24).\n\nConclusion\nGubernatorial party affiliation may drive policy decisions that impact COVID-19 infections and deaths across the US.  As attitudes toward the pandemic become increasingly polarized, policy decisions should be guided by public health considerations rather than political ideology.", "filename": "2020.10.08.20209619v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209619 "}, {"title": "Outcomes of COVID-19: disparities by ethnicity", "abstract": "Abstract\nObjectives\nTo investigate the role of ethnicity in COVID-19 outcome disparities in a cohort in Kuwait.\nMethods\nThis is a retrospective analysis of 405 individuals infected with SARS-CoV2 in Kuwait. Outcomes such as symptoms severity and mortality were considered. Multivariate logistic regression models were used to report the odds ratios (OR) for ICU admission and dying from COVID-19. \nResults\nThe cohort included 290 Arabs and 115 South Asians. South Asians recorded significantly higher COVID-19 death rates compared to Arabs (33% vs. 7.6%, P value<0.001). When compared to Arabs, South Asians also had higher odds of being admitted to the ICU (OR = 6.28, 95% CI: 3.34-11.80, p < 0.001). South Asian patients showed 7.62 (95% CI: 3.62-16.02, p < 0.001) times the odds of dying from COVID-19.\nConclusion\nCOVID-19 patients with South Asians ethnicity are more likely to have worse prognosis and outcome when compared to patients with Arab ethnicity. This suggest a possible role for ethnicity in COVID-19 outcome disparities and this role is likely to be multifactorial.", "filename": "2020.10.11.20210740v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210740 "}, {"title": "An Overview of Retraction Status and Reasons of Non-Cochrane Systematic Reviews in Medicine", "abstract": "Background: Many previous studies have analyzed the status of retracted publications from different perspectives, but so far no study has focused on systematic reviews (SRs). The purpose of this study is to analyze the retraction status and reasons of non-Cochrane SRs in the field of medicine. \nMethods: We searched MEDLINE and Embase from their inception to April 18, 2020, as well as Retraction Watch Database and Google Scholar with no language restriction to find non-Cochrane SRs that were retracted for any reason. Two reviewers independently screened and extracted data. We describe the characteristic and reasons of retraction and the duration from publication to retraction.\nResults: We identified 150 non-Cochrane SRs in medicine retracted between 2004 and 2020. The majority of retracted SRs were led by authors from China and affiliated with hospitals. Most SRs were published in journals with an impact factor \u22643, and in journal ranked in the third quarter. The largest proportion of retraction notices were issued by the publisher and editor(s) jointly; seven did not report this information. Fraudulent peer-review was the most common reason for retraction, followed by unreliable data meaning errors in study selection or data analysis. The median time between publication and retraction was 14.0 months. SRs retracted due to research misconduct took longer to retract than SRs retracted because of honest error. \nConclusions: The situation with retracted SRs is critical globally, and in particular in China. The most common reasons for retraction are fraudulent peer-review and unreliable data, and in most cases the study is retracted more than a year after publication. Efforts should be made to improve the process of peer review and adherence to the COPE retraction guidance, while at the same time authors should strengthen their skills in SR methodology.\nKeywords: Retraction; Systematic review; non-Cochrane; Research ethics.", "filename": "2020.10.10.20210666v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210666 "}, {"title": "The Florida Pancreas Collaborative Next-Generation Biobank: State-wide Infrastructure to Reduce Disparities and Improve Survival for a Racially and Ethnically Diverse Cohort of Patients with Pancreatic Cancer", "abstract": "Background: Well-annotated, high-quality biorepositories provide a valuable platform to support translational research and discovery. However, most biorepositories have poor representation of minority groups, limiting the ability to address cancer health disparities and improve disease outcomes. This report describes the establishment of the Florida Pancreas Collaborative (FPC), the first state-wide prospective longitudinal cohort study and biorepository specifically designed to address the higher burden of pancreatic cancer (PaCa) in African Americans (AA) compared to Non-Hispanic Whites (NHW) and Hispanic/Latinx (H/L).\nMethods: We describe rationale for establishing the FPC and provide an overview of key stakeholders; study eligibility and design; ascertainment and recruitment strategies; and standard operating procedures (SOPs) developed to collect, process, store, and transfer biospecimens, medical images, and data. We also describe the customized cloud-based, secure data management platform built to facilitate recruitment, track study-related workflow, house data, and perform queries. We also present progress to date regarding recruitment and biobanking.\nResults: The FPC consists of multidisciplinary teams from fifteen Florida medical institutions. From March 2019 through August 2020, 350 patients were assessed for study eligibility, 323 met inclusion/exclusion criteria, and 305 (94%) enrolled, including 228 NHW, 30 AA, and 47 H/L, with 94%, 100%, and 94% participation rates, respectively. A high percentage of participants have donated blood (87%), pancreatic tumor tissue (41%), computed tomography scans (76%), and baseline questionnaire data (62%).\nConclusions: This biorepository addresses a critical gap in PaCa research with the potential to advance basic, clinical, population-based, and translational studies intended to minimize disparities, increase quality of life, and reduce PaCa-related morbidity and mortality.\nImpact: This multi-institutional infrastructure can serve as a prototype for development of similar resources across the country and disease sites.", "filename": "2020.10.10.20209247v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20209247 "}, {"title": "Development and validation of the 4C Deterioration model for adults hospitalised with COVID-19", "abstract": "Prognostic models to predict the risk of clinical deterioration in acute COVID-19 are required to inform clinical management decisions. Among 75,016 consecutive adults across England, Scotland and Wales prospectively recruited to the ISARIC Coronavirus Clinical Characterisation Consortium (ISARIC4C) study, we developed and validated a multivariable logistic regression model for in-hospital clinical deterioration (defined as any requirement of ventilatory support or critical care, or death) using 11 routinely measured variables. We used internal-external cross-validation to show consistent measures of discrimination, calibration and clinical utility across eight geographical regions. We further validated the final model in held-out data from 8,252 individuals in London, with similarly consistent performance (C-statistic 0.77 (95% CI 0.75 to 0.78); calibration-in-the-large 0.01 (-0.04 to 0.06); calibration slope 0.96 (0.90 to 1.02)). Importantly, this model demonstrated higher net benefit than using other candidate scores to inform decision-making. Our 4C Deterioration model thus demonstrates unprecedented clinical utility and generalisability to predict clinical deterioration among adults hospitalised with COVID-19.", "filename": "2020.10.09.20209957v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209957 "}, {"title": "Occurrence of Four Dengue Virus Serotypes and Chikungunya Virus in Kilombero, Tanzania during Dengue Outbreak in 2018", "abstract": "Background: Dengue and Chikungunya viruses can cause large-scale epidemics with attack rates exceeding 80%. In Tanzania, there have been repeated outbreaks of dengue fever, the most recent one in 2018 and 2019 mostly reported in coastal areas. Despite its importance, there is limited knowledge on epidemiology of dengue (DENV) and chikungunya (CHIKV) in Tanzania. This study was conducted to investigate the prevalence of DENV and CHIKV in Kilombero district, South-Eastern Tanzania. \n\nMethods: A cross-sectional study was conducted at Kibaoni Health Center, in Kilombero district, in the rainy and dry seasons of 2018. Febrile patients of any age and gender were enrolled.   Blood samples were taken and screened for DENV and CHIKV viral RNA by real-time RT-PCR assays.\n\nResults: A total of 294 patients were recruited. Most were females (65%), and aged between 14\u250025 years (33%). DENV and CHIKV were detected in 29 (9.9%) and 3 (1.0%) patients, respectively. DENV was detected across all age groups and during both dry and rainy seasons. Although all four DENV serotypes were detected, serotypes 1 and 3 dominated and were present in 14 patients (42.4%) each. Additionally, the study showed DENV-1 and DENV-3 co-infections.\n\nConclusion: This study reveals the co-circulation of all four DENV serotypes and CHIKV in Kilombero district. Importantly, we report the first occurrence of DENV-4 in Tanzania. Unlike previous DENV outbreaks caused by DENV-2, the 2018 outbreak was dominated by DENV-1 and DENV-3. Occurrence of all serotypes suggests the possibility of having severe clinical outcomes in future DENV epidemics in Tanzania.", "filename": "2020.10.09.20209783v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209783 "}, {"title": "Findings from serological surveys (in August 2020) to assess the exposure of adult population to SARS Cov-2 infection in three cities of Odisha, India.", "abstract": "Background: There is always an uncertainty of epidemiological , serological infectivity and virulence of the emerging novel coronavirus. Antibody test can be used for assessing whether immunity has developed in the infected person after 5-7 days of illness and understand cumulative exposure levels to the infection, make inferences on the actual burden of infection, its geographical spread, effect on specific demographic/risk groups, gaps in testing and infection fatality rates. \nObjective-\nTo estimate and compare the sero-prevalence, hidden prevalence and determine the demographic risk factors associated with SARS-CoV-2 infection among adults in three largest cities of Odisha, India.\nMethodology: This was a population based cross sectional serological survey carried out in August 2020 in the three largest cities of the state of Odisha. Sample size per city was estimated to be 1500 and participants were enrolled from the community using multi-stage random sampling from 25 clusters from each city. Data was collected using ODK based tools by household visits and 3-4 ml of blood samples were collected after informed consent.  Samples were transported to testing lab where Serum was separated and tested for anti- SARS CoV-2 antibodies using automated CLIA platform. Statistical analysis was done using R-software packages. \nResults: A total of 4146 participants from the 3 cities of Bhubaneswar (BBS), Berhampur (BAM) and Rourkela (RKL) participated. A total of 5635 households were approached and the average non response rate in the community was 17.4%. The gender weighted seroprevalence across the three cities was 20.78% (95% CI: 19.56%-22.05%). Seroprevalence was highest in BAM at 31.14% (95% CI: 28.69-33.66%) followed by 24.59% (95% CI: 22.39-26.88%) in RKL and 5.24% (95% CI: 4.10-6.58%) in BBS. While females reported a higher seroprevalence (22.8%) as compared to males (18.8%), there was no significant difference in seroprevalence across age groups. A majority of the seropositive participants were asymptomatic (93.87%). Among those who reported symptoms, the most common symptom was fever (68.89%) followed by cough (46.06%) and myalgia (32.67%). The case to infection ratio on the date of serosurvey was 1: 6.6 in BBS, 1:61 in BAM and 1:29.8 in RKL. \nConclusion: The study found a high seroprevalence against COVID-19 in urban Odisha as well as high numbers of asymptomatic infections.", "filename": "2020.10.11.20210807v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210807 "}, {"title": "Analysis of the potential for a malaria vaccine to reduce gaps in malaria intervention coverage", "abstract": "Background: The RTS,S/AS01 malaria vaccine is currently being piloted in three African countries. We sought to identify whether vaccination could reach additional children who are at risk from malaria but do not currently have access to, or use, core malaria interventions.\nMethods: Using data from household surveys we calculated the overlap between malaria intervention coverage and childhood vaccination (diphtheria-tetanus-pertussis dose 3, DTP3) uptake in 20 African countries with at least one first administrative level unit with Plasmodium falciparum parasite prevalence greater than 10%. We used multilevel logistic regression to explore patterns of overlap by demographic and socioeconomic variables. We also estimated the public health impact of delivering RTS,S/AS01 to those children who do not use an insecticide-treated net (ITN) but who received the DTP3 vaccine.\nResults: Uptake of DTP3 was higher than malaria intervention coverage in most countries. Overall, 34% of children did not use ITNs and received DTP3, while 35% of children used ITNs and received DTP3, although this breakdown varied by country. We estimated that there are 33 million children in these 20 countries who do not use an ITN. Of these, 23 million (70%) received the DTP3 vaccine. Vaccinating those 23 million children who receive DTP3 but do not use an ITN could avert an estimated 9.7 million clinical malaria cases each year. An additional 10.8 million cases could be averted by vaccinating those 24 million children who receive the vaccine and use an ITN. Children who had access to or used an ITN were 9 to 13% more likely to reside in rural areas compared to those who had neither intervention regardless of vaccination status. Mothers' education status was a strong predictor of intervention uptake and was positively associated with use of ITNs and vaccination uptake and negatively associated with having access to an ITN but not using it. Wealth was also a strong predictor of intervention coverage.\nConclusions: Childhood vaccination to prevent malaria has the potential to reduce inequity in access to existing malaria interventions and could substantially reduce the childhood malaria burden in sub-Saharan Africa, even in regions with lower existing DTP3 coverage.", "filename": "2020.10.09.20209973v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209973 "}, {"title": "What Specimen Urologists Should Be Most Concerned About ? A Systematic Review and Meta-Analysis", "abstract": "Objective:Investigating the infectivity of body fluid can be useful for preventative measures in the community and ensuring safety in the operating rooms and on the laboratory practices.\n\nMethods:We performed a literature search of clinical trials, cohorts, and case series using PubMed/MEDLINE, Google Scholar, and Cochrane library, and downloadable database of CDC. We excluded case reports and searched all language articles for review and repeated until the final drafting. The search protocol was registered in the PROSPERO database. \n\nResults: Thirty studies with urinary sampling for viral shedding were included. A total number of 1,271 patients were enrolled initially, among which 569 patients had undergone urinary testing. Nine studies observed urinary viral shedding in urine from 41 patients. The total incidence of urinary SARS-CoV-2 shedding was 8%, compared to 21.3% and 39.5 % for blood and stool, respectively. The summarized risk ratio (RR) estimates for urine positive rates compared to the pharyngeal rate was 0.08. The pertaining RR urine compared to blood and stool positive rates were 0.20 and 0.33 respectively. \n\nConclusions: Our review concludes that not only the SARS-CoV-2 can be excreted in the urine in eight ?percent of patients but also its incidence may have associations with the severity of the ?systemic disease, ICU admission, and fatality rates. Moreover, the findings in our review ?suggest that a larger population size may reveal more positive urinary cases possibly by ?minimizing biases. However, it is important to notice that it is the naso-pharyngeal specimens, ?stool, and serum that show more possibilities to became positive, respectively.", "filename": "2020.10.08.20209544v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209544 "}, {"title": "Investigating the relationship between IGF-I, -II and IGFBP-3 concentrations and later-life cognition and brain volume", "abstract": "Background: The insulin/insulin-like signalling (IIS) pathways, including Insulin-like Growth Factors (IGFs), varies with age. However, their association with late-life cognition and neuroimaging parameters is not well characterised.\n \nMethods: Using data from the British 1946 birth cohort we investigated associations of IGF-I, -II and IGFBP-3 (measured at 53 and 60-64 years) with cognitive performance (word learning test (WLT)  and visual letter search (VLS) - at 60-64y and 69y) and cognitive state (Addenbrooke's Cognitive Exam-III (ACE-III) - at 69-71y), and in a proportion, quantified neuroimaging measures (whole brain volume (WBV); white matter hyperintensity volume (WMHV); hippocampal volume (HV)). Regression models included adjustments for demographic, lifestyle and health factors. \n\nResults: Higher IGF-I and IGF-II at 53y was associated with higher ACE-III scores (B 0.07 95%CI [0.02,0.12]; scoreACE-III 89.48 [88.86,90.1], respectively). IGF-II at age 53y was additionally associated with higher WLT scores (scoreWLT 20 [19.35,20.65]). IGFBP-3 at 60-64y was associated with favourable VLS score at 60-64y and 69y (B 0.07 [0.01,0.12]; B 0.07 [0.02,0.12], respectively), higher memory and cognitive state at 69y (B 0.07 [0.01,0.12]; B 0.07 [0.01,0.13], respectively) and reduced WMHV (B -0.1, [-0.21,-0.00]). IGF-I/IGFBP-3 at 60-64y was associated with slower VLS scores at 69y (B -0.08, [-0.15,-0.02]).\n\nConclusions: Increased measure in IIS parameters (IGF-I, -II and IGFBP-3) relate to better cognitive state in later life. Furthermore, there were apparent associations with specific cognitive domains (IGF-II relating to memory; IGFBP-3 to memory, processing speed and WMHV; and IGF-I/IGFBP-3 molar ratio with slower processing speed). IGFs and IGFBP-3 are associated with favourable cognitive function outcomes.", "filename": "2020.10.09.20209833v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209833 "}, {"title": "SARS-CoV-2 waves in Europe: A 2-stratum SEIRS model solution", "abstract": "In order to design actionable SARS-CoV-2 strategies, we extended the SEIRS model to support stratified isolation levels for healthy <60 and vulnerable individuals. At first, we forced isolation levels to be uniform, showing that daily deaths curves of all metropolitan areas in the analysis can be fitted using homogeneous Ro=3.3. In the process, we established the possibility that an extremely short infectiousness period of 2 days coupled with 5 days exposure may be responsible for the multiple deaths valleys observed during the weeks following lockdowns. Regardless of the infectiousness period, we realized that is possible to infer non-uniform isolation levels for healthy <60 and vulnerable by forcing the model to match the <60 to >60 age serology ratio reported in seroprevalence studies. Since the serology ratio is more robust than absolute values, we argue immunity level estimations made in this way (Madrid 43%; Catalonia 24%; Brussels 73%; and Stockholm 65%) are closer to reality. In locations where we did not find reliable serology, we performed immunity estimations assuming Spain serology ratio (Paris: 24%; London: 34%). We predict that, with the exception of Brussels, no location can return to normal life without having a second wave (albeit in Stockholm a smaller one). For locations far from the herd immunity threshold (HIT) we searched what isolation values allow to return to normal life in 90 days minimizing final deaths, shockingly all found isolations for healthy <60 were negative (i.e. coronavirus parties minimize final deaths). Then, assuming an ideal 1-day long vaccination campaign with a 77% efficacy vaccine, we compared predicted final deaths of those 90-day strategies for all possible vaccination dates with a 180-day long vaccine waiting strategy that imposes 0.40 mandatory isolation to healthy <60 and results in 0.65 isolation to vulnerable. We found that 180-day of mandatory isolations to healthy <60 (i.e. schools and workplaces closed) produces more final deaths if the vaccination date is later than (Madrid: March 7 2021; Catalonia: Dec 26 2020; Paris: Jan 12 2021; London: Jan 25 2021). We conclude that our 2-stratum SEIRS model is suitable to predict SARS-CoV-2 epidemic behavior and can be used to minimize covid-19 disease and isolations related damages.", "filename": "2020.10.09.20210146v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210146 "}, {"title": "Cleaning and Re-Use of cobas\u00ae 6800/8800 Processing Plates for the SARS-CoV-2 Assay", "abstract": "Real-time reverse transcription polymerase chain reaction (rRT-PCR) is the primary method used for the detection and diagnosis of infections caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Since SARS-CoV-2s entrance into the United States, numerous clinical laboratories and in vitro diagnostic companies have developed rRT-PCR assays, some requiring specialized materials and reagents. One such assay includes the cobas\u00ae SARS-CoV-2 Qualitative Assay for use on the cobas\u00ae 6800/8800 (Roche Molecular Systems, Inc.). Since initiation of this assay at our facility, our ability to run testing at full capacity has been limited due to restricted supply of the omni cobas\u00ae Processing Plate (Product Number 05534917001), a 96 deep well plate used for all sample processing and total nucleic acid extraction via MagNA Pure magnetic beads. To work around this limiting factor, we have successfully designed and tested a cleaning protocol utilizing the widely available laboratory resources of bleach, ethyl-alcohol and autoclaving, for omni cobas\u00ae Processing Plate re-use.", "filename": "2020.10.09.20209601v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209601 "}, {"title": "Rapid and Low-cost Sampling for Detection of Airborne SARS-CoV-2 in Dehumidifier Condensate", "abstract": "Airborne spread of COVID-19 by infectious aerosol is all but certain. However, easily implemented approaches to assess the actual environmental threat are currently unavailable. We present a simple approach with the potential to rapidly provide information about the prevalence of SARS-CoV-2 in the atmosphere at any location. We used a portable dehumidifier as a readily available and affordable tool to collect airborne virus in the condensate. The dehumidifiers were deployed in selected locations of a hospital ward with patients reporting flu like symptoms which could possibly be due to COVID-19 over three separate periods of one week. Samples were analyzed frequently for both virus envelope protein and SARS-CoV-2 RNA. In several samples across separate deployments, condensate from dehumidifiers tested positive for the presence of SARS-CoV-2 antigens and confirmed  using two independent assays. RNA was detected, but not attributable to SARS-CoV-2. Our results point to a facile pool testing method to sample air in any location in the world and assess the presence and concentration of the infectious agent in order to obtain quantitative risk assessment of exposure, designate zones as hot spots and minimize the need for individual testing which may often be time consuming, expensive and laborious.", "filename": "2020.10.08.20208785v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208785 "}, {"title": "Estimating COVID-19 cases and outbreaks on-stream through phone-calls", "abstract": "One of the main problems in controlling COVID-19 epidemic spread is the delay in confirming cases. Having information on changes in the epidemic evolution or outbreaks rise before lab-confirmation is crucial in decision making for Public Health policies. We present an algorithm to estimate on-stream the number of COVID-19 cases using the data from telephone calls to a COVID-line. By modeling the calls as background (proportional to population) plus signal (proportional to infected), we fit the calls in Province of Buenos Aires (Argentina) with coefficient of determination R 2 > 0.85. This result allows us to estimate the number of cases given the number of calls from a specific district, days before the lab results are available. We validate the algorithm with real data. We show how to use the algorithm to track on-stream the epidemic, and present the Early Outbreak Alarm to detect outbreaks in advance to lab results. One key point in the developed algorithm is a detailed track of the uncertainties in the estimations, since the alarm uses the significance of the observables as a main indicator to detect an anomaly. We present the details of the explicit example in Villa Azul (Quilmes) where this tool resulted crucial to control an outbreak on time. The presented tools have been designed in urgency with the available data at the time of the development, and therefore have their limitations which we describe and discuss. We consider possible improvements on the tools, many of which are currently under development.", "filename": "2020.10.09.20210351v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210351 "}, {"title": "Anxiety disorders and asthma among adolescents in urban Uganda: the role of early life exposures", "abstract": "Background: The reasons for the association between anxiety disorders and asthma are not fully established, and data from Africa is sparse. We investigated whether the association between anxiety disorders and asthma among adolescents may be partly related to shared exposures in early life.\nMethods: We conducted a case-control study among adolescents (12-17 years) with and without asthma in Wakiso District, an urban area in Uganda. Anxiety disorders were diagnosed by the Youth Inventory-4R (YI-4R), a Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-5) referenced instrument. For this report, we focus on generalized anxiety disorder (GAD), panic disorder and social anxiety disorder. Asthma was doctor-diagnosed by study clinicians. We used questionnaires to collect data on early life exposures. The data were analysed using multiple logistic regression models.\nResults: We enrolled 162 adolescents. Adolescents with asthma were more likely to have any of three anxiety disorders (44.6%) than adolescents without asthma (21.4%) (adjusted odds ratio (AOR) 2.68, 95% confidence interval (CI) 1.30-5.53, p-value=0.007). The association was strong for GAD (AOR 4.49, 95% CI 1.48-13.56) and panic disorder (AOR 5.43, 95% CI 2.11-14.02), but not for social anxiety disorder (1.46, 95% CI 0.63-3.37). The early life risk factors associated with anxiety disorders among adolescents were similar to asthma risk factors previously published, including urban residence at birth (AOR 3.42 (1.29-9.09)) and during most of the first five years of life (AOR 2.87 (1.07-7.66)), fathers tertiary education (AOR 2.09 (1.00-4.37)), and adolescents history of other allergy-related diseases (AOR 4.64 (1.66-13.00)). \nConclusion: We confirm a positive association between anxiety disorders and asthma among adolescents in urban Uganda. The early life risk factors associated with anxiety disorders among adolescents were similar to those for asthma in the same age-group, suggesting shared underlying causes.", "filename": "2020.10.08.20209478v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209478 "}, {"title": "Reliability of retinal pathology quantification in age-related macular degeneration: Implications for clinical trials and machine learning applications", "abstract": "Purpose: To investigate the inter-reader agreement for grading of retinal alterations in age-related macular degeneration (AMD) using a reading center setting.\nMethods: In this cross-sectional case series, spectral domain optical coherence tomography (OCT, Topcon 3D OCT, Tokyo, Japan) scans of 112 eyes of 112 patients with neovascular AMD (56 treatment-naive, 56 after three anti-vascular endothelial growth factor injections) were analyzed by four independent readers. Imaging features specific for AMD were annotated using a novel custom-built annotation platform. Dice score, Bland-Altman plots, coefficients of repeatability (CR), coefficients of variation (CV), and intraclass correlation coefficients (ICC) were assessed.\nResults: Loss of ellipsoid zone, pigment epithelium detachment, subretinal fluid, and Drusen were the most abundant features in our cohort. The features subretinal fluid, intraretinal fluid, hypertransmission, descent of the outer plexiform layer, and pigment epithelium detachment showed highest inter-reader agreement, while detection and measures of loss of ellipsoid zone and retinal pigment epithelium were more variable. The agreement on the size and location of the respective annotation was more consistent throughout all features.\nConclusions: The inter-reader agreement depended on the respective OCT-based feature. A selection of reliable features might provide suitable surrogate markers for disease progression and possible treatment effects focusing on different disease stages. This might give opportunities to a more time- and cost-effective patient assessment and improved decision-making as well as have implications for clinical trials and training machine learning algorithms.", "filename": "2020.10.09.20210120v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210120 "}, {"title": "Covid Pandemic Analysis using Regression", "abstract": "Covid-19 is a pandemic which has affected all parts of the world. Covid-19 is a pandemic which can be controlled only by maintaining social distancing, proper hygiene, wearing mask, hand sanitation and to a extend by wearing face shield. Even though each state has followed their own ways of controlling the infection, awareness among citizens and behaving as responsible citizens is very important in controlling this disease. Contact tracing plays an important role in controlling this pandemic. This paper deals with the effect of Covid-19 in various states of India and also forecasts its effect using machine learning techniques. Regression analysis like Linear and polynomial have been used for analysis of Covid-19, where Kaggle dataset has been used. This helps in understanding the much-affected states in India and helps to understand the infrastructure requirements to handle this pandemic efficiently.", "filename": "2020.10.08.20208991v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208991 "}, {"title": "The risk for a new COVID-19 wave -- and how it depends on $R_0$, the current immunity level and current restrictions", "abstract": "The COVID-19 pandemic has hit different parts of the world differently: some regions are still in the rise of the first wave, other regions are now facing a decline after a first wave, and yet other regions have started to see a second wave. The current immunity level $\\hat i$ in a region is closely related to the cumulative fraction infected, which primarily depends on two factors: a) the initial potential for COVID-19 in the region (often quantified by the basic reproduction number $R_0$), and b) the timing, amount and effectiveness of preventive measures put in place. By means of a mathematical model including heterogeneities owing to age, social activity and susceptibility, and allowing for time-varying preventive measures, the risk for a new epidemic wave and its doubling time, and how they depend on $R_0$, $\\hat i$ and the overall effect of the current preventive measures, are investigated. Focus lies on quantifying the minimal overall effect of preventive measures $p_{Min}$ needed to prevent a future outbreak. The first result shows that the current immunity level $\\hat i$ plays a more influential roll than when immunity is obtained from vaccination. Secondly, by comparing regions with different $R_0$ and $\\hat i$ it is shown that regions with lower $R_0$ and low $\\hat i$ may now need higher preventive measures ($p_{Min}$)  compared with other regions having higher $R_0$ but also higher $\\hat i$, even when such immunity levels are far from herd immunity.", "filename": "2020.10.09.20209981v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209981 "}, {"title": "COVID-19 serological survey using micro blood sampling", "abstract": "During August 2020, we carried out a serological survey among students and employees at the Okinawa Institute of Science and Technology Graduate University (OIST), Japan, testing for the presence of antibodies against SARS-CoV-2, the causative agent of COVID-19. We used a FDA-authorized 2-step ELISA protocol developed by the Krammer Lab in combination with at-home self-collection of blood samples using a custom low-cost finger prick-based capillary blood collection kit. Although our survey did not find any COVID-19 seropositive individuals among the OIST cohort, it reliably detected all positive control samples obtained from a local hospital and excluded all negatives controls. Among our controls, we found strong cross-reactivity of antibodies in samples from a serum pool from two MERS patients in the anti-SARS-CoV-2-S ELISA. Here we show that a centralized ELISA in combination with patient-based capillary blood collection using as little as one drop of blood can reliably assess the seroprevalence among communities. Anonymous sample tracking and an integrated website created a stream-lined procedure. Major parts of the workflow were automated on a liquid handler, demonstrating scalability. We anticipate this concept to serve as a prototype for reliable serological testing among larger populations.", "filename": "2020.10.09.20209858v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209858 "}, {"title": "Determinants of Developing Symptomatic Disease in Ethiopian COVID-19 Patients", "abstract": "Background: Studies show that having some symptoms seems to be associated with more severe disease and poor prognosis. Therefore, knowing who is more susceptible to symptomatic COVID-19 disease is important to provide targeted preventive and management practice. The aim of the study was to assess the determinants of having symptomatic disease among COVID-19 patients admitted to Millennium COVID-19 Care Center in Ethiopia.\nMethods: A case-control study was conducted from August to September 2020 among a randomly selected 765 COVID-19 patients (372 Asymptomatic and 393 Symptomatic patients). Chi-square test and independent t-test were used to detect the presence of a statistically significant difference in the characteristics of the cases (symptomatic) and controls (asymptomatic), where p-value of <0.05 considered as having a statistically significant difference. Multivariable binary logistic regression was used to assess a statistically significant association between the independent variables and developing symptomatic COVID-19 where Adjusted Odds ratio (AOR), 95% CIs for AOR, and P-values were used for testing significance and interpretation of results.  \nResults: The result of the multivariable binary logistic regression shows that age group (AOR= 1.818, 95% CI= 1.210, 2.731, p-value=0.004 for 30-39 years; AOR= 1.611, 95% CI= 1.016, 2.554, p-value=0.043 for 40-49 years and AOR= 4.076, 95% CI= 2.582, 6.435, p-value=0.0001 for years and above), sex (AOR= 1.672, 95% CI= 1.216, 2.299, p-value=0.002) and history of diabetes mellitus (AOR= 2.406, 95% CI= 1.384, 4.181, p-value=0.002) were found to be significant factors that determine the development of symptomatic disease in COVID-19 patients.\nConclusions: Developing a symptomatic COVID-19 disease was found to be determined by exposures of old age, male sex, and being diabetic. Therefore, patients with the above factors should be given enough attention in the prevention and management process, including inpatient management, to pick symptoms earlier and to manage accordingly so that these patients can have a favorable treatment outcome.", "filename": "2020.10.09.20209734v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209734 "}, {"title": "A double-blind sham-controlled phase 1 clinical trial of tDCS of the dorsolateral prefrontal cortex in cocaine inpatients: craving, sleepiness, and contemplation to change", "abstract": "Impaired inhibitory control accompanied by enhanced salience attributed to drug-related cues, both dorsolateral prefrontal cortex (dlPFC) functions, are hallmarks of drug addiction, contributing to worse symptomatology including craving. dlPFC modulation with transcranial direct current stimulation (tDCS) showed craving reduction in inpatients with cocaine use disorder (CUD). Our study aimed at assessing feasibility of a longer tDCS protocol in CUD (15 vs. the common five/10 sessions), and replicability of previous results. \nIn a randomized double-blind sham-controlled protocol, 17 inpatients were assigned to either a real-tDCS (right anodal/left cathodal) or a sham-tDCS condition, for 15 sessions. Primary outcome measures were self-reported craving, anxiety, depression, and quality of life. Secondary measures included sleepiness, readiness to change drug use, and affect. We also assessed cognitive function including impulsivity.\nAn 82% retention rate demonstrated feasibility. Partially supporting previous results, there was a trend for self-reported craving to decrease in the real-tDCS group more than the sham group, an effect that would reach significance with 15 subjects per group. Quality of life and impulsivity improved over time of treatment in both groups. Significant group \u00d7 time interactions showed improvements after treatment only in the real-tDCS group for daytime sleepiness and readiness to change drug use. One-month follow-up suggested transient effects of tDCS on sleepiness and craving.\nThis study suggests that more subjects are needed to show a unique effect of real-tDCS on craving and to examine the duration of effect. Increased vigilance and motivation to change in the real-tDCS group suggest fortification of dlPFC-supported executive functions.", "filename": "2020.10.09.20209676v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209676 "}, {"title": "Explaining the Effective Reproduction Number of COVID-19 through Mobility and Enterprise Statistics: Evidence from the First Wave in Japan", "abstract": "This study uses mobility statistics-a relatively novel data source consisting of smartphone location data-combined with business census data for the eight Japanese prefectures with the highest COVID-19 infection rates to study the effect of lockdown measures on the effective transmission rate of the virus. Based on data for the first wave of infections in Japan, we found that reductions targeting the hospitality industry were more effective than restrictions on general business activities. Specifically, we found that to fully converge the pandemic (that is, to reduce the effective reproduction number to one or less for all the days), a 40-67% reduction in weekly mobility is required, depending on the region. A lesser goal, 80% of days with one or less observed transmission, a 14-61% reduction in weekly mobility is needed.", "filename": "2020.10.08.20209643v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209643 "}, {"title": "COVID-19 Disease Severity and Determinants among Ethiopian Patients: A study of the Millennium COVID-19 Care Center", "abstract": "Background: Understanding determinants of developing severe COVID-19 disease is important as studies show that severe disease is associated with worse outcomes.\nObjective: The study aimed to assess the determinants of COVID-19 disease severity among COVID-19 patients admitted to Millennium COVID-19 Care Center in Ethiopia.\nMethods: A cross-sectional study was conducted from June to August 2020 among randomly selected 686 patients. Chi-square test was used to detect the presence of a statistically significant difference in the characteristics of the patients based on disease severity (Mild Vs Moderate Vs Severe), where p-value of <0.05 was considered as having a statistically significant difference. A Multivariable multinomial logistic regression model was used to assess the presence of a significant association between the independent variables and COVID-19 disease severity where Adjusted Odds ratio (AOR), 95% CIs for AOR and P-values were used for testing significance and interpretation of results.\nResults: Having moderate as compared with mild disease was significantly associated with having hypertension (AOR= 2.302, 95% CI= 1.266, 4.184, p-value=0.006), diabetes mellitus (AOR=2.607, 95% CI= 1.307, 5.198, p-value=0.007 for diabetes mellitus), fever (AOR= 6.115, 95% CI= 2.941, 12.716, p-value=0.0001) and headache (AOR= 2.695, 95% CI= 1.392, 5.215, p-value=0.003). Similarly, having severe disease as compared with mild disease was associated with age group (AOR= 4.428, 95% CI= 2.497, 7.853, p-value=0.0001 for 40-59 years and AOR=18.070, 95% CI=9.292, 35.140, p-value=0.0001 for \u2265 60 years), sex (AOR=1.842, 95% CI=1.121, 3.027, p-value=0.016), hypertension (AOR= 1.966, 95% CI= 1.076, 3.593, p-value=0.028), diabetes mellitus (AOR= 3.926, 95% CI= 1.964, 7.847, p-value=0.0001), fever (AOR= 13.218, 95% CI= 6.109, 28.601, p-value=0.0001) and headache (AOR= 4.816, 95% CI= 2.324, 9.979, p-value=0.0001). In addition, determinants of severe disease as compared with moderate disease were found to be age group (AOR= 4.871, 95% CI= 2.854, 8.315, p-value=0.0001 for 40-59 years and AOR= 18.906, 95% CI= 9.838, 36.334, p-value=0.0001 for \u2265 60 years), fever (AOR= 2.161, 95% CI= 1.286, 3.634, p-value=0.004) and headache (AOR= 1.787, 95% CI= 1.028, 3.107, p-value=0.039).\nConclusions: Being old, male sex, hypertension, diabetes mellitus, and having symptoms of fever and headache were found to be determinants of developing a more severe COVID-19 disease category. We recommend a better preventive practice to be set in place so that these groups of patients can be protected from acquiring the disease. And for those who are already infected, a more careful follow-up and management should be given so that complication and death can be prevented. Furthermore, considering the above non respiratory symptoms as disease severity indicator could be important.", "filename": "2020.10.09.20209999v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209999 "}, {"title": "Large-Scale Testing using Tapestry Pooling", "abstract": "We have previously described Tapestry Pooling, a scheme to enhance the capacity of RT-qPCR testing, and provided experimental evidence with spiked synthetic RNA to show that it can help to scale testing and restart the economy. Here we report on validation studies with Covid19 patient samples for the Tapestry Pooling scheme with prevalence in the range of 1% to 2%. We pooled RNA extracted from patient samples that were previously tested for Covid19, sending each sample to three pools. Following three different pooling schemes, we pipetted 320 samples into 48 pools with pool size of 20 at prevalence rate of 1.6%, 500 samples into 60 pools with pool size of 25 at prevalence rate of 2%, and 961 samples into 93 pools with pool size of 31 at prevalence rate of 1%. Of the 191 RT-qPCR experiments that we performed, only one pool was incorrect (false negative). Our recovery algorithm correctly called results for the individual samples, with a 100% sensitivity and a 99.9% specificity, with only one false positive across all the 1,781 blinded results required to be called. We show up to 10X savings in the number of tests required at a range of prevalence rates and pool sizes. These experiments establish that Tapestry Pooling is robust enough to handle the diversity of sample constitutions and viral loads seen in real-world samples.", "filename": "2020.10.09.20209742v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209742 "}, {"title": "Prevalence and Determinants of Premarital Sexual Practice Among Youths in Ethiopia: Further analysis of the Ethiopian Demographic and Health Survey", "abstract": "Introduction: Premarital sexual practice becomes a common phenomenon among youths in Ethiopia. It is usually associated with an unwanted pregnancy, abortion, and sexually transmitted diseases including HIV/AIDS.\nObjective: This study aimed to assess the prevalence and determinants of premarital sexual practice among Ethiopian youths.\nMethods and Materials: A Community based crosssectional study was conducted in all regions of Ethiopia from January 18 to June 27, 2016. All participants from the age of 15 to 24 (7, 389) were included for the analysis of the present study. Bivariable and multivariable binary logistic regression analysis models were fitted to identify factors associated with premarital sexual practice. A 95% CI and p-value < 0.05 were used to declare statistical significance.  \nResult: The prevalence of premarital sexual practice was 10.8% (95% CI, 10 %, 11.5%). Being in the age group of 20 to 24 (AOR = 3.6, 95% CI (2.8, 4.6)), male sex (AOR = 1.7, 95% CI (1.3, 2.2)), employed (AOR = 1.4, 95% CI (1.03, 1.8)), from pastorals region (AOR= 1.4, 95% CI (1.3,2.4)), having mobile phone (AOR=1.7, 95% CI, (1.3, 2.3)), ever use of internet (AOR = 1.8, 95% CI (1.3, 2.5)), ever drinking alcohol AOR = 2.4, 95% CI (1.7, 2.5)), ever chewed khat (AOR = 2.4, 95% CI (1.6, 3.5), and ever tested for HIV (AOR = 1.3, 95% CI (1.1,1.6)) were a statistically significant factors associated  with premarital sexual practice at p value less than 0.05.\nConclusion: For every 10 youths at least one of them had sexual intercourse before they got married. Being in the age group of 20 to 24, male sex, employed, from a pastoral region, having a mobile phone, ever use of the internet, alcohol drinking, khat chewing, and ever tested for HIV were significant factors associated with the premarital sexual practice. Thus, national sexual education and reproductive health behavior change interventions should give due attention to those groups. Indeed, adequate education should be given about premarital sexual intercourse when youths come for HIV tests.", "filename": "2020.10.08.20209577v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209577 "}, {"title": "Examining Unit Costs for COVID-19 Case Management in Kenya", "abstract": "Introduction\nCase management for COVID-19 patients is one of key interventions in country responses to the pandemic. Countries need information on the costs of case management to inform resource mobilization, planning and budgeting, purchasing arrangements, and assessments of the cost-effectiveness of interventions. We estimated unit costs for COVID-19 case management for patients with asymptomatic, mild to moderate, severe, and critical COVID-19 disease in Kenya. \n\nMethods\nWe estimated per patient per day unit costs of COVID-19 case management for patients that are asymptomatic and those that have mild to moderate, severe, and critical symptoms. For asymptomatic and mild to moderate patients, we estimated unit costs for home-based care and institutional (hospitals and isolation centers). We used an ingredients approach, adopted a health system perspective and patient episode of care as our time horizon. We obtained data on inputs and their quantities from COVID-19 case management guidelines, home based care guidelines, and human resource guidelines, and augmented this with data provided by three public covid-19 treatment hospitals in Kenya. We obtained input prices for services from a recent costing survey of 20 hospitals in Kenya and for pharmaceuticals, non-pharmaceuticals, devices and equipment from market price databases for Kenya.   \n\nResults\nPer day per patient unit cost for asymptomatic patients and patients with mild to moderate COVID-19 disease under home based care are KES 1,993.01 (USD 18.89) and 1995.17 (USD 18.991) respectively. When these patients are managed in an isolation center of hospital, the same unit costs for asymptomatic patients and patients with mild to moderate disease are 7,415.28 (USD 70.29) and 7,417.44 (USD 70.31) respectively. Per day unit costs for patients with severe COVID-19 disease managed in general hospital wards and those with critical COVID-19 disease admitted in intensive care units are 12,570.75 (USD 119.16) and 59,369.42 (USD 562.79).", "filename": "2020.10.08.20209684v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209684 "}, {"title": "Mitigating the impact of COVID-19 on tuberculosis and HIV services: a cross-sectional survey of 669 health professionals in 64 low and middle-income countries", "abstract": "Background\nThe disruption of essential services for infectious diseases such as tuberculosis (TB) and HIV is likely to result in the indirect health impacts of COVID-19 being even greater than the direct impacts. The experiences of frontline health professionals are invaluable in understanding how to minimise disruption of healthcare services during emergency situations, but are insufficiently incorporated into policy planning. We\nsynthesised information from frontline TB and HIV professionals to identify ways in which COVID-19 has affected services in low and middle-income countries (LMIC), and strategies to minimise impacts on patients and healthcare providers.  \nMethods\nWe conducted a cross-sectional study of TB and HIV healthcare delivery, management, and research professionals in LMIC around the world. Between May 12 and August 6 2020, we collected qualitative and quantitative data using an online survey disseminated through professional networks and social media in 11 languages. We used descriptive statistics and thematic analysis to analyse responses.  \nResults\n669 respondents from 64 countries completed the survey, representing a 72% response rate. Over 40% of respondents stated that it was impossible or much harder for TB and HIV patients to reach healthcare facilities since COVID-19. The most common barriers reported to affect patient utilisation of healthcare facilities were: fear of getting infected with SARS-CoV-2, transport disruptions, movement restrictions, and reduced income. Healthcare provider access to healthcare facilities was also severely impacted according to 37% of TB respondents and 28% of HIV respondents. In line with this finding, qualitative responses focused on strategies to facilitate transport of patients and healthcare providers or service delivery adaptations to reduce the need for patients to travel to healthcare facilities. While only 16% and 11% of respondents reported major disruptions to provision of medical treatment for HIV or TB, access to non-medical support for patients, such as food supplementation or counselling, was harder or impossible to access according to 35% and 31% of HIV and TB respondents respectively. Our qualitative data suggested that nutritional support became critical for some patients when movement restrictions and employment instability reduced access\nto income and food.  \nDiscussion\nOur large multi-country survey indicated that patients and healthcare providers across numerous LMIC faced substantial challenges in accessing healthcare facilities, and that critical non-medical support for patients, such as food supplementation and counselling, was particularly impacted by COVID-19 disruptions. Frontline\nprofessionals identified important policies and healthcare service delivery adaptations that could mitigate disruptions in the future. It is essential to facilitate sharing of their experiences with policymakers and healthcare service delivery organisations.", "filename": "2020.10.08.20207969v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20207969 "}, {"title": "Peripheral Blood DNA Methylation Changes after Omega-3 Fatty Acid Treatment Indicate Anti-inflammatory Effects and Individual Variability", "abstract": "Background: Omega-3 or n-3 polyunsaturated fatty acids (PUFAs) are widely studied for health benefits based on potential anti-inflammatory effects. However, the factors involved in mediating the anti-inflammatory responses to n-3 PUFAs are not fully understood; furthermore, many effects from n-3 PUFA treatment are not well characterized in humans. Of interest is the role of DNA methylation (DNAm) in mediating the effects of n-3 PUFAs on inflammation. Objective: We aimed to characterize the effects of n-3 PUFA treatment on DNAm in inflammation-related signaling pathways in PBMCs of women at high risk of breast cancer\nMethods: PBMCs of women at high risk of breast cancer were obtained at 0 and 6 months of n-3 PUFA treatment in a previously reported dose finding trial (n=10 matched pairs in the 5 g/day EPA+DHA dose arm). DNA methylation of PBMCs were assayed using reduced representation bisulfite sequencing to obtain genome-wide methylation profiles on a single nucleotide level. Analyses were performed to investigate the effects of n-3 PUFA treatment on DNAm both genome-wide and within a set of candidate genes.\nResults: A large number of differentially methylated CpGs (DMCs) in gene promoters (24,842 DMCs in 5507 genes) showed significant enrichment for hypermethylation in both the candidate gene and genome-wide analyses. Using these DNAm changes, pathway analysis identified significantly hypermethylated signaling networks after n-3 PUFA treatment, such as the Toll-like Receptor pathway. Based on analyses of data per individual, DNAm changes from n-3 PUFA treatment appear highly variable between study participants.\nConclusions: Dietary n-3 PUFA supplementation for six months is associated with DNAm changes in PBMCs with potential for anti-inflammatory effects. PBMC DNAm profiles may offer a novel means of assessing individual response to n-3 PUFAs. This observation warrants further investigation in future n-3 PUFA intervention studies.", "filename": "2020.10.09.20209726v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209726 "}, {"title": "A rapid and cost-effective multiplex ARMS-PCR method for the simultaneous genotyping of the circulating SARS-CoV-2 phylogenetic clades", "abstract": "Tracing the globally circulating SARS-CoV-2 mutants is essential for the outbreak alerts and far-reaching epidemiological surveillance. The available technique to identify the phylogenetic clades through high-throughput sequencing is costly, time-consuming, and labor-intensive that hinders the viral genotyping in low-income countries. Here, we propose a rapid, simple and cost-effective amplification-refractory mutation system (ARMS)-based multiplex reverse-transcriptase PCR assay to identify six distinct phylogenetic clades: S, L, V, G, GH, and GR. This approach is applied on 24 COVID-19 positive samples as confirmed by CDC approved real-time PCR assay for SARS-CoV-2. Our multiplex PCR is designed in a mutually exclusive way to identify V-S and G-GH-GR clade variants separately. The pentaplex assay included all five variants and the quadruplex comprised of the triplex variants alongside either V or S clade mutations that created two separate subsets. The procedure was optimized in the primer concentration (0.2-0.6 \u03bcM) and annealing temperature (56-60\u00b0C) of PCR using 3-5 ng/\u03bcl cDNA template synthesized upon random- and oligo(dT)-primer based reverse transcription. The different primer concentration for the triplex and quadruplex adjusted to different strengths ensured an even amplification with a maximum resolution of all targeted amplicons. The targeted Sanger sequencing further confirmed the presence of the clade-featured mutations with another set of our designed primers. This multiplex ARMS-PCR assay is sample, cost-effective, and convenient that can successfully discriminate the circulating phylogenetic clades of SARS-CoV-2.", "filename": "2020.10.08.20209692v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209692 "}, {"title": "Estimating the effect of social inequalities in the mitigation of COVID-19 across communities in Santiago de Chile", "abstract": "We study the spatio-temporal spread of SARS-CoV-2 in Santiago de Chile using anonymized mobile phone data from 1.4 million users, 22% of the whole population in the area, characterizing the effects of non-pharmaceutical interventions (NPIs) on the epidemic dynamics. We integrate these data into a mechanistic epidemic model calibrated on surveillance data. As of August 1, 2020, we estimate a detection rate of 102 cases per 1,000 infections (90% CI: [95 - 112 per 1,000]).\nWe show that the introduction of a full lockdown on May 15, 2020, while causing a modest additional decrease in mobility and contacts with respect to previous NPIs, was decisive in bringing the epidemic under control, highlighting the importance of a timely governmental response to COVID-19 outbreaks. We find that the impact of NPIs on individuals' mobility correlates with the Human Development Index of comunas in the city. Indeed, more developed and wealthier areas became more isolated after government interventions and experienced a significantly lower burden of the pandemic. The heterogeneity of COVID-19 impact raises important issues in the implementation of NPIs and highlights the challenges that communities affected by systemic health and social inequalities face adapting their behaviors during an epidemic.", "filename": "2020.10.08.20204750v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20204750 "}, {"title": "Estimating the Burden of COVID-19 Symptoms Among Participants at the 2020 USA Curling Club Nationals Tournament", "abstract": "The COVID-19 pandemic has been a significant cause of global morbidity and mortality, with evidence suggesting that activities involving heavier breathing, such as singing and exercise, can result in increased risk for disease transmission. The USA Curling Club Nationals is a week-long curling tournament to determine the men's and women's club-level champions. The 2020 tournament took place March 7-14 at the Potomac Curling Club in Laurel, MD, and featured teams from across the United States. Preventative measures, such as increased cleaning and disinfection of surfaces, single use and disposable food containers, and canceling traditional event banquets were implemented. Despite these measures, players, coaches, officials, volunteers, and spectators contracted the virus as a result of participation in the event. We surveyed participants to assess total positivity, potential days of transmission, and the burden of symptoms experienced among the participants. We found that 55.6% of all participants reported experiencing symptoms consistent with COVID-19, with nearly all experiencing more than one symptom. Although most participants' symptoms resolved quickly, 9.6% of all participants experienced symptoms for at least one month and 12.6% of all participants reported taking at least 30 days before they felt they had returned to normal. As a result of this study, we believe curling tournaments have the potential to be high-risk events for the transmission of COVID-19. Further infection prevention measures that were not yet publicly implemented at the time of this tournament may be an effective method of lowering transmission risk, although further research is required.", "filename": "2020.10.08.20209437v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209437 "}, {"title": "Characteristics and clinical features of SARS-CoV-2 infections among ambulatory and hospitalized children and adolescents in an integrated health care system in Tennessee", "abstract": "Background\nLittle is known regarding the full spectrum of illness among children with SARS-CoV-2 infection across ambulatory and inpatient settings. \n\nMethods\nActive surveillance was performed for SARS-CoV-2 by polymerase chain reaction among asymptomatic and symptomatic individuals in a quaternary care academic hospital laboratory in Tennessee from March 12-July 17, 2020. For symptomatic patients \u226418 years of age, we performed phone follow-up and medical record review to obtain sociodemographic and clinical data on days 2, 7, and 30 after diagnosis and on day 30 for asymptomatic patients \u226418 years. Daily and 7-day average test positivity frequencies were calculated for children and adults beginning April 26, 2020.\n\nResults\nSARS-CoV-2 was detected in 531/10327 (5.1%) specimens from patients \u226418 years, including 46/5752 (0.8%) asymptomatic and 485/4575 (10.6%) specimens from 459 unique symptomatic children. Cough (51%), fever (42%), and headache (41%) were the most common symptoms associated with SARS-CoV-2 infection. SARS-CoV-2-related hospitalization was uncommon (18/459 children; 4%); no children with SARS-CoV-2 infection during the study period required intensive care unit admission. Symptom resolution occurred by follow-up day 2 in 192/459 (42%), by day 7 in 332/459 (72%), and by day 30 in 373/396 (94%). The number of cases and percent positivity rose in late June and July in all ages.\n\nConclusions\nIn an integrated healthcare network, most pediatric SARS-CoV-2 infections were mild, brief, and rarely required hospital admission, despite increasing cases as community response measures were relaxed.", "filename": "2020.10.08.20208751v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208751 "}, {"title": "An immunologically active, adipose-derived extracellular matrix biomaterial for soft tissue reconstruction: concept to clinical trial", "abstract": "Soft tissue reconstruction remains an intractable clinical challenge as current surgical options and synthetic implants may produce inadequate outcomes. Soft tissue deficits may be surgically reconstructed using autologous adipose tissue, but these procedures can lead to donor site morbidity, require multiple trips to the operating room, and have highly variable outcomes. To address the clinical need for soft tissue reconstruction, we developed an off-the-shelf adipose matrix from allograft human adipose tissue (acellular adipose tissue, AAT). We applied physical and chemical processing methods to remove lipids and create an injectable matrix that mimicked the properties of fat grafting materials. Biological activity was assessed using cell migration and stem cell adipogenesis assays. Characterization of the regenerative immunology properties in a murine muscle injury model revealed allograft and xenograft AAT induced pro-regenerative CD4+ T cells and macrophages with xenograft AAT attracting additional eosinophils secreting interleukin 4 (Il4). In immunocompromised mice, AAT injections retained similar tissue volumes as human fat grafts but did not have the cysts and calcifications that formed in the human fat graft implants. Combination of AAT with human adipose-derived stem cells (ASCs) resulted in lower implant volumes. However, tissue remodeling and new adipose development increased significantly with the addition of cells. Larger injected volumes of porcine-derived AAT demonstrated biocompatibility and greater volume retention when applied allogeneicly in Yorkshire cross pigs. Under a biologic IND application, AAT was implanted in healthy volunteers in abdominal tissue that was later removed (panniculectomy or abdominoplasty). The AAT implants were well tolerated and biocompatible in all eight human subjects. Analysis of implants removed between 1 and 18 weeks demonstrated increasing cellular infiltration and immune populations, suggesting continued tissue remodeling and the potential for long term tissue replacement.", "filename": "2020.10.08.20206672v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20206672 "}, {"title": "The Statistical Monitoring by Adaptive RMSTD Tests: an efficient, informative, and customizable method for the complete internal quality control intended for low-frequent sampling of control measures", "abstract": "Two control mechanisms are relevant to perform an internal quality assurance: a permissible limit L_SMC applied to single measures of control samples and a retrospective statistical analysis to detect increased imprecision and baseline drifts. A common statistical metric is the root mean square (total) deviation (RMSD/RMSTD). To focus on recent changes under low-frequent sampling conditions, the monitored amount of retrospective data is usually very small. Unfortunately, the calculated RMSTD of a small data set with n<50 samples has a significant statistical uncertainty that needs to be considered in adequate limit definitions. In particular, the minimum reasonable limit L_RMSTD(n), applied to the RMSTD of a series of n samples, decreases from L_SMC (e.g., 2.33*standard_deviation+bias) for n=1 towards L_true_RMSTD for n\u2192\u221e (long-term statistics). Two mathematical approaches were derived to reliably estimate an optimal function to adjust L_RMSTD(n) to small sample sizes. \nThis knowledge led to the development of a new quality-control method: the Statistical Monitoring by Adaptive RMSTD Tests (SMART). SMART requires just one mandatory limit (either L_SMC or L_true_RMSTD) per analyte. By definition of up to 7 possible alert levels, SMART can early recognize and evaluate both the significance of a single outlier and establishing critical trends or shifts in recent SMC data. SMART is intended to efficiently monitor and evaluate small amounts of control data.", "filename": "2020.10.08.20209288v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209288 "}, {"title": "Effectiveness of Influenza Vaccine for Preventing Laboratory-Confirmed Influenza Hospitalizations in Immunocompromised Adults", "abstract": "Background: Yearly influenza immunization is recommended for immunocompromised (IC) individuals, although immune responses are lower than that for the non-immunocompromised and the data on vaccine effectiveness (VE) in the IC is scarce. We evaluated VE against influenza-associated hospitalization among IC adults. \nMethods: We analyzed data from adults \u2265 18 years hospitalized with acute respiratory illness (ARI) during the 2017-2018 influenza season at 10 hospitals in the United States. IC adults were identified using pre-specified case-definitions, utilizing electronic medical record data. VE was evaluated with a test-negative case-control design using multivariate logistic regression with PCR-confirmed influenza as the outcome and vaccination status as the exposure, adjusting for age, enrolling site, illness onset date, race, days from onset to specimen collection, self-reported health, and self-reported hospitalizations.\nResults: Of 3,524 adults hospitalized with ARI, 1,210 (34.3%) had an immunocompromising condition. IC adults were more likely to be vaccinated than non-IC (69.5% vs 65.2%), and less likely to have influenza (22% vs 27.8%). The mean age did not differ among IC and non-IC (61.4 vs 60.8 years old). The overall VE against influenza hospitalization, including immunocompetent adults, was 33% (95% CI, 21% to 44%). VE among IC vs non-IC adults was lower at 5% (-29% to 31%) vs. 41% (27% to 52%) (p<0.05 for interaction term).  \nConclusions: VE in one influenza season was very low among IC individuals. Future efforts should include evaluation of VE among the different immunocompromising conditions and whether enhanced vaccines improve the suboptimal effectiveness among the immunocompromised.", "filename": "2020.10.08.20208579v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208579 "}, {"title": "Estimating the impact of disruptions due to COVID-19 on HIV transmission and control among men who have sex with men in China", "abstract": "Introduction \nThe COVID-19 pandemic is impacting HIV care globally, with gaps in HIV treatment expected to increase HIV transmission and HIV-related mortality. We estimated how COVID-19-related disruptions could impact HIV transmission and mortality among men who have sex with men (MSM) in four cities in China.\n\nMethods \nRegional data from China indicated that the number of MSM undergoing facility-based HIV testing reduced by 59% during the COVID-19 pandemic, alongside reductions in ART initiation (34%), numbers of sexual partners (62%) and consistency of condom use (25%).  A deterministic mathematical model of HIV transmission and treatment among MSM in China was used to estimate the impact of these disruptions on the number of new HIV infections and HIV-related deaths. Disruption scenarios were assessed for their individual and combined impact over 1 and 5 years for a 3-, 4- or 6-month disruption period. \n\nResults\nOur China model predicted that new HIV infections and HIV-related deaths would be increased most by disruptions to viral suppression, with 25% reductions for a 3-month period increasing HIV infections by 5-14% over 1 year and deaths by 7-12%. Observed reductions in condom use increased HIV infections by 5-14% but had minimal impact (<1%) on deaths. Smaller impacts on infections and deaths (<3%) were seen for disruptions to facility testing and ART initiation, but reduced partner numbers resulted in 11-23% fewer infections and 0.4-1.0% fewer deaths. Longer disruption periods of 4 and 6 months amplified the impact of combined disruption scenarios. When all realistic disruptions were modelled simultaneously, an overall decrease in new HIV infections was always predicted over one year (3-17%), but not over 5 years (1% increase - 4% decrease), while deaths mostly increased over one year (1-2%) and 5 years (1.2 increase - 0.3 decrease).\n\nConclusions\nThe overall impact of COVID-19 on new HIV infections and HIV-related deaths is dependent on the nature, scale and length of the various disruptions. Resources should be directed to ensuring levels of viral suppression and condom use are maintained to mitigate any adverse effects of COVID-19 related disruption on HIV transmission and control among MSM in China.", "filename": "2020.10.08.20209072v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209072 "}, {"title": "Meta-analysis and adjusted estimation of COVID-19 case fatality risk in India and its association with the underlying comorbidities", "abstract": "There is a lack of COVID-19 adjusted case fatality risk (aCFR) estimates and information on states with high aCFR. State-specific aCFRs were estimated, using 13 day lag for fatality. To estimate country level aCFR, state estimates were meta-analysed. Multiple correspondence analyses (MCA), followed by univariable logistic regression, were conducted to understand the association between aCFR and geodemographic, health and social indicators. Based on health indicators, states likely to report a higher aCFR were identified. Using random- and fixed-effects models, the aCFRs in India were 1.42 (95% CI 1.19 - 1.70) and 2.97 (95% CI 2.94 - 3.00), respectively. The aCFR was grouped with the incidence of diabetes, hypertension, cardiovascular diseases and acute respiratory infections in the first and second dimensions of MCA. The current study demonstrated the value of using meta-analysis to estimate aCFR. To decrease COVID-19 associated fatalities, states estimated to have a high aCFR must take steps to reduce co-morbidities.", "filename": "2020.10.08.20209163v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209163 "}, {"title": "An epigenetic proxy of chronic inflammation outperforms serum levels as a biomarker of brain ageing", "abstract": "Low-level chronic inflammation increases with age and is associated with cognitive decline. DNA methylation (DNAm) levels may provide more stable reflections of cumulative inflammatory burden than traditional serum approaches. Using structural and diffusion MRI data from 521 individuals aged 73, we demonstrate that a DNAm proxy of C-Reactive Protein (CRP) shows significantly (on average 6.4-fold) stronger associations with brain structural outcomes than serum CRP. We additionally find that DNAm CRP has an inverse association with global and domain-specific (speed, visuospatial and memory) cognitive functioning, and that brain structure partially mediates this CRP-cognitive association (up to 29.4%), dependent on lifestyle and health factors. These data support the hypothesis that chronic systemic inflammation may contribute to neurodegenerative brain changes which underlie differences in cognitive ability in later life. DNA methylation-based predictors could be used as proxies for chronic inflammatory status.", "filename": "2020.10.08.20205245v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20205245 "}, {"title": "Elevated antiviral, myeloid and endothelial inflammatory markers in severe COVID-19", "abstract": "The mechanisms that underpin COVID-19 disease severity, and determine the outcome of infection, are only beginning to be unraveled. The host inflammatory response contributes to lung injury, but circulating mediators levels fall below those in classical cytokine storms. We analyzed serial plasma samples from 619 patients hospitalized with COVID-19 recruited through the prospective multicenter ISARIC clinical characterization protocol U.K. study and 39 milder community cases not requiring hospitalization. Elevated levels of numerous mediators including angiopoietin-2, CXCL10, and GM-CSF were seen at recruitment in patients who later died. Markers of endothelial injury (angiopoietin-2 and von-Willebrand factor A2) were detected early in some patients, while inflammatory cytokines and markers of lung injury persisted for several weeks in fatal COVID-19 despite decreasing antiviral cytokine levels. Overall, markers of myeloid or endothelial cell activation were associated with severe, progressive, and fatal disease indicating a central role for innate immune activation and vascular inflammation in COVID-19.", "filename": "2020.10.08.20209411v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209411 "}, {"title": "Large-scale transcriptome-wide profiling of microRNAs in human placenta and maternal plasma at early to mid gestation", "abstract": "Background\n\nMicroRNAs (miRNAs) are increasingly seen as important regulators of placental development and opportunistic biomarker targets. Given the difficulty in obtaining samples from early gestation and subsequent paucity of the same, investigation of the role of miRNAs in early gestation human placenta has been limited. To address this, we generated miRNA profiles using 96 placentas from presumed normal pregnancies, across early gestation, in combination with matched profiles from maternal plasma. Placenta samples range from 6-23 weeks of gestation, a time period that includes placenta from the early, relatively low but physiological (6-10 weeks of gestation) oxygen environment, and later, physiologically normal oxygen environment (11-23 weeks of gestation).\n\nResults\n\nWe identified 637 miRNAs with expression in 86 samples (after removing poor quality samples), showing a clear gestational age gradient from 6-23 weeks of gestation. We identified 374 differentially expressed (DE) miRNAs between placentas from 6-10 week versus 11-23 weeks of gestation. We see a clear gestational age group bias in miRNA clusters C19MC, C14MC, miR-17~92 and paralogs, regions that also include many DE miRNAs. Proportional change in expression of placenta-specific miRNA clusters was reflected in maternal plasma.\n\nConclusion\n\nThe presumed introduction of oxygenated maternal blood into the placenta (between ~10-12 weeks of gestation) changes the miRNA profile of the chorionic villus, particularly in placenta-specific miRNA clusters. Data presented here comprise a clinically important reference set for studying early placenta development and may underpin the generation of minimally invasive methods for monitoring placental health.", "filename": "2020.08.19.20177873v2", "doi": "doi: https://doi.org/10.1101/2020.08.19.20177873 "}, {"title": "The Health Impact of Electronic Nicotine Delivery Systems: A Systematic Review", "abstract": "The objective of this systematic review was to identify, report and critically appraise studies that have reported health outcomes from use of electronic nicotine delivery systems (ENDS).\n\n\nWe conducted a systematic review of all published literature on the health impact of ENDS products from 1st January 2015 until February 1, 2020, following the PRISMA protocol, including across the databases, PubMed, Embase, Scopus and Google Scholar using medical subject headings. \n\nA category for the level of evidence was assigned blindly using the Centres for Evidence Based Medicine framework. A similar approach was adopted to evaluate methodological quality of each study utilizing the National Institutes for Health (NIH) Quality Assessment Tools. \n\n\nThe database search identified 755 studies and a further 265 were identified from other sources and reference reviews of which 37 studies met the eligibility criteria.\n\nThe majority of studies were of low strength for levels of evidence including 24 (65%) cross-sectional, 1(2.7%) case-control and six (16%) case studies. There were four (11%) cohort studies and only one (2.7%) RCT. There was only one (2.7%) meta-analysis or pooled study of observational study designs; there were no pooled results of randomized controlled trials. Of 37 studies, eight (22%) studies reported on benefits, two (2%) studies were neutral, reporting on both harm and benefits, the remaining 27 (73%) reported only on harms. The quality ratings were poor (20, 54%), fair (9, 24%) and good (8, 22%). \n\nIn our review ENDS use has not been shown to be causative for any CVD outcomes and has been shown to be beneficial for hypertensive patients. Switching from cigarettes to e-cigarettes resulted in reduced exacerbations of COPD, with no evidence of long-term deterioration in lung function. There was a suggestion of short-term reductions in respiratory function in asthmatics, but no increased risk of asthma in ENDS users who were never smokers. Mental Health, cancer and mortality have not been adequately studied to form any consensus with regards to health outcomes from ENDS use.\n\nOur review suggests that the majority of studies on the use of ENDS products reported on negative health impacts with few reporting on health outcomes from switching from cigarettes to e-cigarettes. The strength of evidence and quality of the published studies overall is poor. \n\nOur review has demonstrated that ENDS use is not causative for any harmful CVD outcomes and may be beneficial for hypertensive patients. Switching from cigarettes to e-cigarettes resulted in reduced exacerbations of COPD, with no evidence of increased risk of asthma, long-term respiratory harm or deterioration in lung function. Other health outcomes such as mental health, cancer and mortality have not been adequately studied to form a consensus. However, the findings of our review did not negate the consensus held by many that ENDS use is safer than the risks posed from smoking cigarettes. \n\nOverall, our review found the research on ENDS use is not yet adequate to provide quantitative estimates about health risks. Consequently, the current body of evidence is inadequate for informing policy around tobacco harm reduction.", "filename": "2020.10.07.20208355v2", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208355 "}, {"title": "Machine learning based prognostic model and mobile application software platform for predicting infection susceptibility of COVID-19 using health care data", "abstract": "From public health perspectives of COVID-19 pandemic, accurate estimates of infection severity of individuals are extremely valuable for the informed decision making and targeted response to an emerging pandemic. This paper presents machine learning based prognostic model for providing early warning to the individuals for COVID-19 infection using the health care data set. In the present work, a prognostic model using Random Forest classifier and support vector regression is developed for predicting the Infection Susceptibility Probability (ISP) score of COVID-19 and it is applied on an open health care data set containing 27 field values. The typical fields of the health care data set include basic personal details such as age, gender, number of children in the household, marital status along with medical data like Coma score, Pulmonary score, Blood Glucose level, HDL cholesterol etc. An effective preprocessing method is carried out for handling the numerical, categorical values (non-numerical), missing data in the health care data set. The correlation between the variables in the health care data is analyzed using the correlation coefficient and heat map with a color code is used to identify the influencing factors on the Infection Susceptibility Probability (ISP) score of COVID-19. Based on the accuracy, Precision, Sensitivity and F-scores, it is noted that the random forest classifier provides an improved classification performance as compared to Support vector regression for the given health care data set. Android based mobile application software platform is developed using the proposed prognostic approach for enabling the healthy individuals to predict the susceptibility infection score of COVID-19 to take the precautionary measures. Based on the results of the proposed method, clinicians and government officials can focus on the highly susceptible people for limiting the pandemic spread.", "filename": "2020.10.09.20165431v2", "doi": "doi: https://doi.org/10.1101/2020.10.09.20165431 "}, {"title": "The impact of the SARS-CoV-2 pandemic on healthcare provision in Italy to non-COVID patients: a systematic review", "abstract": "Background: Italy has been one of the countries most affected by the SARS-CoV-2 pandemic and the regional healthcare system has had to quickly adapt its organization to meet the needs of infected patients. This has led to a drastic change in the routine management of non-communicable diseases with a potential long-term impact on patient health care. We investigated the management of non-COVID-19 patients across all medical specialties during the pandemic in Italy.\n\nMethods: A PRISMA guideline-based systematic review of the available literature was performed using PubMed, Embase, and Scopus, restricting the search to the main outbreak period in Italy (from 20 February to 22 June, 2020). We selected articles in English or Italian that detailed changes in the Italian hospital care for non-COVID-19 patients due to the pandemic. Our keywords included all medical specialties in combination with our geographical focus (Italy) and COVID-19.\n\nFindings: Of the 4643 potentially eligible studies identified by the search, 247 studies were included in the systematic review. A decrease in the management of emergencies in non-COVID patients was found together with an increase in mortality. Similarly, non-deferrable conditions met a tendency toward decreased diagnosis. All specialties have been affected by the reorganization of healthcare provision in the hub-and-spoke system and have benefited from telemedicine during the pandemic.\n\nInterpretation: Our work highlights the changes taking place in the Italian public healthcare system in order to tackle the developing health crisis due to the COVID-19 pandemic. The findings of our review may be useful to analyze future directions for the healthcare system in the case of new pandemic scenarios.", "filename": "2020.09.17.20192088v2", "doi": "doi: https://doi.org/10.1101/2020.09.17.20192088 "}, {"title": "A generalized SEIRD model with implicit social distancing mechanism: a Bayesian approach for the identification of the spread of COVID-19 with applications in Brazil and Rio de Janeiro state", "abstract": "Brazil's continental dimension poses a challenge to the control of the spread of COVID-19. Due to the country specific scenario of high social and demographic heterogeneity, combined with limited testing capacity, lack of reliable data, under-reporting of cases, and restricted testing policy, the focus of this study is twofold: (i) to develop a generalized SEIRD model that implicitly takes into account the quarantine measures, and (ii) to estimate the response of the COVID-19 spread dynamics to perturbations/uncertainties. By investigating the projections of cumulative numbers of confirmed and death cases, as well as the effective reproduction number, we show that the model parameter related to social distancing measures is one of the most influential along all stages of the disease spread and the most influential after the infection peak. Due to such importance in the outcomes, different relaxation strategies of social distancing measures are investigated in order to determine which strategies are viable and less hazardous to the population. The results highlight the need of keeping social distancing policies to control the disease spread. Specifically, the considered scenario of abrupt social distancing relaxation implemented after the occurrence of the peak of positively diagnosed cases can prolong the epidemic, with a significant increase of the projected numbers of confirmed and death cases. An even worse scenario could occur if the quarantine relaxation policy is implemented before evidence of the epidemiological control, indicating the importance of the proper choice of when to start relaxing social distancing measures.", "filename": "2020.05.30.20117283v2", "doi": "doi: https://doi.org/10.1101/2020.05.30.20117283 "}, {"title": "Chest X-ray image analysis and classification for COVID-19 pneumonia detection using Deep CNN", "abstract": "To speed up the discovery of COVID-19 disease mechanisms by X-ray images, this research developed a new diagnosis platform using a deep convolutional neural network (CNN) that is able to assist radiologists with diagnosis by distinguishing COVID-19 pneumonia from non-COVID-19 pneumonia in patients based on chest X-ray classification and analysis. Such a tool can save time in interpreting chest X-rays and increase the accuracy and thereby enhance our medical capacity for the detection and diagnosis of COVID-19. The research idea is that a set of X-ray medical lung images (which include normal, infected by bacteria, infected by virus including COVID-19) are used to train a deep CNN that can distinguish between the noise and the useful information and then uses this training to interpret new images by recognizing patterns that indicate certain diseases such as coronavirus infection in the individual images. The supervised learning method is used as the process of learning from the training dataset and can be thought of as a doctor supervising the learning process. It becomes more accurate as the number of analyzed images grows, and the average accuracy is above 95%. In this way, it imitates the training for a doctor, but the theory is that since it is capable of learning from a far larger set of images than any human, it can have the potential of being more accurate.", "filename": "2020.08.20.20178913v2", "doi": "doi: https://doi.org/10.1101/2020.08.20.20178913 "}, {"title": "Identifying Optimal COVID-19 Testing Strategies for Schools and Businesses: Balancing Testing Frequency, Individual Test Technology, and Cost", "abstract": "Background: COVID-19 test sensitivity and specificity have been widely examined and discussed yet optimal use of these tests will depend on the goals of testing, the population or setting, and the anticipated underlying disease prevalence. We model various combinations of key variables to identify and compare a range of effective and practical surveillance strategies for schools and businesses.\nMethods: We coupled a simulated data set incorporating actual community prevalence and test performance characteristics to a susceptible, infectious, removed (SIR) compartmental model, modeling the impact of base and tunable variables including test sensitivity, testing frequency, results lag, sample pooling, disease prevalence, externally-acquired infections, and test cost on outcomes case reduction. \nResults: Increasing testing frequency was associated with a non-linear positive effect on cases averted over 100 days. While precise reductions in cumulative number of infections depended on community disease prevalence, testing every 3 days versus every 14 days (even with a lower sensitivity test) reduces the disease burden substantially. Pooling provided cost savings and made a high-frequency approach practical; one high-performing strategy, testing every 3 days, yielded per person per day costs as low as $1.32.\nConclusions: A range of practically viable testing strategies emerged for schools and businesses. Key characteristics of these strategies include high frequency testing with a moderate or high sensitivity test and minimal results delay. Sample pooling allowed for operational efficiency and cost savings with minimal loss of model performance.", "filename": "2020.10.11.20211011v2", "doi": "doi: https://doi.org/10.1101/2020.10.11.20211011 "}, {"title": "Cardiovascular risk prediction in type 2 diabetes: a comparison of 22 risk scores in primary care setting", "abstract": "Objective: To compare performance of general and diabetes specific cardiovascular risk prediction scores in type 2 diabetes patients (T2DM).\n\nDesign: Cohort study.\n\nSetting: Scores were identified through a systematic review and included irrespective of predicted outcome, or inclusion of T2DM patients. Performance was assessed using data from routine practice.\n\nParticipants: A contemporary representative sample of 203,172 UK T2DM patients (age \u2265 18 years).\n\nMain outcome measures: Cardiovascular disease (CVD i.e., coronary heart disease and stroke) and CVD+ (including atrial fibrillation and heart failure).\n\nResults: We identified 22 scores: 11 derived in the general population, 9 in only T2DM patients, and 2 that excluded T2DM patients. Over 10 years follow-up, 63,000 events occurred. The RECODE score, derived in people with T2DM, performed best for both CVD (c-statistic 0.731 (0.728,0.734), and CVD+ (0.732 (0.729,0.735)).  Overall, neither derivation population, nor original predicted outcome influenced performance.  Calibration slopes (1 indicates perfect calibration) ranged from 0.38 (95%CI 0.37;0.39) to 1.05 (95%CI 1.03;1.07).  A simple, population specific recalibration process considerably improved performance, ranging between 0.98 and 1.03. Risk scores performed badly in people with pre-existing CVD (c-statistic ~0.55). Scores with more predictors did not perform scores better: for CVD+ QRISK3 (19 variables) c-statistic 0.69 (95%CI 0.68;0.69), compared to CHD Basic (8 variables) 0.71 (95%CI 0.70; 0.71).\n\nConclusions: CVD risk prediction scores performed well in T2DM, irrespective of derivation population and of original predicted outcome.  Scores performed poorly in patients with established CVD. Complex scores with multiple variables did not outperform simple scores. A simple population specific recalibration markedly improved score performance and is recommended for future use.<br>\nKeywords: Cardiovascular disease, Diabetes, Prediction, Risk Score, Systematic Review", "filename": "2020.10.08.20209015v3", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209015 "}, {"title": "Remote home monitoring (virtual wards) during the COVID-19 pandemic: a systematic review", "abstract": "Objectives: The aim of this review was to analyse the implementation and impact of remote home monitoring models (virtual wards) during COVID-19, identifying their main components, processes of implementation, target patient populations, impact on outcomes, costs and lessons learnt. \nDesign: The review was designed as a rapid systematic review to capture an evolving evidence base. We used the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) statement. \nSetting: The review included models led by primary and secondary care across seven countries. \nParticipants: 17 examples of models were included in the review. \nMain outcome measures:  Impact of remote home monitoring on virtual length of stay, escalation, emergency department attendance/reattendance, admission/readmission and mortality. \nResults: The aim of the models was to maintain patients safe in the right setting. Most models were led by secondary care and confirmation of COVID-19 was not required (in most cases). Monitoring was carried via online platforms, paper-based systems with telephone calls or (less frequently) through wearable sensors. Models based on phone calls were considered more inclusive. Patient/carer training was identified as a determining factor of success. We could not reach conclusions regarding patient safety and the identification of early deterioration due to lack of standardised reporting and missing data. Economic analysis was not reported beyond how the resources were used. \nConclusions: Future research should focus on staff and patient experiences of care and inequalities in patients access to care. Attention needs to be paid to the cost-effectiveness of the models and their sustainability, evaluation of their impact on patient outcomes by using comparators and the use of risk-stratification tools. \nProtocol registration: The review protocol was published on PROSPERO (CRD: 42020202888).", "filename": "2020.10.07.20208587v2", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208587 "}, {"title": "Comparative Effectiveness Study of Home-Based Interventions to Prevent CA-MRSA Infection Recurrence", "abstract": "BACKGROUND: Recurrent skin and soft tissue infections (SSTI) caused by Community-Associated Methicillin-Resistant (CA-MRSA) or Methicillin-Sensitive Staphylococcus aureus (CA-MSSA) present treatment challenges.\nOBJECTIVES: Can an evidence-based intervention (CDC Guidelines, topical decolonization, surface decontamination) reduce SSTI recurrence, mitigate household contamination and transmission, and improve patient-reported outcomes?\nDESIGN: Randomized trial  \nSETTING: Community settings\nPARTICIPANTS: Participants (n=186) with confirmed MRSA(+)/MSSA(+) SSTIs and household members.\nINTERVENTION Community Health Workers/Promotoras conducted home visits and provided participants with instructions, a five-day supply of mupirocin for nasal application, chlorhexidine for body cleansing, and disinfecting wipes for household cleaning (EXP) versus Usual Care (UC). \nMEASUREMENTS: Primary outcome was six-month SSTI recurrence recorded in electronic health records (EHR). Home visits (months 0/3) and telephone assessments (months 0/1/6) collected self-report data. Surveillance culture swabs (nares, axilla, groin) were obtained from index patients and participating household members. Secondary outcomes included household surface contamination, household member colonization and transmission, quality of life and satisfaction with care.\nRESULTS: Among patients with SSTIs (n=421), 44.2% were MRSA(+)/MSSA(+); an intent-to-treat analyses (n=186) demonstrated no significant differences in SSTI recurrence (OR: 1.4, 95% CI: 0.51-3.5). Among the enrolled cohort (n=119), there were no significant SSTI recurrence effects (OR=1.14, 95% CI=0.35-3.6). EXP participants showed reduced but non-significant colonization rates. There were no differential reductions in household member transmission or in reductions in proportions of households with >1 contaminated surface. Mupirocin resistance did not increase.  No significant improvements for patient-reported outcomes were seen.\nLIMITATIONS: A lower-than-predicted six-month recurrence rate may have limited the ability to detect effects.\nCONCLUSION: This intervention did not reduce clinician-reported MRSA/MSSA SSTI recurrence. No differences were observed for household members decolonization or household surfaces decontamination.", "filename": "2020.07.15.20154393v3", "doi": "doi: https://doi.org/10.1101/2020.07.15.20154393 "}, {"title": "A multi-centric, cross-sectional study on COVID-19 in Bangladesh: Clinical epidemiology and short-term outcomes in recovered individuals", "abstract": "Background: COVID-19 turned into a global pandemic rapidly. This study was aimed to investigate SARS-CoV-2 associated epidemiology and clinical outcomes in Bangladesh in order to understand the future course of COVID-19 pandemic and develop prevention approaches. \nDesign and Methods: A cross-sectional retrospective study was conducted for a sample of 1,021 RT-PCR confirmed COVID-19 cases admitted in six different hospitals in Bangladesh and who recovered four weeks prior to the interview date. \nResults: Of the total sample, 111 (10.9%) cases were asymptomatic while the number of symptomatic cases were 910 (89.1%). Higher prevalence of COVID-19 persisted in the male population (75%), cohorts having B (+) ve blood group (36.3%) and for the 31-40 age group. More than 85% of the sample reported a BCG vaccination mark. Common symptoms observed in our study samples were fever (72.4%), cough (55.9%), loss of taste (40.7%) and body ache (40%); whereas among the biochemical parameters, Neutrophil (46.4%), D-dimer (46.1%), and Ferritin (37.9%) levels were found elevated. Post-COVID complications including pain (31.8%), loss of concentration (24.4%) and anxiety or depression (23.1%) were also found significantly prevalent in the symptomatic cases with commodities. \nConclusion: Our study has shown that adult males aged in between 31-40 in Bangladesh are more vulnerable to being infected with COVID-19. The study also indicates a rising trend of the asymptomatic cases as the pandemic progresses deeper in time, and hence, deployment of interventions to curb further spread of community infection is necessary to avoid the grave outcomes of COVID-19 in Bangladesh.", "filename": "2020.09.09.20191114v2", "doi": "doi: https://doi.org/10.1101/2020.09.09.20191114 "}, {"title": "Severe COVID-19 patients display a back boost of seasonal coronavirus-specific antibodies", "abstract": "Severe acquired respiratory syndrome coronavirus-2 (SARS-CoV-2) is the cause of coronavirus disease (COVID-19). In severe COVID-19 cases, higher antibody titers against seasonal coronaviruses have been observed than in mild cases. To investigate antibody cross-reactivity as potential explanation for severe disease, we determined the kinetics, breadth, magnitude and level of cross-reactivity of IgG against SARS-CoV-2 and seasonal CoV nucleocapsid and spike from 17 severe COVID-19 cases at the clonal level. Although patients mounted a mostly type-specific SARS-CoV-2 response, B-cell clones directed against seasonal CoV dominated and strongly increased over time. Seasonal CoV IgG responses that did not neutralize SARS-CoV-2 were boosted well beyond detectable cross-reactivity, particularly for HCoV-OC43 spike. These findings support a back-boost of poorly protective coronavirus-specific antibodies in severe COVID-19 patients that may negatively impact de novo SARS-CoV-2 immunity, reminiscent of original antigenic sin.", "filename": "2020.10.10.20210070v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210070 "}, {"title": "Social Distancing with Movement Restrictions and the Effective Replication Number of COVID-19: Multi-Country Analysis Based on Phone Mobility Data", "abstract": "Background\nLinking phone mobility data to the effective replication number (Rt) could help evaluation of the impact of social distancing on the coronavirus disease 2019 (COVID-19) spread and estimate the time lag (TL) needed for the effect of movement restrictions to appear.\nMethods\nWe used a time-series analysis to discover how patterns of five indicators of mobility data relate to changes in Rt of 125 countries distributed over three groups based on Rt-mobility correlation. Group 1 included 71 countries in which Rt correlates negatively with residential and positively with other mobility indicators. Group 2 included 25 countries showing an opposite correlation pattern to Group 1. Group 3 included the 29 remaining countries. We chose the best-fit TL based on forecast and linear regression models. We used linear mixed models to evaluate how mobility indicators and the stringency index (SI) relate with Rt. SI reflects the strictness of governmental responses to COVID-19.\nResults\nWith a median of 14 days, TLs varied across countries as well as across groups of countries. There was a strong negative correlation between SI and Rt in most countries belonging to Group 1 as opposed to Group 2. SI (units of 10%) associated with decreasing Rt in Group 1 [\u03b2 -0.15, 95% CI -0.15 - (-0.14)] and Group 3 [-0.05, -0.07 - (-0.03)], whereas, in Group 2, SI associated with increasing Rt (0.13, 0.11 - 0.16).\nConclusion\nMobile phone mobility data could contribute evaluations of the impact of social distancing with movement restrictions on the spread of the COVID-19.", "filename": "2020.10.08.20209064v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209064 "}, {"title": "Summer School Holidays and the Growth Rate in Sars-CoV-2 Infections Across German Districts", "abstract": "In this ecological study, we analyse the association between summer school holidays and the weekly growth rate in SARS-CoV-2 infections in 401 German districts. In Germany school holidays are coordinated between states and spread out in order to reduce the number and length of traffic jams on motorways. We employ a district fixed effects Chow-type structural break model specification in which we test whether the holiday season as well as the period of two weeks after holidays end result in a higher infection growth rate than the period of two weeks before holidays start, our presumed counterfactual. We also allow the effect to vary week-by-week and by states. We find that between 30 and 50 percent of the growth rate in new infections in Germany can be attributed to the holiday season. A substantive increase in the growth of new infections can be observed between two and four weeks after the begin of the holidays. The effect becomes stronger the further holidays proceed. States in the West of Germany tend to experience stronger effects than those in the East. Part of this finding is explained by another result, namely that we find significant interaction effects of school holidays with per capita taxable income and the share of foreign residents in a district's population.", "filename": "2020.10.11.20210773v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210773 "}, {"title": "Evolution of COVID-19 cases in selected low- and middle-income countries: have they peaked due to high levels of infection and immunity?", "abstract": "COVID-19 cases have peaked and declined rapidly in many low- and middle-income countries in recent months, in some cases after control measures were relaxed. For 10 such countries, the hypothesis that COVID-19 cases have declined mainly through low susceptibility levels, stemming largely from high levels of infection leading to (at least temporary) immunity, warrants serious consideration. The Reed-Frost model, perhaps the simplest description for the evolution of cases in an epidemic, with only a few constant parameters, fits the observed case data remarkably well, and yields parameter values that are reasonable. The model results give infection levels of 45% and 79%, above the herd immunity threshold for each country under their current social distancing conditions. Reproduction numbers range between 1.4 and 2.0, indicating that epidemic curves were flattened but not suppressed. Between 0.05% and 2.86% of cases have been detected according to the estimates; values which are consistent with findings from serological studies. Overall infection fatality ratios for two of three countries studied are lower than expected from reported infection fatality ratios by age (which are based on studies of several high-income countries). COVID-19 may have lower age-specific fatality risks in some countries, due to differences in immune-response, prior exposure to coronaviruses, disease characteristics or other factors. We find that the hypothesis of control through low susceptibility would not have fit the evolution of reported cases in several European countries, even just after the initial peaks; instead, these countries reduced COVID-19 cases initially through disease control measures; and subsequent resurgences of cases obviously prove that those countries have infection levels well below those required for herd immunity. Our hypothesis that the 10 countries we studied have low susceptibility levels should now be tested further through immunity studies, and efforts should continue to determine the duration and extent of immunity to SARS-CoV-2 after infection.", "filename": "2020.09.26.20201814v5", "doi": "doi: https://doi.org/10.1101/2020.09.26.20201814 "}, {"title": "Vaginal dinoprostone versus placebo for pain relief during intrauterine device insertion: a systematic review and meta-analysis of randomized controlled trials", "abstract": "Objective: To investigate the safety and efficacy of vaginal dinoprostone versus placebo in pain relief during intrauterine device (IUD) insertion.\nDesign: Systematic review and meta-analysis of randomized placebo-controlled trials.\nSetting: Not applicable.\nPatient(s): Women undergoing IUD insertion and receiving vaginal dinoprostone or placebo.  \nIntervention(s): PubMed, Scopus, Web of Science, and Cochrane Library were screened from inception to 01-October-2020, using the following search strategy: (dinoprostone OR cervidil OR prepidil) AND (intrauterine device OR iud).\nMain outcome measure(s): IUD insertion related pain, patient satisfaction, provider ease of IUD insertion, and side effects.\nResult(s): Five studies met the study inclusion criteria, comprising 862 patients; equally 431 patients received vaginal dinoprostone and placebo. All studies had an overall low risk of bias. When compared to placebo, dinoprostone significantly correlated with decreased pain at tenaculum placement (SMD=-0.79, 95% CI [-1.43, -0.16], p=0.01), decreased pain at uterine sounding (SMD=-0.88, 95% CI [-1.54, -0.22], p=0.009), decreased pain at IUD insertion (SMD=-1.18, 95% CI [-1.74, -0.61], p<0.001), decreased need for additional analgesia (RR=0.34, 95% CI [0.22, 0.53], p<0.001), increased patient satisfaction (SMD=1.41, 95% CI [0.62, 2.20], p<0.001), and increased provider ease of IUD insertion (SMD=-1.17, 95% CI [-1.62, -0.73], p<0.001). Fever was statistically significantly higher in dinoprostone versus placebo group (RR=3.73, 95% CI [1.47, 9.44], p=0.006). All other side effects-including nausea, vomiting, shivering, diarrhea, abdominal cramps, vasovagal attack, uterine perforation, and postprocedural bleeding-did not substantially differ between both groups. \nConclusions: This first ever meta-analysis advocates that dinoprostone is safe, effective, and yields favorable analgesic outcomes during IUD insertion.", "filename": "2020.10.08.20209239v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209239 "}, {"title": "Physical health complaints among healthcare workers engaged in the care of critically ill COVID-19 patients: A single tertiary-care center prospective study from Japan", "abstract": "Background: Healthcare workers (HCWs) who care for patients with the novel coronavirus infectious disease (COVID-19) are at an increased risk and fear contracting the infection themselves. HCWs are chronically exposed to very intense stress, both and physically and mentally. Hospitals must reduce both the physical and mental burden of HCWs on the front lines and ensure their safety. No prospective study has focused on the physical health complaints among HCWs engaged in the care of critically ill COVID-19 patients. This study aimed to investigate the occupational risk among HCWs of experiencing physical symptoms during the current COVID-19 pandemic.\nMethods: A twice-weekly questionnaire targeting HCWs who care for COVID-19 patients was performed at Osaka City University Hospital from April 30 to May 31, 2020 using a shareable Research Electronic Data Capture tool. The demographic characteristics of the participants, frequency of exposure to at-risk care, and physical complaints were evaluated.\nResults: A total of 35 doctors, 88 nurses, and 35 technicians were engaged in the care of these critically ill COVID-19 patients. 76 HCWs participated in this study, of whom 24 (31.6%) were doctors, 43 (56.6%) were nurses, and 9 (11.8%) were technicians. The frequency of experiencing any physical symptom was 25.0% among HCWs. Exposure to at-risk care was significantly higher among nurses than among doctors (p < 0.001); likewise, the frequency of experiencing physical symptoms was higher among nurses than among doctors (p < 0.01). The multivariate analysis revealed that nurses (odds ratio 8.29; p = 0.01) might be independently at risk of experiencing physical symptoms.\nConclusions: Our results indicate that occupational health care at hospitals must be allocated to HCWs who are highly exposed to at-risk care, particularly nurses engaged in the care of COVID-19 patients.", "filename": "2020.10.09.20210393v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210393 "}, {"title": "Subclinical left ventricular disfunction in obese children: are we late?", "abstract": "Aim \n\tLongitudinal global strain (LGS) is reduced in obese patients with normal ejection fraction of the left ventricle. TAPSE/PAPS ratio, recently described, may be a step forward a more efficient RV function evaluation.\n\tThere are still few publications in the application of these methods in pediatric patients. \n\nMethods \n\tThis case-control study compared 104 children aged 5-18 years between October 2017 and February 2019, 52 obese children with body mass index (BMI) > +2 SD, and 52 matched controls. \n\n\tThey were screened for other cardiovascular risk factors like insulin resistance or hypercholesterolemia. A complete echocardiography including standard and functional parameters was performed.\n\nResults \n\tWe found that obese children presented poor systolic function (LGS -15,90 +/- 3,84 %) in comparison with non-obese children (-19,44 +/- 5,75 %, p=0,001). LGS correlated positively with body mass index (BMI). \n\n\tStandard echocardiography also revealed cardiomegaly and hypertrophy. \n\tTAPSE/PASP ratio correlated negatively with triglycerides levels (beta -946; -0,402, p=0,014). Diastolic function was poor in those with HOMA-IR (beta -946; -0,375, p=0,016) and hypertriglyceridemia (beta -946; -0,375 p=0,024).\nConclusion \n\tWe think that is necessary to perform a standarised cardiovascular evaluation in obese children for early identification of subclinical dysfunction especially in those with insulin resistance and dyslipidemia.", "filename": "2020.10.10.20195743v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20195743 "}, {"title": "Which electronic health record system should we use? - a systematic review", "abstract": "Objectives: This is the first systematic review to look at all published data on EHRs to determine which systems are advantageous.\n\nDesign: A systematic review was performed by searching EMBASE and Ovid MEDLINE between 1974 and November 2019.\n\nParticipants: All original studies that appraised EHR systems were included.\n\nMain outcome measures: EHR system comparison, implementation, user satisfaction, efficiency and performance, documentation, and research and development.\n\nResults: The search strategy identified 701 studies, which were filtered down to 46 relevant studies. Level of evidence ranged from 1 to 4 according to the Oxford Centre for Evidence-based Medicine. The majority of the studies were performed in the USA (n = 44). N=6 studies compared more than one EHR, and Epic followed by Cerner were the most favourable through direct comparison. N=17 studies evaluated implementation which highlighted that it was challenging, and productivity dipped in the early phase. N=5 studies reflected on user satisfaction, with women demonstrating higher satisfaction than men. Efficiency and performance issues were the driving force behind user dissatisfaction. N=26 studies addressed efficiency and performance, which improved with long-term use and familiarity. N=18 studies considered documentation and showed that EHRs had a positive impact with basic and speciality tasks. N=29 studies assessed research and development which revealed vast capabilities and positive implications. \n\nConclusion: Epic is the most studied EHR system and the most commonly used vendor on the market. There is limited comparative data between EHR vendors, so it is difficult to assess which is the most advantageous system.", "filename": "2020.10.11.20210930v1", "doi": "doi: https://doi.org/10.1101/2020.10.11.20210930 "}, {"title": "One size fits all?: Modeling face-mask fit on population-based faces", "abstract": "The use of face masks by the general population during viral outbreaks such as the COVID-19 pandemic, although at times controversial, has been effective in slowing down the spread of the virus. The fit of simple cloth masks on the face as well as the resulting perimeter leakage and face mask efficacy are expected to be highly dependent on the type of mask and facial topology. However, this effect has to date, not been examined and quantified. Here, we study the leakage of a rectangular cloth mask on a large virtual population of subjects with diverse facial features, using computational mechanics modeling. The effect of weight, age, gender, and height on the leakage is studied. The Centers for Disease Control and Prevention (CDC) recommended mask size was used as a basis for comparison and was found not to be the most effective design for all subjects. Thin, feminine, and young faces benefit from mask sizes smaller than that recommended by the CDC. The results show that side-edge tuck-in of the masks could lead to a larger localized gap opening in many face categories, and is therefore not recommended for all. The perimeter leakage from the face mask worn by thin/feminine faces is mostly from the leakage area along the bottom edge of the mask and therefore, a tuck-in of the bottom edge of the mask or a mask smaller than the CDC recommended mask size are proposed as a more effective design. The leakage from the top edge of the mask is determined to be largely unaffected by mask size and tuck-in ratio, meaning that other mechanical alterations such as a nose wire strip are necessary to reduce the leakage at this site.", "filename": "2020.10.07.20208744v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208744 "}, {"title": "High use of the emergency department shows typical features of complex systems: analysis of multicentre linked data", "abstract": "Objective, \nHigh use of the ED is a worldwide problem. We hypothesised that high use of the ED could be understood as a feature of a complex system comprising patients, healthcare and society. Complex systems have characteristic statistical properties, with stable patterns at the level of the system emerging from unstable patterns at the level of individuals who make up the system.\n\nMethods\nAnalysis of a linked dataset of routinely collected health records from all 13 hospital trusts providing ED care in the Yorkshire and Humber region of the UK (population 5.5 million). We analysed the distribution of attendances per person in each of three years and measured the transition of individual patients between high, low and non-attendance. We fitted data to power law distributions typically seen in complex systems using maximum likelihood estimation. \n\nResults \nThe data included 3.6 million attendances at EDs in 13 hospital trusts. 29/39 (74.3%) analyses showed a statistical fit to a power law; 2 (5.1%) fitted an alternative distribution. All trusts' data fitted a power law in at least one year. Differences over time and between hospital trusts were small and partly explained by demographics. In contrast, individual patients' high use was unstable between years. \n\nConclusions \nED attendance patterns are stable at the level of the system, but unstable at the level of individual high users.  Attendances follow a power law distribution typical of complex systems. Interventions to address ED high use need to consider the whole system and not just the individual high users.", "filename": "2020.10.08.20209296v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209296 "}, {"title": "Does sensory modulation dysfunction contribute to emotional dysregulation in children with ADHD?: Analysis plan", "abstract": "Introduction: Attention-deficit/hyperactivity disorder (ADHD) is one of the most common neurodevelopmental disorders of childhood. Up to 50% of children with ADHD may also experience symptoms of emotional dysregulation, such as anger, irritability, and aggression. Emotional dysregulation contributes to adverse health outcomes such as depression and peer problems, yet it is poorly understood and effective treatment options are lacking. Emerging evidence suggests that sensory processing may play a role in emotional dysregulation. Forty to 50% of children with ADHD may also experience sensory modulation dysfunction, or SMD. SMD is characterized by hypo- or hyperreactivity to pain and sensation. Only one study investigated the relationship of SMD and emotional dysregulation in ADHD; they found a correlation of r=0.45. If SMD drives emotional dysregulation in ADHD, treating SMD has the potential to improve emotional regulation. Further evaluating the relationship between SMD and emotional dysregulation in ADHD is the crucial first step in developing effective treatment options.\n\nMethods: Data for this analysis are derived from the baseline assessment of a multi-site, randomized, controlled trial: The Micronutrients for ADHD in Youth (MADDY) Study. The study enrolled children aged 6-12 with a diagnosis of ADHD and symptoms of emotional dysregulation. Using a cross-sectional study design, we will measure the association between emotional dysregulation and SMD at baseline. Emotional dysregulation was measured using the Strengths and Difficulties Questionnaire (SDQ) and a composite score from the Child and Adolescent Symptom Inventory, Version-5 (CASI-5). SMD will be assessed using three subscales from the Temperament in Middle Childhood Questionnaire (TMCQ). To test our hypothesis, we will use simple linear regression. Models will be adjusted for potential confounding variables.\n\nConclusion: Our results will serve to better characterize the relationship between SMD and emotional dysregulation in children with ADHD, which may inform treatment options and diminish adverse health outcomes.", "filename": "2020.10.09.20191601v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20191601 "}, {"title": "Estimated Seroprevalence of SARS-CoV-2 Antibodies Among Adults in Orange County, California", "abstract": " Background:   Clinic-based estimates of SARS-CoV-2 may considerably underestimate the total number of infections. Access to testing in the US has been heterogeneous and symptoms vary widely in infected persons. Public health surveillance efforts and metrics are therefore hampered by underreporting. We set out to provide a minimally biased estimate of SARS-CoV-2 seroprevalence among adults for a large and diverse county (Orange County, CA, population 3.2 million).\nMethods: We implemented a surveillance study that minimizes response bias by recruiting adults to answer a survey without knowledge of later being offered SARS-CoV-2 test. Several methodologies were used to retrieve a population-representative sample. Participants (n=2,979) visited one of 11 drive-thru test sites from July 10th to August 16th, 2020 (or received an in-home visit) to provide a finger pin-prick sample. We applied a robust SARS-CoV-2 Antigen Microarray technology, which has superior measurement validity relative to FDA-approved tests. \nFindings: Participants include a broad age, gender, racial/ethnic, and income representation. Adjusted seroprevalence of SARS-CoV-2 infection was 11.5% (95%CI: 10.5% to 12.4%). Formal bias analyses produced similar results. Prevalence was elevated among Hispanics (vs. other non-Hispanic: prevalence ratio [PR]= 1.47, 95% CI: 1.22 to 1.78) and household income <$50,000 (vs. >$100,000: PR= 1.42, 95% CI: 1.14 to 1.79).\nInterpretation: Results from a diverse population using a highly specific and sensitive microarray indicate a SARS-CoV-2 seroprevalence of ~12 percent. This population-based seroprevalence is seven-fold greater than that using official County statistics. In this region, SARS-CoV-2 also disproportionately affects Hispanic and low-income adults.", "filename": "2020.10.07.20208660v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208660 "}, {"title": "Clarifying predictions for COVID-19 from testing data: the example of New-York State", "abstract": "In this article, we use testing data as an input of a new epidemic model. We get nice a concordance between the best fit the model to the reported cases data for New-York state. We also get a good concordance of the testing dynamic and the epidemic's dynamic in the cumulative cases.    Finally, we can investigate the effect of multiplying the number of tests by 2, 5, 10, and 100 to investigate the consequences on the reduction of the number of reported cases.", "filename": "2020.10.10.20203034v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20203034 "}, {"title": "Genetic correlation and causality of cancers and Parkinson\u2032s disease", "abstract": "Background and objectives: Most cancers appear with reduced frequency in Parkinson \u2032 s disease (PD), but the prevalence of melanoma and brain cancers are often reported to be increased. Shared genetic architecture and causal relationships to explain these associations have not been fully explored.\nMethods: Linkage disequilibrium score regression (LDSC) was applied for five cancer studies with available genome-wide association studies (GWAS) summary statistics to examine genetic correlations with PD. Additionally, we used GWAS summary statistics of 15 different types of cancers as exposures and two-sample Mendelian randomization to study the causal relationship with PD (outcome). \nResults: LDSC analysis revealed a potential genetic correlation between PD and melanoma, breast cancer and prostate cancer. There was no evidence to support a causal relationship between the studied cancers and PD.\nConclusions: Our results suggest shared genetic architecture between PD and melanoma, breast, and prostate cancers, but no obvious causal relationship between cancers and PD.", "filename": "2020.10.07.20208124v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208124 "}, {"title": "Level of Knowledge in the COVID-19 Pandemic: A Cross-Sectional Survey of Canadian Medical Students", "abstract": "Background: During health crises medical education is often derailed as was the case during the current COVID-19 pandemic. Medical trainees face the daunting task of having to gather, filter and synthesize new information about the evolving situation often without the standardized resources they are used to. \n\nMethods: We surveyed Canadian medical students, in the hardest hit province of Quebec, on how they were acquiring knowledge as well as what they knew of the pandemic. Google Forms was used, with the survey being distributed to each medical school in Quebec (McGill, ULaval, Udem) both through email and through social media pages for each class year. Two analyses, Mann-Whitney and ANOVA tests, were performed for year of study and degree obtained.\n\nResults: We received responses from 111 medical students from three universities, which represents 5% of the students invited to complete the survey. Students reported using mass media most frequently (83%) and also had a high rate of use of social media (to gather information about the pandemic. They rated these resources low in terms of their trustworthiness despite the high rates of use (average 2.91 and 2.03 of 5 respectively). Medical students also endorsed using more formal resources like public health information, scientific journals and faculty-provided information that they trusted more, however, they accessed these resources at lower rates. Of note, medical students had correct answered 60% of COVID-19 prevention strategies, 73% clinical correct answers, 90% epidemiological correct answers. Additionally, students who were training in the larger city of Montreal, where the worst of the outbreak was focused, tended to significantly perform better (p<0.0001) than their colleagues who were not located there. \n\nConclusion: These finding indicate a wide use of information resources intended for public consumption rather than more rigorous and trustworthy sources. Furthermore, there seems to be a knowledge gap amongst medical students responding to this survey that suggests an opportunity to improve the delivery of educational content during this rapidly evolving pandemic.", "filename": "2020.10.07.20208801v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208801 "}, {"title": "Prevalence of COVID-19-related risk factors and risk of severe influenza outcomes in cancer survivors: a matched cohort study using linked English electronic health records data", "abstract": "Background\nPeople with active cancer are recognised as at risk of COVID-19 complications, but it is unclear whether the much larger population of cancer survivors is at elevated risk. We aimed to address this by comparing cancer survivors and cancer-free controls for (i) prevalence of comorbidities considered risk factors for COVID-19; and (ii) risk of severe influenza, as a marker of susceptibility to severe outcomes from epidemic respiratory viruses.\nMethods\nWe included survivors (\u22651 year) of the 20 most common cancers, and age, sex and general practice-matched cancer-free controls, derived from UK primary care data linked to cancer registrations, hospital admissions and death registrations. Comorbidity prevalences were calculated 1 and 5 years from cancer diagnosis. Risk of hospitalisation or death due to influenza was compared using Cox models adjusted for baseline demographics and comorbidities.\nFindings\n108,215 cancer survivors and 523,541 cancer-free controls were included. Cancer survivors had more asthma, other respiratory, cardiac, diabetes, neurological, renal, and liver disease, and less obesity, compared with controls, but there was variation by cancer site. There were 205 influenza hospitalisations/deaths, with cancer survivors at higher risk than controls (adjusted HR 2.78, 95% CI 2.04-3.80). Haematological cancer survivors had large elevated risks persisting for >10 years (HR overall 15.17, 7.84-29.35; HR >10 years from cancer diagnosis 10.06, 2.47-40.93). Survivors of other cancers had evidence of raised risk up to 5 years from cancer diagnosis only (HR 2.22, 1.31-3.74).\nInterpretation\nRisks of severe COVID-19 outcomes are likely to be elevated in cancer survivors. This should be taken into account in policies targeted at clinical risk groups, and vaccination for both influenza, and, when available, COVID-19, should be encouraged in cancer survivors.", "filename": "2020.10.08.20209304v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209304 "}, {"title": "Changes in hyoid bone position in skeletal Class II children post-functional appliance therapy.", "abstract": "Introduction: The hyoid bone is deeply involved in three important body functions: deglutition, phonation and respiration. Several studies have shown that changes in the position of the hyoid bone may influence in pharyngeal size with mandibular advancement, thus a forward positioned hyoid bone may be an indicator of wide upper airways. \nObjective. To determine the changes in the position of the hyoid bone after functional appliance treatment.\nMaterials and methods: 20 children (aged 9-13) that currently visit Hiroshima University Hospital actively undergoing FKO activator therapy volunteered for this study. Several lateral cephalometric radiographs were indicated and traced to assess hyoid bone position changes that might have occurred when actively complying with the FKO therapy, said radiographs were procured before active functional treatment (T0), during it (T1), and a year after continuous use of this appliance (T2). ANOVA tests were done to find statistical significance.\nResults: The results of these tests were analyzed and compared; it was found that, the hyoid bone is at a lower position from the mandibular plane and Frankfurt horizontal plane after FKO treatment, also the mandible is more forward after activator therapy, bringing the hyoid bone forward with it thus widening the lowest section of the upper airways.\nConclusion: The FKO not only induces the proper development of the mandible, it also potentially advances the position of the hyoid bone, thus affecting positively in the opening of airways providing an improvement in the breathing function of the children.", "filename": "2020.10.08.20208967v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208967 "}, {"title": "Prevalence of Mild Cognitive Impairment in the Lothian Birth Cohort 1936", "abstract": "Background\nThe Lothian Birth Cohort 1936 (LBC1936) is a highly-phenotyped longitudinal study of cognitive and brain ageing. Given its substantial clinical importance, we derived an indicator of mild cognitive impairment (MCI) as well as amnestic and non-amnestic subtypes at three time points.\nMethods\nMCI status was derived at three waves of the LBC1936 at ages 76 (n=567), 79 (n=441), and 82 years (n=341). A general MCI category was derived as well as amnestic MCI (aMCI) and non-amnestic MCI (naMCI). A comparison was made between MCI derivations using normative data from the LBC1936 cohort versus the general UK population.\nResults\nMCI rates showed a proportional increase at each wave between 76 and 82 years from 15% to 18%. Rates of MCI subtypes also showed a proportional increase over time: aMCI 4% to 6%; naMCI 12% to 16%. Higher rates of MCI were found when using the LBC1936 normative data to derive MCI classification rather than UK-wide norms.\nConclusions\nWe found that MCI and aMCI rates in the LBC1936 were consistent with previous research. However, naMCI rates were higher than expected. Future LBC1936 research should assess the predictive factors associated with MCI prevalence to validate previous findings and identify novel risk factors.", "filename": "2020.10.08.20209130v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209130 "}, {"title": "A Phase 1b/2a Clinical Trial of Dantrolene Sodium in Patients with Wolfram Syndrome", "abstract": "Background. Wolfram syndrome is a rare endoplasmic reticulum disorder characterized by insulin-dependent diabetes mellitus, optic nerve atrophy, and progressive neurodegeneration. Although there is currently no treatment to delay, halt, or reverse the progression of Wolfram syndrome, preclinical studies in cell and rodent models suggest that therapeutic strategies targeting endoplasmic reticulum calcium homeostasis, including dantrolene sodium, may be beneficial.\nMethods: Based on the results from preclinical studies on dantrolene sodium and ongoing longitudinal studies, our group put together the first-ever clinical trial in pediatric and adult patients with Wolfram syndrome. An open-label phase 1b/2a trial design was chosen. The primary objective of the study was to assess the safety and tolerability of dantrolene sodium in adult and pediatric patients with Wolfram syndrome. Secondary objectives were to evaluate the efficacy of dantrolene sodium on residual pancreatic beta-cell functions, visual acuity, quality of life measures related to vision, and neurological functions.\nResults: The results indicate that dantrolene sodium is well tolerated by patients with Wolfram syndrome. Although the study was small, a select few patients seemed to have improvements in beta-cell function, which might correlate with a positive trend in other outcome measures, including visual acuity and neurological functions.\nConclusion. This study justifies further investigation into using dantrolene sodium and other small molecules targeting the endoplasmic reticulum for the treatment of Wolfram syndrome.", "filename": "2020.10.07.20208694v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208694 "}, {"title": "An Innovative Non-Pharmaceutical Intervention to Mitigate SARS-CoV02 Spread: Probability Sampling to Identify and Isolate Asymptomatic Cases", "abstract": "Studies estimate that a substantial proportion of SARS-CoV-2 transmission occurs through individuals who do not exhibit symptoms. Mitigation strategies test only those who are moderately to severely symptomatic, excluding the substantial portion of cases that are asymptomatic yet still infectious and likely responsible for a large proportion of the virus spread (1-8). While isolating asymptomatic cases will be necessary to effectively control viral spread, these cases are functionally invisible and there is no current method to identify them for isolation. To address this major omission in COVID-19 control, we develop a strategy, Sampling-Testing-Quarantine (STQ), for identifying and isolating individuals with asymptomatic SARS-CoV-2 in order to mitigate the epidemic. STQ uses probability sampling in the general population, regardless of symptoms, then isolates the individuals who test positive along with their household members who are high probability for asymptomatic infections. To test the potential efficacy of STQ, we use an agent-based model, designed to computationally simulate the epidemic in the Seattle with infection parameters, like R0 and asymptomatic fraction, derived from population data. Our results suggest that STQ can substantially slow and decrease the spread of COVID-19, even in the absence of school and work shutdowns. Results also recommend which sampling techniques, frequency of implementation, and population subject to isolation are most efficient in reducing spread with limited numbers of tests.", "filename": "2020.10.07.20208686v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208686 "}, {"title": "Suicide and mental health during the COVID-19 pandemic in Japan", "abstract": "Background: The coronavirus disease (COVID-19) pandemic is an unprecedented public health crisis, but its effect on suicide deaths is little understood.\n\nMethod: We analyzed data from monthly suicide statistics between January 2017 and August 2020 and online surveys on mental health among the general population during the COVID-19 pandemic in Japan. \n\nResults: Compared to the last three years (2017-2019), the number of suicide deaths was lower during the initial phase of the pandemic but subsequently exceeded the past trend. By August 2020, the total number of suicides was 7.72% higher than the average number of suicides in the same month of the previous three years. The largest increase was found in suicides by young women (less than 40 years of age), with a 63.1% increase in August 2020 compared to the same month in the past three years. The number of suicides among students and housekeepers in summer months was notably larger in 2020. The survey data indicated that the status of mental health among young women was worse than that of women in other age groups. In addition, young female workers were more likely to have experienced a job or income loss in recent months compared to any other groups, suggesting adverse economic conditions surrounding some of these young female workers. \n\nConclusion: Our results strongly indicate that continuous monitoring of mental health, particularly that of the most vulnerable populations identified in this study, and appropriate suicide prevention efforts are necessary during and in the aftermath of the COVID-19 pandemic.", "filename": "2020.10.06.20207530v2", "doi": "doi: https://doi.org/10.1101/2020.10.06.20207530 "}, {"title": "SARS-CoV-2-specific peripheral T follicular helper cells correlate with neutralizing antibodies and increase during convalescence.", "abstract": "T-cell immunity is likely to play a role in protection against SARS-CoV-2 by helping generate neutralizing antibodies. We longitudinally studied CD4 T-cell responses to the M, N, and S structural proteins of SARS-CoV-2 in 21 convalescent individuals. Within the first two months following symptom onset, a majority of individuals (81%) mount at least one CD4 T-cell response, and 48% of individuals mount detectable SARS-CoV-2-specific peripheral T follicular helper cells (pTfh, defined as CXCR5+PD1+ CD4 T cells). SARS-CoV-2-specific pTfh responses across all three protein specificities correlate with antibody neutralization with the strongest correlation observed for S protein-specific responses. When examined over time, pTfh responses increase in frequency and magnitude in convalescence, and robust responses with magnitudes greater than 5% were detected only at the second convalescent visit, an average of 38 days post-symptom onset. These data deepen our understanding of antigen-specific pTfh responses in SARS-CoV-2 infection, suggesting that M and N protein-specific pTfh may also assist in the development of neutralizing antibodies and that pTfh response formation may be delayed in SARS-CoV-2 infection.", "filename": "2020.10.07.20208488v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208488 "}, {"title": "Forecasting COVID-19 cases in the Philippines using various mathematical models", "abstract": "Due to the rapid increase of COVID-19 infection cases in many countries such as the Philippines, many efforts in forecasting the daily infections have been made in order to better manage the pandemic, and respond effectively. In this study, we consider the cumulative COVID-19 infection cases in the Philippines from March 6 to July 31, 2020 and forecast the cases from August 1 - 15, 2020 using various mathematical models - weighted moving average, exponential smoothing, Susceptible-Exposed-Infected-Recovered (SEIR) model, Ornstein-Uhlenbeck process, Autoregressive Integrated Moving Average (ARIMA) model, and random forest. We then compare the results to the actual data using traditional error metrics. Our results show that the ARIMA(1,2,1) model has the closest forecast values to the actual data. Policymakers can use our result in determining which forecast method to use for their community in order to have data-based information for the preparation of their personnel and facilities.", "filename": "2020.10.07.20208421v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208421 "}, {"title": "Determinants of Time to Convalescence among COVID-19 Patients at Millennium COVID-19 Care Center in Ethiopia: A prospective cohort study", "abstract": "Aim: To estimate time to recovery/convalescence and identify determinants among COVID-19 infected patients admitted to Millennium COVID-19 Care Center in Addis Ababa, Ethiopia.  \nMethods: A prospective cohort study was conducted among a randomly selected sample of 360 COVID-19 patients who were on follow up from 2nd June to 5th July 2020. Kaplan Meier plots, median survival times, and Log-rank test were used to describe the data and compare survival distribution between groups.  Association between time to recovery/ convalescence and determinants was assessed using the Cox proportional hazard survival model, where hazard ratio, P-value, and 95% CI for hazard ratio were used for testing significance.\nResults: The mean age of the participants was 32.4 years (+/_ 12.5 years). On admission, 86.9 % had mild COVID-19, 78.6% were asymptomatic and 11.4% of the patients had a history of pre-existing co-morbid illness. The Median time to recovery/ convalescence among the study population was 16 days. The log-rank test shows that having non-mild (moderate and severe) disease, having one or more symptoms at presentation, and presenting with respiratory and constitutional symptoms seems to extend the time needed to achieve recovery. The Final Cox regression result shows that the presence of symptom at presentation was found to be a significant factor that affects time to recovery/ convalescence, the rate of achieving recovery/ convalescence among symptomatic patients was 44% lower than patients who were asymptomatic at presentation (HR= 0.560, 95% CI= 0.322-0.975, p-value=0.040).\nConclusions: Presence of symptom was found to be associated with delayed viral clearance. This implies symptomatic patients are more likely to be infectious because of the prolonged viral shedding in addition to the presence of a more concentrated virus in the upper respiratory tract that enhances the transmission. Therefore, attention should be given in the isolation and treatment practice of COVID-19 patients with regard to presence of symptom.", "filename": "2020.10.07.20208413v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208413 "}, {"title": "Variability of Salivary and Nasal Specimens for SARS-CoV-2 Detection", "abstract": "In a large cohort of ambulatory confirmed COVID-19 patients with multiple self-collected sample time points, we compared 202 matched nasal-oropharyngeal swabs and oral salivary fluid sample pairs by RT-PCR. Nasal-oropharyngeal swabs were more sensitive than this salivary sample type (oral crevicular fluid) suggesting that not all saliva sample types have equivalent sensitivity. However, all samples that were Vero E6-TMPRSS2 cell culture positive (e.g., infectious virus) were also oral fluid RT-PCR positive suggesting that oral fluid may find the patients most likely to transmit disease to others.", "filename": "2020.10.07.20208520v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208520 "}, {"title": "LDL-apheresis as an alternate method for plasma LPS purification in healthy volunteers, dyslipidemic and septic patients", "abstract": "Lipopolysaccharide (LPS) is a key player for innate immunity activation. It is therefore a prime target for sepsis treatment, as antibiotics are not sufficient to improve outcome during septic shock. Extracorporeal removal method by polymyxin B hemoperfusion (PMX-DHP) is used in Japan, but recent trials failed to show a significant lowering of circulating LPS levels after PMX-DHP therapy. PMX-DHP has a direct effect on LPS molecules. However, LPS is not present in a free form in the circulation, as it is mainly carried by lipoproteins, including low density lipoproteins (LDL). Lipoproteins are critical for physiological LPS clearance, as LPS are carried by low density lipoproteins (LDL) to the liver for elimination. We hypothesized that LDL-apheresis can be an alternate method for LPS removal. We demonstrated first in vitro that LDL apheresis microbeads are almost as efficient as PMX beads to reduce LPS concentration in LPS-spiked human plasma, whereas it is not active in phosphate-buffered saline. We found that PMX was also adsorbing lipoproteins, although less specifically. Then, we found that endogenous LPS of patients treated by LDL-apheresis for familial hypercholesterolemia is also removed during their LDL-apheresis sessions, both with electrostatic-based devices and filtration devices. Finally, LPS circulating in the plasma of septic shock and severe sepsis patients with gram-negative bacteremia was also removed in vitro by LDL adsorption. Overall, these results underline the importance of lipoproteins for LPS clearance, making them a prime target to study and treat endotoxemia-related conditions.", "filename": "2020.10.07.20206771v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20206771 "}, {"title": "Rapid detection of SARS-CoV2 by Ambient Mass Spectrometry Techniques", "abstract": "Ambient Ionisation Mass Spectrometry techniques: Desorption Electrospray Ionisation (DESI) and Laser Desorption Rapid Evaporative Ionisation Mass Spectrometry (LD-REIMS) were used to detect the SARS-CoV-2 in dry nasal swabs. 45 patients were studied from samples collected between April & June 2020 in a clinical feasibility study. Diagnostic accuracy was calculated as 86.7% and 84% for DESI and LD-REIMS respectively. Results can be acquired in seconds providing robust and quick analysis of COVID-19 status which could be carried out without the need for a centralised laboratory. This technology has the potential to provide an alternative to population testing and enable the track and trace objectives set by governments and curtail the effects of a second surge in COVID-19 positive cases. In contrast to current PCR testing, using this technique there is no requirement of specific reagents which can cause devastating delays upon breakdowns of supply chains, thus providing a promising alternative testing method.", "filename": "2020.10.07.20207647v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207647 "}, {"title": "Using test positivity and reported case rates to estimate state-level COVID-19 prevalence in the United States", "abstract": "Accurate estimates of the prevalence of infection are essential for evaluating and informing public health responses to the ongoing COVID-19 pandemic in the United States (US), but reliable, timely prevalence data based on representative population sampling are unavailable, and reported case and test positivity rates may provide strongly biased estimates. A single parameter semi-empirical model was developed, calibrated, and validated with prevalence predictions from two independent data-driven mathematical epidemiological models, each of which was separately validated using available cumulative infection estimates from recent state-wide serological testing in 6 states. The analysis shows that individually, reported case rates and test positivity rates may provide substantially biased estimates of COVID-19 prevalence and transmission trends in the U.S. However, the COVID-19 prevalence for U.S. states from March-July, 2020 is well approximated, with a 7-day lag, by the geometric mean of reported case and test positivity rates averaged over the previous 14 days.  Predictions of this semi-empirical model are at least 10-fold more accurate than either test positivity or reported case rates alone, with accuracy that remains relatively constant across different US states and varying testing rates.  The use of this simple and readily-available surrogate metric for COVID-19 prevalence, that is more accurate than test positivity and reported case rates and does not rely on mathematical modeling, may provide more reliable information for decision makers to make effective state-level decisions as to public health responses to the ongoing COVID-19 pandemic in the US.", "filename": "2020.10.07.20208504v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208504 "}, {"title": "Safely Reopening K-12 Schools During the COVID-19 Pandemic", "abstract": "Early school closures were a consistent, nationwide response to the COVID-19 pandemic in mid-March due to the role that children play in spreading influenza. This left us with limited understanding of COVID-19 transmission in children until several states reopened schools for the 2020-2021 school year. While early school closures were likely beneficial in protecting children in the initial stages of the pandemic in the U.S., long-term closures pose significant cumulative effects in children who rely on schools for instruction and additional social services, and for parents who need to balance work and childcare obligations. Reopening schools safely is a high priority for many interested stakeholders. \n\nProposed in-person school reopening plans include traditional, 100% school capacity, five days per week instruction, hybrid scenarios with reduced in-person instruction and virtual learning, and various reduced school capacity schedules with non-pharmaceutical interventions in place. To assess the potential impacts of different reopening plans, we created a modified SIR-type transmission model that captures multiple known pathways of COVID-19 transmission in a 100,000-person community. \n\nOur results show that plans that utilize consecutive days in school and divide students into separated smaller cohorts who attend school together, as well as plans that emphasize distance learning, are better able to suppress disease spread and reduce risk from an introduced infective into the community. Plans with more consecutive school days are protective for both the schoolchildren and surrounding community by acting to separate the larger intermixing population into smaller intermixing subpopulations.  The \"Five-Day Switch\" plan, which separates students into two cohorts, each of whom attend in-person learning for five consecutive days followed by five days of distance learning, best captures these protective attributes. All modeled plans assumed initially disease-free communities and that children's interactions with the community are greatly reduced during instructional days, both for in-person and distance learning.", "filename": "2020.10.07.20208710v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208710 "}, {"title": "Evaluating the impact of curfews and other measures on SARS-CoV-2 transmission in French Guiana", "abstract": "While general lockdowns have proven effective to control SARS-CoV-2 epidemics, they come with enormous costs for society. It is therefore essential to identify control strategies with lower social and economic impact. Here, we report and evaluate the control strategy implemented during a large SARS-CoV-2 epidemic in June-July 2020 in French Guiana that relied on curfews, targeted lockdowns and other measures. We find that the combination of these interventions reduced the basic reproduction number of SARS-CoV-2 from 1.7 to 1.1, which was sufficient to avoid saturation of hospitals. We estimate that thanks to the young demographics across the territory, the risk of hospitalisation following infection was 0.3 times that of metropolitan France and that about 20% of the population was infected by July. Our model projections are consistent with a recent seroprevalence study. The study showcases how mathematical modeling can be used to support healthcare planning and decision making in a context of high uncertainty.", "filename": "2020.10.07.20208314v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208314 "}, {"title": "Impact of pre-existing SARS-CoV-2 reactive T cells in uninfected individuals on COVID-19 mortality in different countries", "abstract": "Several recent studies identified SARS-CoV-2 reactive T cells in people without exposure to the virus. However, pathophysiological implications of these findings remain unknown. Here, the potential impact of pre-existing T cell reactivity against SARS-CoV-2 in uninfected individuals on markedly different COVID-19 mortality levels in different countries has been investigated. The inverse correlation is documented between the prevalence of pre-existing SARS-CoV-2 reactive T cells in people without exposure to the virus and COVID-19 mortality rates in different countries. In countries with similar levels of pre-existing SARS-CoV-2 cross-reactive T cells in uninfected individuals, differences in COVID-19 mortality appear linked with the extend and consistency of implementations of social measures designed to limit the transmission of SARS-CoV-2 (lockdown; physical distancing; mask wearing). Collectively, these observations support the model that the level of pre-existing SARS-CoV-2 reactive T cells is one of the important determinants of the innate herd immunity against COVID-19. Together with the consistent social measures directed to limit the virus spread, high levels of pre-existing SARS-CoV-2 reactive T cells appear significant determinants diminishing the COVID-19 mortality. Observations reported in this contribution should have significant impact on definitions of the herd immunity threshold required to effectively stop the pandemic in different countries across the globe.", "filename": "2020.10.03.20206151v2", "doi": "doi: https://doi.org/10.1101/2020.10.03.20206151 "}, {"title": "SARS-CoV-2 genomic characterization and clinical manifestation of the COVID-19 outbreak in Uruguay", "abstract": "COVID-19 is a respiratory illness caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and declared by the World Health Organization a global public health emergency. Among the severe outbreaks across South America, Uruguay has become known for curtailing SARS-CoV-2 exceptionally well. To understand the SARS-CoV-2 introductions, local transmissions, and associations with genomic and clinical parameters in Uruguay, we sequenced the viral genomes of 44 outpatients and inpatients in a private healthcare system in its capital, Montevideo, from March to May 2020. We performed a phylogeographic analysis using sequences from our cohort and other studies that indicate a minimum of 23 independent introductions into Uruguay, resulting in five major transmission clusters. Our data suggest that most introductions resulting in chains of transmission originate from other South American countries, with the earliest seeding of the virus in late February 2020, weeks before the borders were closed to all non-citizens and a partial lockdown implemented. Genetic analyses suggest a dominance of S and G clades (G, GH, GR) that make up >90% of the viral strains in our study. In our cohort, lethal outcome of SARS-CoV-2 infection significantly correlated with arterial hypertension, kidney failure, and ICU admission (FDR < 0.01), but not with any mutation in a structural or non-structural protein, such as the spike D614G mutation. Our study contributes genetic, phylodynamic, and clinical correlation data about the exceptionally well-curbed SARS-CoV-2 outbreak in Uruguay, which furthers the understanding of disease patterns and regional aspects of the pandemic in Latin America.", "filename": "2020.10.08.20208546v2", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208546 "}, {"title": "Investigation of the protection efficacy of face shields against aerosol cough droplets", "abstract": "Simple plastic face shields have numerous practical advantages over regular surgical masks. In light of the spreading COVID-19 pandemic, the potential of face shields as a substitution for surgical masks, as a recommendation to the general population, was investigated In order to determine the efficacy of the protective equipment we used a cough simulator that was carefully tuned to replicate human cough in terms of droplet size distribution and jet velocity. The protective equipment considered was placed on a manikin head that simulated human breathing. An Aerodynamic Particle Sizer (APS) was used to analyze the concentration and size distribution of small particles that reached the manikin respiration pathways. Additionally, water sensitive papers were taped on the tested protective equipment and the manikin face, and subsequently photographed and analyzed. In the case of frontal exposure, for droplet diameter larger than 3\u03bcm , the shield efficiency in blocking cough droplets was found to be comparable to that of regular surgical masks, with enhanced protection for portions of the face that the mask does not cover. Additionally, for finer particles, down to 0.3 micron diameter, a shield was found to perform even better, blocking about 10 times more fine particles than the surgical mask. When exposure from the side was considered, the performance of the shield was found to depend dramatically on its geometry. While a narrow shield allowed more droplets and aerosol to penetrate in comparison to a mask under the same configuration, a slightly wider shield significantly improved the performance. The  ability of a shield worn by an infected person in order  to protect others in his vicinity was also investigated. A shield, and alternatively, a surgical mask, were placed on the cough simulator, while the breathing simulator remained totally exposed. In both cases, no droplets or particles were found in the vicinity of the breathing simulator.", "filename": "2020.07.06.20147090v2", "doi": "doi: https://doi.org/10.1101/2020.07.06.20147090 "}, {"title": "Clearing the fog: Is Hydroxychloroquine effective in reducing Corona virus disease-2019 progression: A randomized controlled trial", "abstract": "Background: Hydroxychloroquine (HCQ) has been considered to treat Coronavirus disease 2019 (COVID-19) but data on efficacy is conflicting. we analyzed the efficacy of HCQ) in addition to standard of care (SOC) compared with SOC alone in reducing disease progression in Mild COVID-19\nMethods: A single centre open label randomized controlled trial during 10th April to 31st May 2020 was conducted at Pak emirates Military Hospital (PEMH) Five hundred patients of both genders having age between 18-80 years with Mild COVID-19 were enrolled. Patients assigned to standard dose of HCQ plus SOC were 349 while 151 patients received SOC (control group). Primary outcome was progression of disease while secondary outcome was PCR negativity on day 7 and 14. The results were analyzed on SPSS version 23. P value <0.05 was considered significant.  \nResults: Median age of intervention group (34 + 11.778 years) and control group (34 + 9.813 years). Disease progressed in 16 patients, 11 (3.15%) were in intervention group as compared to 5 (3.35%) in control group, (P value = 0.865). PCR negativity in intervention and control groups were (day 7, 182 (52.1%) vs. 54 (35.7%) (P value = 0.001), (day 14, 244 (69.9%) vs. 110 (72.8%) (P value = 0.508). Consecutive PCR negativity at day 7 and 14 was observed in 240 (68.8%) in intervention group compared to 108 (71.5%) in control group. (P value = 0.231).\nConclusion: Addition of HCQ to SOC in Mild COVID-19 neither stops disease progression nor help in early and sustained viral clearance.", "filename": "2020.07.30.20165365v2", "doi": "doi: https://doi.org/10.1101/2020.07.30.20165365 "}, {"title": "Modeling the dynamics of SARS-CoV-2 immunity waning, antigenic drifting, and population serology patterns", "abstract": "The authors have withdrawn this manuscript for the following reason. Upon following their strategy for making valid decisions, they found that making the escape from immunity steps in the model more biologically realistic, the model behavior changed so significantly that the first version of the model was no longer valid. Specifically, the old version misdirected drifting toward instead of away from immunity. The authors intend to upload a new version of their manuscript in the coming weeks. Therefore, the authors do not wish this work to be cited as reference for the project. If you have any questions, please contact the corresponding author.", "filename": "2020.09.10.20192153v2", "doi": "doi: https://doi.org/10.1101/2020.09.10.20192153 "}, {"title": "Clinical Characteristics and Outcomes of Diabetic COVID-19 patients in Kuwait", "abstract": "Background: Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) emerged in Wuhan, China, in 2019 and rapidly turned into a global pandemic, resulting in what is now known as Coronavirus Disease 2019 (COVID-19). COVID-19 has a highly variable clinical presentation, ranging from asymptomatic to severe respiratory symptoms and death. Diabetes seems to be one of the main comorbidities contributing to a worse COVID-19 outcome. Methods: In this single-center, retrospective study of 417 consecutive COVID-19 patients in Kuwait, we analyze and compare disease severity, outcome, associated complications, and clinical laboratory findings between diabetic and non-diabetic COVID-19 patients. Results: COVID-19 patients with diabetes had a higher prevalence of comorbidities, such as hypertension, higher levels of inflammatory markers, lower estimated glomerular filtration rate, and a higher incidence of complications. All of these factors could lead to more severe outcomes and higher mortality than non-diabetic COVID-19 patients. Conclusion: Diabetes could be a major contributor to COVID-19 worsening outcomes.", "filename": "2020.08.20.20178525v2", "doi": "doi: https://doi.org/10.1101/2020.08.20.20178525 "}, {"title": "The role of children in the spread of COVID-19: Using household data from Bnei Brak, Israel, to estimate the relative susceptibility and infectivity of children", "abstract": "One of the significant unanswered questions about COVID-19 epidemiology relates to the role of children in transmission. This study uses data on infections within households in order to  estimate the susceptibility and infectivity of children compared to those of adults.\nThe data were collected from households in the city of Bnei Brak, Israel, in which all household members were tested for COVID-19 using PCR (637 households, average household size of 5.3). In addition, serological tests were performed on a subset of the individuals in the study. \nInspection of the PCR data shows that children are less likely to be tested positive  compared to adults (25\\% of children positive over all households, 44\\% of adults positive over all households, excluding index cases), and the chance of being positive increases with age.\nAnalysis of joint PCR/serological data shows that there is under-detection of infections in the PCR testing, which is more substantial in children. However, the differences in detection rates are not sufficient to account for the differences in PCR positive rates in the two age groups.\nTo estimate relative transmission parameters, we employ a discrete stochastic model of the spread of infection within a household, allowing for susceptibility and infectivity parameters to differ among children and adults. The model is fitted to the household data using a simulated maximum likelihood approach.  To adjust parameter estimates for under-detection of infections in the PCR  results, we employ a multiple imputation procedure using estimates of under-detection in children and adults, based on the available serological data. \nWe estimate that the susceptibility of children (under 20 years old) is 43% (95% CI: [31%,55%]) of the susceptibility of adults. The infectivity of children was estimated to be 63% (95% CI: [37%,88%]) relative to that of adults.", "filename": "2020.06.03.20121145v2", "doi": "doi: https://doi.org/10.1101/2020.06.03.20121145 "}, {"title": "Health conditions and the risk of home injury in French adults: Results from a prospective study of the MAVIE cohort", "abstract": "Background Home injury (HI) is a significant cause of mortality and morbidity in adults of all ages. Health conditions significantly impact HI among old adults, but little is known for other adults.\nStudy design Prospective cohort study\nObjective: We assessed the associations between health-related factors and HI's risk in a French study, the MAVIE cohort.\nMethods Poisson mixed models were fitted using health-related data information (diseases, treatments, and disabilities) at baseline and the number of injuries prospectively recorded during the follow-up, adjusting for significant socio-demographics and exposure to a range of home activities. Attributable fractions (AFs) were estimated based on RR estimations measured in the fully adjusted models.\nResults A total of 6,146 dwelling adults aged 15 or more were followed up for 5.1 years on average. Vertigo or dizziness (RR=2.36, 95% CI 1.06 to 5.01) and sciatica or back pain (RR=1.49, 95% CI 1.08 to 2.05) were independently associated with an increased risk of HI.\nThese two groups of conditions showed the most significant associations among people aged 15 to 49, whereas musculoskeletal diseases other than rachialgias and arthropathies were the most significant health-related risk factor in people aged 50 and more. Sciatica or back pain represented the highest-burden of HIs in overall adults (8%) and among people aged 15 to 49\n(12%).\nConclusion Our results suggest that adults with musculoskeletal disorders and vertigo or dizziness symptoms have a higher risk of HI, regardless of age.", "filename": "2020.10.10.20210435v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210435 "}, {"title": "Epidemiology of sleep disorders during COVID-19 pandemic: A systematic scoping review", "abstract": "Background: A growing burden of mental health problems has become a global concern amid the coronavirus disease (COVID-19) pandemic.  Sleep disorders are major mental health problems associated with increased psychosocial stressors; however, no research synthesis is available on the epidemiology of it. In this systematic scoping review, we aimed to assess the current evidence on the epidemiological burden, associated factors, and interventions from the existing literature. \nMethod: Seven major health databases and additional sources were searched to identify, evaluate, and synthesize empirical studies on the prevalence and correlates of sleep disorders and available interventions. The Joanna Briggs Institute Methodology for Scoping Review were used, and the findings were reported using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) checklist. \nResults: A total of 78 articles were retrieved, the prevalence of sleeping disorders ranged from 2.3% to 76.6%. Age, sex, level of education, physical and mental health, COVID-19 related factors, occupation especially being health care workers (HCW) were the main associated factors. Only two intentions were identified to address the issue. \nConclusion: The finding of this review indicated a high burden of sleep disorder with limited interventions that necessitate informing policymakers and practitioners to facilitate future research and implementations.", "filename": "2020.10.08.20209148v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209148 "}, {"title": "Development of wastewater pooled surveillance of SARS-CoV-2 from congregate living settings", "abstract": "Wastewater-based monitoring for SARS-CoV-2 holds promise as tool to inform public health-decision making.  Testing at individual building-level could be an efficient, passive means of preventing early detection of new cases in congregate living settings, but this approach has not been validated. Sample collection protocols were developed and refined during preliminary sampling from a hospital and a local municipal wastewater treatment plant. Molecular diagnostic methods were compared side-by-side to assess feasibility, performance and sensitivity. Optimized sample collection and processing protocols were then used to monitor two occupied dormitory complexes (n=105 and 66) over eight weeks. Wastewater results were validated using known case counts from external clinical testing of building occupants. Results confirm that ultracentrifugation from a 24 hour composite collection had a sensitivity of 95% and a specificity of 100%.  However, if the detection of convalescent shedding is considered a false positive then the sensitivity would be 95.2% but the specificity would drop to 52%.  We determined a highly sensitive method for detecting SARS-CoV-2 shedding in building wastewater however our methods could not distinguish new infectious cases from persistent convalescent shedding of SARS-CoV-2 RNA. Future work must focus on methods to distinguish new infections from convalescent shedding to widely deploy this promising wastewater surveillance tool.", "filename": "2020.10.10.20210484v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210484 "}, {"title": "Radiomic and clinical predictors of cachexia in non-small cell lung cancer patients treated with immunotherapy", "abstract": "Background: Cachexia is present in up to 50% of patients with cancer and may contribute to primary resistance to immunotherapy. Biomarkers to predict cachexia are urgently required for early intervention. Herein, we test the hypothesis that pre-treatment 18F-FDG-PET/CT-based radiomics can be used to predict cachexia and subsequently associated with clinical outcomes among patients with advanced non-small cell lung cancer (NSCLC) who are treated with immunotherapy.\nMethods: This retrospective multi-institution study included 210 patients with histologically confirmed stage IIIB-IV NSCLC who were treated with immune checkpoint blockade between June 2011 and August 2019. Baseline (pre-immunotherapy) PET/CT images of 175 patients from Moffitt Cancer Center were used to train (N=123) and test (N=52) a radiomics signature to predict cachexia, which was also used to predict durable clinical benefit (DCB), progression-free survival (PFS) and overall survival (OS) subsequently. An external cohort that enrolled 35 patients from James A. Haley Veterans' Hospital (VA) was used to further validate the predictive and prognostic value of this signature. \nResults: A radiomics signature  demonstrated cachexia prediction ability with areas under receiver operating characteristics curves (AUC) of 0.77 (95%CI:0.68-0.85), 0.75 (95%CI:0.60-0.86) and of 0.73 (95%CI:0.53-0.92) in the training, test and external VA cohorts, respectively. For the further investigation of prognostic value, this signature could identify the patients with DCB with AUC of 0.67 (95%CI:0.57-0.77), 0.66 (95%CI:0.51-0.81), and 0.72 (95%CI:0.54-0.89) in these three cohorts.  Additionally, the PFS and OS were significantly shorter among patients with higher radiomics signature in all the three cohorts (p<0.05).\nConclusion: Using PET/CT radiomics analysis, cachexia could be predicted before the start of the immunotherapy, making it possible to monitor the patients with a higher risk of cachexia and identify patients most likely to benefit from immunotherapy.", "filename": "2020.10.08.20207415v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20207415 "}, {"title": "Quality assessment of studies included in Cochrane oral health systematic reviews", "abstract": "Objectives: The Risk of Bias (RoB) and other characteristics of randomized clinical trials included in Cochrane oral health systematic reviews were assessed.\nStudy Design and Settings: All the trials included in Cochrane oral health systematic reviews were examined. The RoB was evaluated for all the included clinical trials according to the Cochrane review standards. The Overall Risk of Bias (ORoB) was defined in this study based on the criteria for determining the overall bias in Cochrane's RoB tool-v2. Descriptive analyses were carried out to determine the frequency of each intended variable.\nResults: A total of 2565 studies were included in our analysis. The majority of the studies (n=1600) had sample sizes of 50 or higher. As for blinding, 907 studies were labelled as double-blind. Performance bias showed the highest rate of high risk (31.4%). Almost half of the studies had a high ORoB compared to 11.1% with low ORoB. The studies that used placebos had higher low ORoB (14.8% vs. 10.7%). The double-blind studies had the highest low ORoB (23.6%). The studies with a cross-over design had the highest low ORoB (28.8%).\nConclusion: Overall, the RoB for the studies on dentistry and oral health in Cochrane reviews was deemed high.", "filename": "2020.10.10.20210518v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210518 "}, {"title": "When lockdown policies amplify social inequalities in COVID-19 infections. Evidence from a cross-sectional population-based survey in France.", "abstract": "Objectives\nTo assess social inequalities in the trends in COVID-19 infections following lockdown \nDesign\nA cross-sectional survey conducted among the general population in France in April 2020, during COVID-19 lockdown. \nParticipants\n10 401 participants aged 18-64, from a national cohort who lived in the three metropolitan French regions most affected by the first wave of COVID-19. \nMain outcome \nThe main outcome was occurrence of possible COVID-19 symptoms, defined as the occurrence of sudden onset of cough, fever, dyspnea, ageusia and/or anosmia, that lasted more than three days in the 15 days before the survey. We used multinomial regression models to identify social and health factors related to possible COVID-19 before and during the lockdown.\nResults\nIn all, 1,304 (13.0%; 95% CI: 12.0%-14.0%) reported cases of possible COVID-19. The effect of lockdown on the occurrence of possible COVID-19 was different across social hierarchies. The most privileged class individuals saw a significant decline in possible COVID-19 infections between the period prior to lockdown and during the lockdown (from 8.8% to 4.3%, P=0.0001) while the decline was less pronounced among working class individuals (6.9% before lockdown and 5.5% during lockdown, P=0.03). This differential effect of lockdown remained significant after adjusting for other factors including history of chronic disease. The odds of being contaminated during lockdown as opposed to the prior period increased by 57% among working class individuals (OR=1.57; 95% CI: 1.0-2.48).  The same was true for those engaged in in-person professional activities during lockdown (OR=1.53; 95% CI: 1.03-2.29). \nInterpretation\nLockdown was associated with social inequalities in the decline in COVID-19 infections,  calling for the adoption of preventive policies to account for living and working conditions. Such adoptions are critical to reduce social inequalities related to COVID-19, as working-class individuals also have the highest COVID-19 related mortality, due to higher prevalence of comorbidities.", "filename": "2020.10.07.20208595v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208595 "}, {"title": "Age-targeted dose allocation can halve COVID-19 vaccine requirements", "abstract": "In anticipation of COVID-19 vaccine deployment, we use an age-structured mathematical model to investigate the benefits of optimizing age-specific dose allocation to suppress SARS-CoV-2 transmission. Across 179 countries, we find that the highest priority individuals are typically those between 30 and 59 years of age because of their high contact rates and higher risk of infection and disease. We reaffirm that vaccination alone may be insufficient to achieve herd immunity in some settings, and that additional intervention measures may be required. Nevertheless, we show that optimizing the allocation of vaccine doses can more than double their effectiveness.", "filename": "2020.10.08.20208108v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208108 "}, {"title": "A Large-Scale Observational Study on the Temporal Trends and Risk Factors of Opioid Overdose: Real-World Evidence for Better Opioids", "abstract": "Aims. To study 1) temporal trends and risk factors of opioid overdose and 2) properties underlying opioids with less overdose events.\nDesign. A retrospective cross-sectional study.\nSetting. Inpatient setting in Cerner Health Facts, a large-scale database for electronic health records in the United States.\nParticipants. Patients admitted between January 1, 2009 and December 31, 2017.\nMeasurements. Opioid overdose prevalence by year, demographics and prescription opioid exposures. \nFindings. A total of 4,720,041 patients with 7,339,480 inpatient encounters were retrieved from Cerner Health Facts. Among them, 30.2% patients were aged 65+, 57.0% female, 70.1% Caucasian, 42.3% single, 32.0% from South and 80.8% in urban area.  From 2009 to 2017, annual opioid overdose prevalence per 1,000 patients significantly increased from 3.7 to 11.9 with an adjusted odds ratio (aOR): 1.16, 95% confidence interval (CI): [1.15-1.16].  Comparing to the major demographic counterparts above, being in 1) age group: 41-50 or 51-64, 2) marital status: divorced, 3) census region: West, were significantly associated with higher odds of opioid overdose. Prescription opioid exposures were also associated with increased odds of opioid overdose, such as meperidine (overall aOR 1.09, 95% CI: [1.06-1.13]) and tramadol (overall aOR 2.20, 95% CI: [2.14-2.27]).  Examination on the relationships between opioid agonists properties and their association strengths, aORs, in opioid overdose showed that lower aORs values were significantly associated with 1) high molecular weight, 2) negative interaction with multi-drug resistance protein 1 or positive interaction with cytochrome P450 3A4 and 3) negative interaction with delta opioid receptor or kappa opioid receptor. \nConclusions. The significant increasing trends of opioid overdose from 2009 to 2017 and the risk factors indicated an ongoing need for targeted interventions to combat the opioid overdose epidemic. There are physicochemical, pharmacokinetic and pharmacodynamic properties underlying opioid agonists with less overdose events, which can be utilized to develop better opioids.", "filename": "2020.10.08.20208678v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208678 "}, {"title": "Exclusion of bacterial co-infection in COVID-19 using baseline inflammatory markers and their response to antibiotics", "abstract": "Background\nCOVID-19 is infrequently complicated by secondary bacterial infection, but nevertheless antibiotic prescriptions are common. We used community-acquired pneumonia (CAP) as a benchmark to define the processes that occur in a bacterial pulmonary infection, and tested the hypothesis that baseline inflammatory markers and their response to antibiotic therapy could distinguish CAP from COVID-19. \n\nMethods\nIn patients admitted to Royal Free Hospital (RFH) and Barnet Hospital (BH) we defined CAP by lobar consolidation on chest radiograph, and COVID-19 by SARS-CoV-2 detection by PCR. Data were derived from routine laboratory investigations.\n\nResults\nOn admission all CAP and >90% COVID-19 patients received antibiotics. We identified 106 CAP and 619 COVID-19 patients at RFH. CAP was characterised by elevated white cell count (WCC) and C-reactive protein (CRP) compared to COVID-19 (median WCC 12.48 (IQR 8.2-15.3) vs 6.78 (IQR 5.2-9.5) x106 cells/ml and median CRP CRP 133.5 (IQR 65-221) vs 86 (IQR 42-160) mg/L). Blood samples collected 48-72 hours into admission revealed decreasing CRP in CAP but not COVID-19 (CRP difference -33 (IQR -112 to +3.5) vs +15 (IQR -15 to +70) mg/L respectively). In the independent validation cohort (BH) consisting of 169 CAP and 181 COVID-19 patients, admission WCC >8.2x106 cells/ml or falling CRP during admission identified 95% of CAP cases, and predicted the absence of bacterial co-infection in 45% of COVID-19 patients.\n\nConclusions\nWe propose that in COVID-19 the absence of both elevated baseline WCC and antibiotic-related decrease in CRP can exclude bacterial co-infection and facilitate antibiotic stewardship efforts.", "filename": "2020.10.09.20199778v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20199778 "}, {"title": "Global projections of potential lives saved from COVID-19 through universal mask use", "abstract": "Background: Social distancing mandates have been effective at reducing the health impacts of COVID19. The ensuing economic downturns and unemployment increases have led many nations to progressively relax mandates. As COVID19 transmission and deaths rise in many low and middle-income countries (LMICs), with continuing widespread transmission elsewhere, policymakers are searching for options to reduce COVID19 mortality without reimposing strict social distancing mandates.\nMethods: Using a Bayesian meta-regression of 40 studies measuring the impact of mask use on respiratory viral infections, we estimated the reduction in transmission associated with the use of cloth or paper masks used in a general population setting. We used data from daily surveys conducted by Facebook, YouGov, and Premise, on the proportion of people reporting always wearing a mask outside their home for nearly all countries. We predicted deaths and infections until January 1st 2021 under a reference and universal mask use scenario using a deterministic transmission dynamics model with categories for susceptible, exposed, infected and recovered (SEIR). In the reference scenario, we assume continued easing of mandates but with action to re-impose mandates for a period of six weeks, at a level of eight daily deaths per million population. The universal mask scenario assumed scaling up of mask use to 95% over a one-week period.\nFindings: Use of simple masks can reduce transmission of COVID19 by 40% (95% uncertainty interval [UI] 20% to 54%). Universal mask use would lead to a reduction of 815,600 deaths (95% UI 430,600 to 1,491,000 deaths) between August 26th 2020 and January 1st 2021, the difference between the predicted 3.00 million deaths (95% UI 2.20 to 4.52 million) in the reference and 2.18 million deaths (95% UI 1.71 to 3.14 million) in the universal mask scenario over this time period. Mask use was estimated at 59.0% of people globally on August 18th, ranging from 41.9% in North Africa and the Middle East to 79.2% in Latin America and the Caribbean. The effect of universal mask use is greatest in countries such as India (158,832 fewer deaths in universal mask scenario, 95% UI 75,152 to 282,838 deaths), the United States of America (93,495 fewer deaths; 95% UI 59,329 to 150,967 deaths), and Russia (68,531 fewer deaths; 95% UI 34,249 to 145,960 deaths).\nInterpretation: The rising toll of the COVID19 pandemic can be substantially reduced by the universal adoption of masks. This low-cost policy, whether customary or mandated, has enormous health benefits and likely large economic benefits as well, by delaying the need for re-imposition of social distancing mandates.", "filename": "2020.10.08.20209510v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209510 "}, {"title": "Evaluating the Sensitivity of SARS-CoV-2 Infection Rates on College Campuses to Wastewater Surveillance", "abstract": "As college campuses reopen, we are in the midst of a large-scale experiment on the efficacy of various strategies to contain the SARS-CoV-2 virus. Traditional individual surveillance testing via nasal swabs and/or saliva is among the measures that colleges are pursuing to reduce the spread of the virus on campus. Additionally, some colleges are testing wastewater on their campuses for signs of infection, which can provide an early warning signal for campuses to locate COVID-positive individuals. However, a representation of wastewater surveillance has not yet been incorporated into epidemiological models for college campuses, nor has the efficacy of wastewater screening been evaluated relative to traditional individual surveillance testing, within the structure of these models. Here, we implement a new model component for wastewater surveillance within an established epidemiological model for college campuses. We use a hypothetical residential university to evaluate the efficacy of wastewater surveillance to maintain low infection rates. We find that wastewater sampling with a 1-day lag to initiate individual screening tests, plus completing the subsequent tests within a 4-day period can keep overall infections within 5% of the infection rates seen with traditional individual surveillance testing. Our results also indicate that wastewater surveillance can be an effective way to dramatically reduce the number of false positive cases by identifying subpopulations for surveillance testing where infectious individuals are more likely to be found. Through a Monte Carlo risk analysis, we find that surveillance testing that relies solely on wastewater sampling can be fragile against scenarios with high viral reproductive numbers and high rates of infection of campus community members by outside sources. These results point to the practical importance of additional surveillance measures to limit the spread of the virus on campus and the necessity of a proactive response to the initial signs of outbreak.", "filename": "2020.10.09.20210245v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210245 "}, {"title": "Clinical characteristics and outcomes of adult patients admitted with COVID-19 in East London: a retrospective cohort analysis", "abstract": "Background: Descriptions of clinical characteristics of patients hospitalised with coronavirus disease 2019 (COVID-19), their clinical course and short-term in- and outpatient outcomes in deprived urban populations in the United Kingdom are still relatively sparse. We describe the epidemiology, clinical course, experience of non-invasive ventilation and intensive care, mortality and short-term sequalae of patients admitted to two large District General Hospitals across a large East London NHS Trust during the first wave of the pandemic.\n\nMethods: A retrospective analysis was carried out on a cohort of 1,946 patients with a clinical or laboratory diagnosis of COVID-19, including descriptive statistics and survival analysis. A more detailed analysis was undertaken of a subset of patients admitted across three Respiratory Units in the trust.\n\nResults: Increasing age, male sex and Asian ethnicity were associated with worse outcomes. Increasing severity of chest X-ray abnormalities trended with mortality. Radiological changes persisted in over 50% of cases at early follow up (6 weeks). Ongoing symptoms including hair loss, memory impairment, breathlessness, cough and fatigue were reported in 67% of survivors, with 42% of patients unable to return to work due to ongoing symptoms.\n\nConclusions:  Understanding the acute clinical features, course of illness and outcomes of COVID-19 will be vital in preparing for further peaks of the pandemic. Our initial follow up data suggest there are ongoing sequalae of COVID-19 including persistent symptoms and radiological abnormalities. Further data, including longer term follow up data, are necessary to improve our understanding of this novel pathogen and associated disease.", "filename": "2020.10.08.20193623v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20193623 "}, {"title": "Factors associated with progression to critical illness in 28 days among COVID-19 patients: results from a tertiary care hospital in Istanbul, Turkey", "abstract": "Background\nCoronavirus disease 2019 (COVID-19) quickly spread worldwide to become a pandemic. This study aimed to define the predictors of critical illness development within 28 days postadmission.\n\nMethods\nWe conducted a prospective cohort study including 477 PCR-positive COVID-19 patients admitted to a tertiary care hospital in Istanbul from March 12 to May 12, 2020. The development of critical illness, e.g., invasive mechanical ventilation and/or death, was followed for a period of 28 days postadmission. Demographic characteristics, number of comorbidities, illness severity at admission defined by the WHO scale, vital signs, laboratory findings and period of admission to the hospital were independent variables. Cox proportional hazards analysis was performed, and the C-index was calculated.\n\nResults\nThe median (IQR) age of the cohort was 55.0 (44.0-67.0) years, and 50.1% were male. The most common presenting symptoms were cough, dyspnea and fatigue. Overall, 65.2% of the patients had at least one comorbidity. Hydroxychloroquine was given to 99.2% of the patients. Critical illness developed in 45 (9.4%; 95% CI: 7.0%-12.4%) patients. In the multivariable analysis, age (HR: 1.05, p<0.001), number of comorbidities (HR: 1.33, p=0.02), procalcitonin \u22650.25 \u03bcg/L (HR: 2.12, p=0.03) and LDH \u2265350 U/L (HR: 2.04, p=0.03) were independently associated with critical illness development. The WHO scale on admission was the strongest predictor of critical illness (HR: 4.15, p<0.001). Prognosis improved within the study period (p<0.05). The C-index of the model was 0.92.\n\nConclusions\nAge, comorbidity number, WHO scale, LDH and procalcitonin were independently associated with critical illness development. Mortality from COVID-19 seems to be decreasing as the pandemic advances.", "filename": "2020.10.09.20209775v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209775 "}, {"title": "Low zinc levels at clinical admission associates with poor outcomes in COVID-19", "abstract": "Background: Biomarkers to predict Coronavirus disease-19 (COVID-19) outcome early at infection are urgently needed to improve prognosis and treatment.  Zinc balances immune responses and also has a proven direct antiviral action against some viruses. Importantly, zinc deficiency (ZD) is a common condition in elderly and individuals with chronic diseases, two groups with more severe COVID-19 outcomes. We hypothesize that serum zinc content (SZC) influences COVID-19 disease progression and thus might represent a useful biomarker.\nMethods: We run a retrospective observational study with 249 COVID-19 patients admitted in Hospital del Mar. We have studied COVID-19 severity and progression attending to SZC at admission. In parallel we have studied SARS-CoV2 replication in the Vero E6 cell line modifying zinc concentrations.\nFindings: Our study demonstrates a correlation between serum zinc levels and COVID-19 outcome. Serum zinc levels lower than 50 mcgg/dl at admission correlated with worse clinical presentation, longer time to reach stability and higher mortality. Our in vitro results indicate that low zinc levels favor viral expansion in SARS-CoV2 infected cells.\nInterpretation: SZC is a novel biomarker to predict COVID-19 outcome. We encourage performing randomized clinical trials to study zinc supplementation as potential prophylaxis and treatment with people at risk of zinc deficiency.", "filename": "2020.10.07.20208645v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208645 "}, {"title": "Enoxaparin is associated with lower rates of thrombosis, kidney injury, and mortality than Unfractionated Heparin in hospitalized COVID patients", "abstract": "Although anticoagulants such as unfractionated heparin and low molecular weight heparin (LMWH, e.g. enoxaparin) are both being used for therapeutic mitigation of COVID associated coagulopathy (CAC), differences in their clinical outcomes remain to be investigated. Here, we employ automated neural networks supplemented with expert curation (Augmented Curation) for retrospectively analyzing the complete electronic health records (EHRs) of 671 hospitalized COVID-19 patients administered either enoxaparin or unfractionated heparin, but not both. We find that COVID-19 patients administered unfractionated heparin but not enoxaparin have higher rates of mortality (risk ratio: 2.6; 95% C.I.: [1.2-5.4]; p-value: 0.02; BH adjusted p-value: 0.09), thrombotic events (risk ratio: 5.7, 95%    C.I.: [2.1, 33.9], p-value: 0.024), acute kidney injury (risk ratio: 5.5; 95% C.I.: [1.2-17.7]; p-value: 0.02; BH adjusted p-value: 0.10), and bacterial pneumonia (risk ratio undefined; 95% C.I.: [1.0, 292]; p-value:0.02; BH adjusted p-value:0.10), compared to patients administered enoxaparin but not unfractionated heparin. Notably, even after controlling for potential confounding factors such as demographics, comorbidities, admission diagnosis, initial ICU status, and initial level of oxygen support, the above differences between the enoxaparin and unfractionated heparin patient cohorts remain statistically significant. This study emphasizes the need for mechanistically investigating differential modulation of the COVID-associated coagulation cascades by enoxaparin versus unfractionated heparin.", "filename": "2020.10.06.20208025v1", "doi": "doi: https://doi.org/10.1101/2020.10.06.20208025 "}, {"title": "Prediction of immunotherapy response using deep learning of PET/CT images", "abstract": "Currently only a fraction of patients with non-small cell lung cancer (NSCLC) experience durable clinical benefit (DCB) from immunotherapy, robust biomarkers to predict response prior to initiation of therapy are an emerging clinical need. PD-L1 expression status from immunohistochemistry is the only clinically approved biomarker, but a non-invasive complimentary approach that could be used when tissues are not available or when the IHC fails and can be assessed longitudinally would have important implications for clinical decision support. In this study, 18F-FDG-PET/CT images and clinical data were curated from 697 NSCLC patients from three institutions. Utilizing PET/CT images, a deeply-learned-score (DLS) was developed by training a small-residual-convolutional-network model to predict the PD-L1 expression status, which was further used to predict DCB, progression-free survival (PFS), and overall survival (OS) in both retrospective and prospective test cohorts of immunotherapy-treated patients with advanced stage NSCLC. This PD-L1 DLS significantly discriminated PD-L1 positive and negative patients (AUC\u22650.82 in all cohorts). Further, higher PD-L1 DLS was significantly associated with higher probability of DCB, longer PFS, and longer OS. The DLS combined with clinical characteristics achieved C-indices of 0.86, 0.83 and 0.81 for DCB prediction, 0.73, 0.72 and 0.70 for PFS prediction, and 0.78, 0.72 and 0.75 for OS prediction in the retrospective, prospective and external cohorts, respectively.  The DLS provides a non-invasive and promising approach to predict PD-L1 expression and to infer clinical outcomes for immunotherapy-treated NSCLC patients. Additionally, the multivariable models have the potential to guide individual pre-therapy decisions pending in larger prospective trials.", "filename": "2020.10.09.20209445v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209445 "}, {"title": "Computerized Cognitive Training in Cognitively Healthy Older Adults: A Systematic Review and Network Meta-Analysis", "abstract": "Background \nComputerized cognitive training (CCT) is a broad category of drill-and-practice interventions aims to maintain cognitive performance in older adults. Despite a supportive evidence base for general efficacy, it is unclear what types of CCT are most likely to be beneficial and what intervention design factors are essential for clinical implementation. \nMethods \nWe searched MEDLINE, Embase, and PsycINFO to August 2019 for randomized controlled trials (RCTs) of any type of CCT in cognitively healthy older adults. Risk of bias within studies was assessed using the Cochrane Risk of Bias 2 tool. The primary outcome was change in overall cognitive performance between CCT and control groups. Secondary outcomes were individual cognitive domains. A series of meta-regressions were performed to estimates associations between key design factors and overall efficacy using robust variance estimation models. Network meta-analysis was used to compare the main approaches to CCT against passive or common active control conditions.     \nResults \nNinety RCTs encompassing 7219 participants across 117 comparisons were included. The overall cognitive effect size across all trials was small (g=0.18, 95% CI 0.14 to 0.23) with considerable heterogeneity (\u03c42=0.074, 95% prediction interval -0.36 to 0.73), robust to small-study effect or risk of bias. Effect sizes for individual cognitive domains were small, heterogeneous and statistically significant apart from fluid intelligence and visual processing. Meta-regressions revealed significantly larger effect sizes in trials using supervised training or up to three times per week. Multidomain training was the most efficacious CCT approach against any type of control, with greater benefits in a subset of supervised training studies.   \n\nConclusions  \nThe efficacy of CCT varies substantially across designs, independent of the type of control. Multidomain supervised CCT appears to be the most efficacious approach, and should be developed to accommodate for individual needs and remote delivery settings. Future research should focus on identifying the intervention components and regimens that could attenuate aging-related cognitive decline.", "filename": "2020.10.07.20208306v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208306 "}, {"title": "A Comparative COVID 19 Characterizations and Clinical Course Analysis between ICU and Non ICU Settings", "abstract": "Objective: With COVID-19 pandemic severely affecting India and Ahmedabad city being one accounting for half COVID cases, objective was to determine disease course and severity of in patients at a COVID care hospital.\nDesign: A Clinical trial registry of India registered observational study (CTRI/2020/05/025247).\nSetting:  Certified COVID hospital located in Ahmedabad, Gujarat, India.\nParticipants: 549 COVID positive patients hospitalized between 15 th May to 10 th August, 2020 and treated in ICU and non ICU settings.\nMain Outcome Measure: Comparative analysis of demographic, clinical characteristics, investigations, treatment, complications and outcome of COVID patients in ICU and non ICU settings.\nResults: Of the 549 hospitalized COVID positive patients, 159 were admitted in ICU during disease course while 390 had ward admissions. Overall median age was 52 (1-86) years. The ICU group was older (>65years), with associated comorbidities like hypertension and diabetes (p<0.001); higher proportion of males (79.25%); with dyspnea as a major clinical characteristic and consolidation in lungs as a major radiological finding as compared to ward patients. C - reactive protein, D-Dimer and Ferritin were higher in ICU patients. Overall 50% females depicted elevated Ferritin levels. Steriods(92.45%)and tocilizumab (69.18%) were more frequently used for ICU patients . Remdesivir was prescribed to both ICU and non ICU patients. Favirapir was also a line of treatment for 25% of ICU patients. Convalescent plasma therapy was given to 7 ICU patients. Complications like acute kidney injury (13.84%), shock (10.69 %), sepsis and encephalopathy were observed in ICU patients. Overall mortality rate was 5.47 % with higher mortality among males in comparison to females (p<0.0001).\nConclusion: About 29% of overall patients required ICU admission that was commonly elderly males. Chances of ICU admission were higher with baselines comorbidities (1.5 times) and dyspnea (3.4 times) respectively. A multi-specialty COVID care team and updated treatment protocols improves outcomes.", "filename": "2020.10.07.20208389v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208389 "}, {"title": "Development and Validation of a Highly Generalizable Deep Learning Pulmonary Embolism Detection Algorithm", "abstract": "Several algorithms have been developed for the detection of pulmonary embolism, though generalizability and bias remain potential weaknesses due to small sample size and sample homogeneity. We developed and validated a highly generalizable deep-learning algorithm, Emboleye, for the detection of PE by using a large and diverse dataset, which included 30,574 computed tomography (CT) exams sourced from over 2,000 hospital sites. On angiography exams, Emboleye demonstrates an AUROC of 0.79 with a specificity of 0.99 while maintaining a sensitivity of 0.37 and PPV of 0.77. On non-angiography  CT exams, Emboleye demonstrates an AUROC of 0.77 with a specificity of 0.99 while maintaining a sensitivity of 0.18 and PPV of 0.35.", "filename": "2020.10.09.20210112v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210112 "}, {"title": "SARS-CoV-2 infections in Italian schools: preliminary findings after one month of school opening during the second wave of the pandemic", "abstract": "Introduction\nThe impact of school opening on the SARS-CoV-2 pandemic is still unknown. This study aims to provide preliminary information about the number of SARS-CoV-2 cases among students attending Italian schools.\n\nMethods \nData are extracted and analysed from an open access, online dataset that monitor, on a daily basis, media news about SARS-CoV-2 infections of students attending Italian schools.\n\nResults\nAs of 5 October 2020, a total of 1350 cases of SARS-CoV-2 infections have been registered in the Italian territory schools (involving 1059 students, 145 teachers and 146 other school members), for a total of 1212 out of 65104 (1.8%) Italian schools involved. National schools reported only 1 case of SARS-CoV-2 infection in more than 90% of cases, and only in one high school a cluster of more than 10 cases have been described (P 0.015). The detection of one or more SARS-CoV-2 infections leaded to the closure of 192 (14.2%) entire schools, more frequently nursery/kindergartens (P <0.0005).\n\nDiscussion\nOur preliminary data support low transmission of SARS-CoV-2 within schools, at least among younger students. However, entire schools are frequently closed in the fear of larger outbreaks. Continuous monitoring of school settings, hopefully through daily updated open access datasets, are needed to better understand the impact of schools on the pandemic, and provide guidelines that better consider different risks within different age groups.", "filename": "2020.10.10.20210328v1", "doi": "doi: https://doi.org/10.1101/2020.10.10.20210328 "}, {"title": "Prevalence and Longevity of SARS-CoV-2 Antibodies in Healthcare Workers: A Single Center Study", "abstract": "Understanding SARS-CoV-2 antibody prevalence as a marker of prior infection in a spectrum of healthcare workers (HCWs) may guide risk stratification and enactment of better health policies and procedures. \n\nThe present study reported on cross-sectional study to determine the prevalence and longevity of SARS-CoV-2 antibodies in HCWs at a regional hospital system in Orange County, California, between May and August, 2020. \n\nData from HCWs (n=3,458) were included in the analysis. Data from first responders (n=226) were also analyzed for comparison. A blood sample was collected at study enrollment and 8-week follow-up. Information on job duties, location, COVID-19 symptoms, polymerase chain reaction test history, travel since January 2020, and household contacts with COVID-19 was collected. Comparisons to estimated community prevalence were also evaluated.\n\nObserved antibody prevalence was 0.93% and 2.58% at initial and 8-week follow-up, respectively, for HCWs, and 5.31% and 4.35% for first responders. For HCWs, significant differences (p < .05) between negative vs. positive at initial assessment were found for age, race, fever, and loss of smell, and at 8-week follow-up for age, race, and all symptoms. Antibody positivity persisted at least 8 weeks in this cohort. Among 75 HCWs with self-reported prior PCR-confirmed COVID-19, 35 (46.7%) were antibody negative. Significant differences between negative vs. positive were observed in age and frequency of symptoms.\n\nThis study found considerably lower SARS-CoV-2 antibody prevalence among HCWs compared with prior published studies. This may be explained by better safety measures in the workplace, heightened awareness inside and outside of the workplace, possibly lower susceptibility due to innate immunity and other biological heterogeneity, and low COVID-19 prevalence in the community itself. HCWs with initial positive results had persistent positive serologies at 8 weeks.  Further research is warranted to investigate factors influencing such lower prevalence in our HCWs.", "filename": "2020.10.09.20210229v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20210229 "}, {"title": "Long-term COVID-19 symptoms in a large unselected population", "abstract": "It is increasingly recognized that SARS-CoV-2 can produce long-term complications after recovery from the acute effects of infection. Here, we report the analysis of 32 self-reported short and long-term symptoms in a general adult population cohort comprised of 233 COVID-19+ cases, 3,652 SARS-CoV-2-negative controls, and 17,474 non-tested individuals. The majority of our COVID-19+ cases are mild, with only 8 of the 233 COVID-19+ cases having been hospitalized. Our results show that 43.4% of COVID-19+ cases have symptoms lasting longer than 30 days, and 24.1% still have at least one symptom after 90 days. These numbers are higher for COVID-19+ cases who were initially more ill, 59.4% at 30 days and 40.6% at 90 days, but even for very mild and initially asymptomatic cases, 14.3% have complications persist for 30 days or longer. In contrast, only 8.6% of participants from the general untested population develop new symptoms lasting longer than 30 days due to any illness during the same study period. The long-term symptoms most enriched in those with COVID-19 are anosmia, ageusia, difficulty concentrating, dyspnea, memory loss, confusion, headache, heart palpitations, chest pain, pain with deep breaths, dizziness, and tachycardia. We additionally observe that individuals who had an initial symptom of dyspnea are significantly more likely to develop long-term symptoms. Importantly, our study finds that the overall level of illness is an important variable to account for when assessing the statistical significance of symptoms that are associated with COVID-19. Our study provides a baseline from which to understand the frequency of COVID-19 long-term symptoms at the population level and demonstrates that, although those most likely to develop long-term COVID-19 complications are those who initially have more severe illness, even those with mild or asymptomatic courses of infection are at increased risk of long-term complications.", "filename": "2020.10.07.20208702v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208702 "}, {"title": "Absence of SARS-CoV-2 neutralizing activity in pre-pandemic sera from individuals with recent seasonal coronavirus infection", "abstract": "Cross-reactive immune responses elicited by seasonal coronaviruses might impact SARS-CoV-2 susceptibility and disease outcomes. We measured neutralizing activity against SARS-CoV-2 in pre-pandemic sera from patients with prior PCR-confirmed seasonal coronavirus infection. While neutralizing activity against seasonal coronaviruses was detected in nearly all sera, cross-reactive neutralizing activity against SARS-CoV-2 was undetectable.", "filename": "2020.10.08.20209650v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209650 "}, {"title": "District level correlates of COVID-19 pandemic in India", "abstract": "Abstract\nBackground \nThe number of patients with coronavirus infection (COVID-19) has amplified in India. Understanding the district level correlates of the COVID-19 infection ratio (IR) is essential for formulating policies and intervention.\nObjectives\nThe present study examines the association between socioeconomic and demographic characteristics of India's population and the COVID-19 infection ratio at the district level.\nData and Methods\nUsing crowdsourced data on the COVID-19 prevalence rate, we analyzed state and district level variation in India from March 14 to July 31, 2020. We identified hotspot and cold spot districts for COVID-19 cases and infection ratio. We have also carried out a regression analysis to highlight the district level demographic, socioeconomic, infrastructure, and health-related correlates of the COVID-19 infection ratio. \nResults\nThe results showed that the IR is 42.38 per one hundred thousand population in India. The highest IR was observed in Andhra Pradesh (145.0), followed by Maharashtra (123.6), and was the lowest in Chhattisgarh (10.1). About 80 percent of infected cases and 90 percent of deaths were observed in nine Indian states (Tamil Nadu, Andhra Pradesh, Telangana, Karnataka, Maharashtra, Delhi, Uttar Pradesh, West Bengal, and Gujarat). Moreover, we observed COVID-19 cold-spots in central, northern, western, and north-eastern regions of India. Out of 736 districts, six metropolitan cities (Mumbai, Chennai, Thane, Pune, Bengaluru, and Hyderabad) emerged as the major hotspots in India, containing around 30 percent of confirmed total COVID-19 cases in the country. Simultaneously, parts of the Konkan coast in Maharashtra, part of Delhi, the southern part of Tamil Nadu, the northern part of Jammu & Kashmir were identified as hotspots of COVID-19 infection. Moran's- I value of 0.333showed a positive spatial clustering level in the COVID-19 IR case over neighboring districts. Our regression analysis found that district-level population density (\u03b2: 0.05, CI:004-0.06), the percent of urban population (\u03b2:3.08, CI: 1.05-5.11), percent of Scheduled Caste Population (\u03b2: 3.92, CI: 0.12-7.72),and district-level testing ratio (\u03b2: 0.03, CI: 0.01-0.04) are positively associated with the prevalence of COVID-19.\nConclusion\nCOVID-19 cases were heavily concentrated in 9 states of India. Several demographic, socioeconomic, and health-related variables are correlated with the COVID-19 prevalence rate. However, after adjusting the role of socioeconomic and health-related factors, the COVID-19 infection rate was found to be more rampant in districts with a higher population density, a higher percentage of the urban population, and a higher percentage of deprived castes and with a higher level of testing ratio. The identified hotspots and correlates in this study give crucial information for policy discourse. \nKeywords\nCOVID-19, socioeconomic, co-morbidity, geographical, hot-cold spot, districts, India.", "filename": "2020.10.08.20208447v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20208447 "}, {"title": "Lockdown impact on age-specific contact patterns and behaviours in France", "abstract": "In the first trimester 2020, a significant number of countries implemented general lockdowns of their populations to contain the quickly expanding SARS-CoV-2 epidemic and avoid major saturation of health care capacity. Understanding how these unprecedented measures impacted population behaviour and contact patterns is key to predict more accurately the health, social and economic impacts of such extreme actions if they were to be applied to future outbreaks. We set up an online survey to measure how the lockdown affected social contact patterns in France, and collected information from 42,036 participants aged 18 years and over between April 10 and April 28, 2020. Among the participants who normally worked outside home prior to the lockdown (72% of the survey population), 68% reported that they had moved to working from home and 17% reported being unemployed during the lockdown. Only 2% of participants used public transport during lockdown, as opposed to 37% before it. Participants reported increased frequency of washing hands, switch in greeting behaviour, but generally limited use of masks outside home. 138,934 contacts were reported, with an average 3.3 contacts per individual per day (1.7 for individuals aged >65 years old compared to 3.6 for younger age-groups). This represented a 70% reduction compared with previous surveys, consistent with reductions in transmission rates measured during the lockdown. Contacts in workplaces, shops, and transports on the previous day were respectively reported in only 11%, 31% and 0.5% of the participants. For those who maintained a professional activity outside home, the frequency of contacts at work dropped by 79%. This study shows that the lockdown dramatically affected population's behavior, work, risk perception and contact patterns. Both frequency and heterogeneity of contacts were affected, impacting potential important features of virus dissemination. Such surveys are essential to evaluate more accurately the impact of past or future lockdowns and anticipate epidemic dynamics in these conditions.", "filename": "2020.10.07.20205104v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20205104 "}, {"title": "Predicting multi-modal symptom trajectories across 7 years in veterans with chronic posttraumatic stress", "abstract": "Background: Veterans are disproportionately affected by symptoms of post-traumatic stress (PTS) and associated poor health and psychosocial functioning. While most improve over time, others experience severe and persistent concerns. The ability to predict this latter group is critical for early intervention. Characterizing this subgroup has proven difficult, with most studies focusing on PTS and neglect a wider assessment of veterans' wellbeing. Consequently, little is known about veterans who experience chronic symptoms and far-reaching impairment.\nMethod: The present study uses dimension reduction, growth mixture modeling, and clustering methods to identify veterans with the worst-faring trajectories of psychiatric symptoms, health, and psychosocial functioning, using data from the seven-year Mind Your Heart study (MYH) of people receiving Veterans Affairs services (n = 747). Random forest classification and feature selection were then used to examine predictors that distinguish the worst-fairing veteran group from others in the cohort. \nResults: The combined analyses revealed a subgroup of veterans with severe and diverse symptoms across psychiatric domains, impairment in multiple facets of living, and poor health with deterioration over seven years. This subgroup was distinguished by transdiagnostic symptom severity and greater social isolation, avoidance, anhedonia, cynicism, anger/hostility, and immune response and inflammation. \nConclusions:  Veterans whose distress spans multiple domains appear to be more broadly impaired, socially isolated, cynical or angry/hostile to others, and show elevated immunoreactivity and inflammation. Care for this population should be informed by a multidisciplinary approach that is conscious of veterans' mental and physical health, and interpersonal needs.", "filename": "2020.10.08.20185272v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20185272 "}, {"title": "DEVELOPING AND VALIDATING COVID-19 ADVERSE OUTCOME RISK PREDICTION MODELS FROM A BI-NATIONAL EUROPEAN COHORT OF 5594 PATIENTS.", "abstract": "Background: Patients with severe COVID-19 have overwhelmed healthcare systems worldwide. We hypothesized that Machine Learning (ML) models could be used to predict risks at different stages of management (at diagnosis, hospital admission and ICU admission) and thereby provide insights into drivers and prognostic markers of disease progression and death.\n\nMethods: From a cohort of approx. 2.6 million citizens in the two regions of Denmark, SARS-CoV-2 PCR tests were performed on subjects suspected for COVID-19 disease; 3944 cases had at least one positive test and were subjected to further analysis. A cohort of SARS-CoV-2 positive cases from the United Kingdom Biobank was used for external validation. \n\nFindings: The ML models predicted the risk of death (Receiver Operation Characteristics  Area Under the Curve, ROC-AUC) of 0.904 at diagnosis, 0.818, at hospital admission and 0.723 at Intensive Care Unit (ICU) admission. Similar metrics were achieved for predicted risks of hospital and ICU admission and use of mechanical ventilation. We identified some common risk factors, including age, body mass index (BMI) and hypertension as driving factors, although the top risk features shifted towards markers of shock and organ dysfunction in ICU patients.  The external validation indicated fair predictive performance for mortality prediction, but suboptimal performance for predicting ICU admission. \n\nInterpretation: ML may be used to identify drivers of progression to more severe disease and for prognostication patients in patients with COVID-19. Prognostic features included age, BMI and hypertension, although markers of shock and organ dysfunction became more important in more severe cases. \nWe provide access to an online risk calculator based on these findings.", "filename": "2020.10.06.20207209v1", "doi": "doi: https://doi.org/10.1101/2020.10.06.20207209 "}, {"title": "Transplacental Transfer of SARS-CoV-2 Antibodies", "abstract": "We measured SARS-CoV-2 antibody levels in serum samples from 1,471 mother/newborn dyads and found efficient transplacental transfer of SARS-CoV-2 IgG antibodies in 72 of 83 seropositive pregnant women. Transfer ratios >1.0 were observed among women with an asymptomatic SARS-CoV-2 infection as well as those with mild, moderate and severe COVID-19. Our findings demonstrate the potential for maternally-derived antibodies to provide neonatal protection from SARS-CoV-2 infection.", "filename": "2020.10.07.20207480v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207480 "}, {"title": "State of the evidence: a survey of global disparities in clinical trials", "abstract": "Introduction\nIdeally, health conditions causing the greatest global disease burden should attract increased research attention. We conducted a comprehensive global study investigating the number of randomised controlled trials (RCTs) published on different health conditions, and how this compares with the global disease burden that they impose.\n \nMethods\nWe use machine learning to monitor PubMed daily, and find and analyse RCT reports. We assessed RCTs investigating the leading causes of morbidity and mortality from the Global Burden of Disease study. Using regression models, we compared numbers of actual RCTs in different health conditions to numbers predicted from their global disease burden (Disability-Adjusted Life Years [DALYs]). We investigated whether RCT numbers differed for conditions disproportionately affecting countries with lower socio-economic development.\n \nResults\nWe estimate 463,000 articles describing RCTs (95% prediction interval 439,000-485,000) were published from 1990 to July 2020. RCTs recruited a median of 72 participants (interquartile range 32-195). 82% of RCTs were conducted by researchers in the top fifth of countries by socio-economic development. As DALYs increased for a particular health condition by 10%, the number of RCTs in the same year increased by 5% (3.2%-6.9%), but the association was weak (adjusted R2=0.13). Conditions disproportionately affecting countries with lower socio-economic development, including respiratory infections and tuberculosis (7 thousand RCTs below predicted) and enteric infections (10 thousand RCTs below predicted), appear relatively under-researched for their disease burden. Each 10% shift in DALYs towards countries with low and middle socio-economic development was associated with a 4% reduction in RCTs (3.7%-4.9%). These disparities have not changed substantially over time.\n \nConclusion\nResearch priorities are not well optimized to reduce the global burden of disease. Most RCTs are produced by highly developed countries, and the health needs of these countries have been, on average, favoured.", "filename": "2020.10.08.20209353v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20209353 "}, {"title": "Diagnostic Accuracy of FDA Authorized Serology Tests to Detect SARS-CoV-2 Antibodies: A Systematic Review and Meta-analysis", "abstract": "Importance: Serology tests are diagnostic and complementary to molecular tests during the COVID-19 pandemic.\n\nObjective: To evaluate the diagnostic accuracy of FDA authorized serology tests for the detection of SARS-CoV-2 infection.\n\nData sources: A search of MEDLINE, SCOPUS, CINAHL Plus, and EMBASE up to April 4, 2020, was performed to identify studies using the \"COVID 19 testing\" and \"meta-analysis.\" FDA website was accessed for the list of tests for emergency use authorization (EUA).\n\nStudy Selection: Manufacturer reported serology tests published in the FDA website were selected. Two reviewers independently assessed the eligibility of the selected reports.\n\nData extraction and synthesis: The meta-analysis was performed in accordance with the PRISMA guidelines. A bivariate analysis using the \"random-effects model\" was applied for pooled summary estimates of sensitivity, specificity, and the summary receiver operating characteristic curves. \n\nMain outcomes and measures: The primary outcome was the diagnostic accuracy of the serology test for detecting SARS-CoV-2 infection. Subgroup analysis of the diagnostic accuracy with lag time between symptom onset and testing were studied. \n\nResults: Seven manufacturer listed reports were included. The pooled sensitivity was 87% (95% CI, 78% - 93%), the pooled specificity was 100% (95% CI, 97% - 100%), and the area under the hierarchical summary receiver operating characteristic curve was 0.97. At \u2264 7 days, sensitivity was 44% (95% CI, 21% - 70%), and for 8-14 days, sensitivity was 84% (95% CI, 67 % - 94%). For blood draws \u2265 15 days after the onset of symptoms, sensitivity was 96% (95% CI, 93% - 98%). Heterogeneity was substantial, and the risk of bias was low in this analysis.\n\nConclusions and relevance: FDA authorized serology tests demonstrate high diagnostic accuracy for SARS-CoV-2 infection (certainty of evidence: moderate). There is a wide variation in the test accuracy based on the duration between the onset of symptoms and the tests (certainty of evidence: low)", "filename": "2020.10.07.20208553v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208553 "}, {"title": "Assessing the Impact of Area Deprivation Index on COVID-19 Prevalence: A Contrast Between Rural and Urban U.S. Jurisdictions", "abstract": "The COVID-19 pandemic has impacted communities differentially, with poorer and minority populations being more adversely affected. Prior rural health research suggests such disparities may be exacerbated during the pandemic and in remote parts of the U.S. To understand the spread and impact of COVID-19 across the U.S., county level data for confirmed cases of COVID-19 were examined by Area Deprivation Index (ADI) scores and Metropolitan vs. Nonmetropolitan designations from the National Center for Health Statistics (NCHS). These designations were the basis for making comparisons between Urban and Rural jurisdictions. Kendalls Tau-B was used to compare effect sizes between jurisdictions on select ADI composites and well researched social determinants of health (SDH). Spearman coefficients and a moderation analysis using Poisson modeling was used to explore the relationship between ADI and COVID-19 prevalence in the context of county designation. Results show that the relationship between area deprivation and COVID-19 prevalence was positive and higher for rural counties, when compared to urban ones and that family income and poverty had a stronger relationship with prevalence than other ADI component measures. Though most Americans live in Metropolitan Areas, rural communities were found to be associated with a stronger relationship between deprivation and COVID-19 prevalence. Models for predicting COVID-19 prevalence by ADI and county type reinforced this observation but revealed no moderating effect of county type on ADI.", "filename": "2020.10.07.20208462v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208462 "}, {"title": "Cost-effectiveness of public health strategies for COVID-19 epidemic control in South Africa: a microsimulation modelling study", "abstract": "Background\nHealthcare resource constraints in low and middle-income countries necessitate selection of cost-effective public health interventions to address COVID-19.\n\nMethods\nWe developed a dynamic COVID-19 microsimulation model to evaluate clinical and economic outcomes and cost-effectiveness of epidemic control strategies in KwaZulu-Natal, South Africa. Interventions assessed were Healthcare Testing (HT), where diagnostic testing is performed only for those presenting to healthcare centres; Contact Tracing (CT) in households of cases; Isolation Centres (IC), for cases not requiring hospitalisation; community health worker-led Mass Symptom Screening and molecular testing for symptomatic individuals (MS); and Quarantine Centres (QC), for household contacts who test negative. Given uncertainties about epidemic dynamics in South Africa, we evaluated two main epidemic scenarios over 360 days, with effective reproduction numbers (Re) of 1.5 and 1.2. We compared HT, HT+CT, HT+CT+IC, HT+CT+IC+MS, HT+CT+IC+QC, and HT+CT+IC+MS+QC, considering strategies with incremental cost-effectiveness ratio (ICER) <US$3,250/year-of-life saved (YLS) cost-effective. In sensitivity analyses, we varied Re, molecular testing sensitivity, and efficacies and costs of interventions.   \n\nFindings\nWith Re 1.5, HT resulted in the most COVID-19 deaths over 360 days. Compared with HT, HT+CT+IC+MS+QC reduced mortality by 94%, increased costs by 33%, and was cost-effective (ICER $340/YLS). In settings where quarantine centres cannot be implemented, HT+CT+IC+MS was cost-effective compared with HT (ICER $590/YLS). With Re 1.2, HT+CT+IC+QC was the least costly strategy, and no other strategy was cost-effective. HT+CT+IC+MS+QC was cost-effective in many sensitivity analyses; notable exceptions were when Re was 2.6 and when efficacies of ICs and QCs for transmission reduction were reduced. \n\nInterpretation\nIn South Africa, strategies involving household contact tracing, isolation, mass symptom screening, and quarantining household contacts who test negative would substantially reduce COVID-19 mortality and be cost-effective. The optimal combination of interventions depends on epidemic growth characteristics and practical implementation considerations.", "filename": "2020.06.29.20140111v2", "doi": "doi: https://doi.org/10.1101/2020.06.29.20140111 "}, {"title": "A large decrease in the magnitude of seasonal fluctuations in mortality explains part of the increase in longevity in Sweden during the 20th century", "abstract": "BACKGROUND:\nMortality rates are known to depend on the seasons and, in temperate climates, rates are highest during winter. The magnitude of these seasonal fluctuations in mortality has decreased substantially in many countries during the 20th century, but the extent to which this decrease has contributed to the concurrent increase in life expectancy is not known. Here, I describe how the seasonality of all-cause mortality among people ages 60 years or more has changed in Sweden between 1860 and 1995, and investigate how this change has contributed to the increase in life expectancy observed during the same time period. \n\nMETHODS:\nYearly sex-specific birth cohorts consisting of all people born in Sweden between 1800 and 1901 who reached at least 59 years of age were obtained from a genealogical database. The mortality rates for each cohort were modeled by an exponential function of age modulated by a sinusoidal function of time of year. The potential impact of seasonal fluctuations on life expectancy was investigated by a novel decomposition of the total mortality rate into a seasonal part and a part independent of the seasons. Cohort life expectancy at age 60 was used to quantify changes in lifespan during the time period.  \n   \nRESULTS:\nThe magnitude of seasonal fluctuations in mortality rates decreased substantially between 1860 and 1995. For cohorts born in 1800, the risk of dying during the winter season was almost twice that of dying during summer. For cohorts born in 1900, the relative increase in winter mortality was 10%. Cohort life expectancy at age 60 increased by 4.3 years for men and 6.8 years for women, and the decrease in seasonal mortality fluctuations accounted for approximately 40% of this increase in average lifespan.\n   \n   \nCONTRIBUTION:\nBy following a large number of extinct cohorts, it was possible to show how the decrease in seasonal fluctuations in mortality has contributed to an increase in life expectancy. The decomposition of total mortality introduced here might be useful to better understand the processes and mechanisms underlying the marked improvements in life expectancy seen over the last 150 years.", "filename": "2020.04.10.20060780v3", "doi": "doi: https://doi.org/10.1101/2020.04.10.20060780 "}, {"title": "High-throughput multivariable Mendelian randomization analysis prioritizes apolipoprotein B as key lipid risk factor for coronary artery disease", "abstract": "Background: Genetic variants can be used to prioritize risk factors as potential therapeutic targets via Mendelian randomization (MR). An agnostic statistical framework using Bayesian model averaging (MR-BMA) can disentangle the causal role of correlated risk factors with shared genetic predictors. Here, our objective is to identify lipoprotein measures as mediators between lipid-associated genetic variants and coronary artery disease (CAD) for the purpose of detecting therapeutic targets for CAD.\n\nMethods: As risk factors we consider 30 lipoprotein measures and metabolites derived from a high-throughput metabolomics study including 24,925 participants. We fit multivariable MR models of genetic associations with CAD estimated in 453,595 participants (including 113,937 cases) regressed on genetic associations with the risk factors. MR-BMA assigns to each combination of risk factors a model score quantifying how well the genetic associations with CAD are explained. Risk factors are ranked by their marginal score and selected using false discovery rate (FDR) criteria. We perform sensitivity and replication analyses varying the dataset for genetic associations with CAD.\n\nResults: In the main analysis, the top combination of risk factors ranked by the model score contains apolipoprotein B (ApoB) only. ApoB is also the highest ranked risk factor with respect to the marginal score (FDR< 0.005). Additionally, ApoB is selected in all replication analyses. No other measure of cholesterol or triglyceride is consistently selected otherwise. \n\nConclusions: Our agnostic genetic investigation prioritizes ApoB across all datasets con- sidered, suggesting that ApoB, representing the total number of hepatic-derived lipoprotein particles, is the primary lipid determinant of CAD.", "filename": "2020.02.10.20021691v2", "doi": "doi: https://doi.org/10.1101/2020.02.10.20021691 "}, {"title": "A prospective study of prognostic factors after Tubularized Incised (TIP) plate repair in distal and midshaft hypospadias in children", "abstract": "Background: Tubularized incised plate (TIP) urethroplasty as the most common hypospadias repair method, aims to achieve normal functioning of the penis along with cosmetic reconstruction. However, there are remaining questions toward anatomical prognostic factors affecting the results of surgery. Lack of age-matched controls or controlling for meatal location, employment of several surgical techniques or multiple surgeons, or age heterogeneity of the study population are the problems affected the results of the current body of literature.\nObjective: This prospective study aimed to evaluate the preoperative factors to predict future complications associated with hypospadias repair outcomes in males aged between 1-3 years and performed by a single surgeon with employing multivariate analysis.\nPatients and methods: A prospective cohort of 101 males aging from 1 to 3 years with distal to mid-shaft hypospadias were consecutively selected for TIP repair. The urethral plate dimensions in erect and flaccid states, penile length, glans diameter, and chordee were evaluated individually before reconstruction.  After surgery and during follow-up visits, the subsequent transient and persistent complications were recorded.\nResults: Postoperatively, the acute transient events were observed in 42 cases (41.6%) and the persistent complications in 16 cases (15.8%). The uncomplicated group had a higher percentage of patients with distal meatal location than the complicated group (P=0.01%). Furthermore, fistula formation was notably higher in the group with acute surgical site infection (P<0.001). The analysis also showed the width of the urethral plate to be inversely associated with the development of complications (P=0.03).\nConclusion: By performing TIP by a single surgeon on a homogenous study population and eliminating the impact of severe chordee as a potential cofounding variable, this study prospectively found that out of the anatomical specifications, pre- and postoperative factors, the urethral meatus location was the only significant and independent predictor of the development of complications in young children with midshaft to distal hypospadias. Finally based on the inverse association of width with the complications we hypostatized that a combination of urethral width and depth should be considered in the investigation of prognostic factors for hypospadias repair outcomes.", "filename": "2020.09.15.20193037v4", "doi": "doi: https://doi.org/10.1101/2020.09.15.20193037 "}, {"title": "Impact of pathogen reduction technologies on immunological properties of the COVID-19 convalescent plasma", "abstract": "Background and Objectives In the absence of a vaccine or specific antiviral drugs against SARS-CoV-2 COVID-19 convalescent plasma became one of the experimental treatment options in many countries. Aim of this study was to assess the impact of different pathogen reduction technologies on the immunological properties of COVID-19 convalescent plasma.\nMaterials and Methods In our experiment 140 doses of plasma collected by plasmapheresis from COVID-19 convalescent donors were subjected to pathogen reduction with one of three different methods: methylene blue (M), riboflavin (R), and amotosalen (A). To conduct a paired two-sample comparison each plasma dose was divided into 2 that were treated by one of these technologies. The titres of SARS-CoV2 neutralizing antibodies (NtAbs) and levels of specific immunoglobulins to RBD, S- and N- proteins of SARS-CoV-2 were measured before and after pathogen reduction.\nResults All methods reduced NtAbs titers significantly but not at the same grade: among units with the initial titre 80 or above, 81% of units had unchanged titres while 19% decreased by 1 step after methylene blue; 60% unchanged and 40% - decreased by 1 step after amotosalen; 43% unchanged, 67% a one-step decrease and 6% - a two-step decrease after riboflavin. Pairwise two-sample comparisons (M vs A, M vs R and A vs R) revealed the most prominent and statistically significant decrease in all studied parameters (except anti-RBD) following pathogen reduction with riboflavin.\nConclusion Pathogen reduction with amotosalen and methylene blue provides the greater likelihood of preserving the immunological properties of the COVID-19 convalescent plasma compared to riboflavin.", "filename": "2020.10.02.20205567v2", "doi": "doi: https://doi.org/10.1101/2020.10.02.20205567 "}, {"title": "Roles of meteorological conditions in COVID-19 transmission on a worldwide scale", "abstract": "The novel coronavirus (SARS-CoV-2/ 2019-nCoV) identified in December 2019 has caused great damage to public health and economy worldwide. Previous research has suggested an involvement of meteorological conditions in the spread of droplet-mediated viral diseases, such as influenza. However, as for the recent novel coronavirus, few studies have discussed systematically about the role of daily weather in the epidemic transmission of the virus. Here, we examine the relationships of meteorological variables with the severity of the outbreak on a worldwide scale. The confirmed case counts, which indicates the severity of COVID-19 spread, and four meteorological variables, i.e., air temperature, relative humidity, wind speed, and visibility, were collected daily between January 20 and March 11 (52 days) for 430 cities and districts all over China, 21 cities/ provinces in Italy, 21 cities/ provinces in Japan, and 51 other countries around the world. Four different time delays of weather (on the day, 3 days ago, 7 days ago, and 14 days ago) as to the epidemic situation were taken for modeling and we finally chose the weather two weeks ago to model against the daily epidemic situation as its correlated with the outbreak best. Taken Chinese cities as a discovery dataset, it was suggested that temperature, wind speed, and relative humidity combined together could best predict the epidemic situation. The meteorological model could well predict the outbreak around the world with a high correlation (r2>0.6) with the real data. Using this model, we further predicted the possible epidemic situation in the future 12 days in several high-latitude cities with potential outbreak. This model could provide more information for government's future decisions on COVID-19 outbreak control.", "filename": "2020.03.16.20037168v2", "doi": "doi: https://doi.org/10.1101/2020.03.16.20037168 "}, {"title": "An exact method for quantifying the reliability of end-of-epidemic declarations in real time", "abstract": "We derive and validate a novel and analytic method for estimating the probability that an epidemic has been eliminated (i.e. that no future local cases will emerge) in real time. When this probability crosses 0.95 an outbreak can be declared over with 95% confidence. Our method is easy to compute, only requires knowledge of the incidence curve and the serial interval distribution, and evaluates the statistical lifetime of the outbreak of interest. Using this approach, we rigorously show how the time-varying under-reporting of infected cases will artificially inflate the inferred probability of elimination, leading to premature (false- positive) end-of-epidemic declarations. Contrastingly, we prove that incorrectly identifying imported cases as local will deceptively decrease this probability, resulting in delayed (false-negative) declarations. Failing to sustain intensive surveillance during the later phases of an epidemic can therefore substantially mislead policymakers on when it is safe to remove travel bans or relax quarantine and social distancing advisories. World Health Organisation guidelines recommend fixed (though disease-specific) waiting times for end- of-epidemic declarations that cannot accommodate these variations. Consequently, there is an unequivocal need for more active and specialised metrics for reliably identifying the conclusion of an epidemic.", "filename": "2020.07.13.20152082v2", "doi": "doi: https://doi.org/10.1101/2020.07.13.20152082 "}, {"title": "Manual ability in hand surgery patients: validation of the ABILHAND scale in four diagnostic groups", "abstract": "Background: Patients treated in hand surgery (HS) belong to different demographic groups and have varying impairments related to different pathologies. HS outcomes are measured to assess treatment results, complication risks and intervention reliability. A one-dimensional and linear measure would allow for unbiased comparisons of manual ability between patients and different treatment effects.\n\nObjective: To adapt the ABILHAND questionnaire through Rasch analysis for specific use in HS patients and to examine its validity. \n\nMethods: A preliminary 90-item questionnaire was presented to 216 patients representing the diagnoses most frequently encountered in HS, including distal radius fracture (n=74), basal thumb arthritis (n=66), carpal tunnel syndrome (n=53), and heavy wrist surgery (n=23). Patients were assessed during the early recovery and in the late follow-up period (0-3 months, 3-6 months and >6 months), leading to a total of 305 assessments. They rated their perceived difficulty with queried activities as impossible, difficult, or easy. Responses were analyzed using the RUMM2030 software. Items were refined based on item-patient targeting, fit statistics, differential item functioning, local independence and item redundancy. Patients also completed the QuickDASH, 12-item Short Form Survey (SF-12) and a numerical pain scale. A preliminary 90-item questionnaire was presented to 216 patients representing the diagnoses most frequently encountered in HS, including distal radius fracture (n=74), basal thumb arthritis (n=66), carpal tunnel syndrome (n=53), and heavy wrist surgery (n=23). Patients were assessed during the early recovery and in the late follow-up period (0-3 months, 3-6 months and >6 months), leading to a total of 305 assessments. They rated their perceived difficulty with queried activities as impossible, difficult, or easy. Responses were analyzed using the RUMM2030 software. Items were refined based on item-patient targeting, fit statistics, differential item functioning, local independence and item redundancy. Patients also completed the QuickDASH, 12-item Short Form Survey (SF-12) and a numerical pain scale. \n\nResults: The rating scale Rasch model was used to select 23 mostly bimanual items on a 3-level scale, which constitute a unidimensional, linear measure of manual ability with good reliability across all included diagnostic groups (Person-Separation Index = 0.90). The resulting scale was found to be invariant across demographic and clinical subgroups and over time. ABILHAND-HS patient measures correlated significantly (p<0.001) with the QuickDASH (r=-0.77), SF-12 Physical Component Summary (r=0.56), SF-12 Mental Component Summary (r=0.31), and pain scale (r=-0.49).\n\nConclusion: ABILHAND-HS is a robust person-centered measure of manual ability in HS patients.", "filename": "2020.07.02.20144147v2", "doi": "doi: https://doi.org/10.1101/2020.07.02.20144147 "}, {"title": "Antibody reactivity to SARS-CoV-2 in adults from the Vancouver metropolitan area, Canada", "abstract": "Background: Quantifying antibody reactivity against multiple SARS-CoV-2 antigens at the population level may help understand individual differences in COVID-19 severity. Pre-existing low antibody cross-reactivity may be particularly prevalent among childcare providers, including pediatric health care workers (HCW) who may be more exposed to circulating coronaviruses.\n\nMethods: Cross-sectional study that included adults in the Vancouver area in British Columbia (BC), Canada, between May 17 and June 19, 2020. SARS-CoV-2 seroprevalence was ascertained by measuring total SARS-CoV-2 IgG/M/A antibodies against a recombinant spike (S1) protein, and adjusted for bias due to false-positive and false-negative test results. A novel, high sensitivity multiplex assay was also used to profile IgGs against four SARS-CoV-2 antigens, SARS-CoV and four circulating coronaviruses.\n\nFindings: Among 276 participants (71% HCW), three showed evidence of direct viral exposure, yielding an adjusted seroprevalence of 0.60% [95%CI 0% - 2.71%], with no difference between HCW and non-HCW, or between paediatric and adult HCW. Among the remaining 273 unexposed individuals, 7.3% [95%CI 4.5% - 11.1%], 48.7 [95%CI 42.7% - 54.8%] and 82.4% [95%CI 77.4% - 86.7%] showed antibody reactivity against SARS-CoV-2 RBD, N or Spike proteins, respectively. SARS-CoV-2 reactivity did not correlate with age, sex, did not differ between HCW and non-HCW (prevalence: 1.0% vs 1.0%; P=1.00) and between pediatric and adult HCW (prevalence: 0.7% vs 1.6%; P=0.54), and weakly correlated with reactivity to circulating coronaviruses (Spearman rho range: 0.130 to 0.224 for 7 significant out of 16 correlations; false-discovery rate-adjusted for a total of 36 correlations).\n\nInterpretation: A substantial proportion of individuals showed low, but detectable antibody reactivity against SARS-CoV-2 antigens in this population despite a low evidence of direct SARS-CoV-2 exposure.", "filename": "2020.10.05.20206664v4", "doi": "doi: https://doi.org/10.1101/2020.10.05.20206664 "}, {"title": "Treatment and prevention of early disease before and after exposure to COVID-19 using hydroxychloroquine: A protocol for exploratory re-analysis of age and time-nuanced effects: Update based on initial dataset review", "abstract": "BACKGROUND: Three companion randomized pragmatic trials were recently published assessing the effect of hydroxychloroquine (HCQ) on pre- exposure prophylaxis (PrEP - Rajasingham, NCT04328467), post- exposure prophylaxis (PEP - Boulware, NCT04308668) and treatment of early COVID-19 (Skipper, NCT04308668). Respectively, they found non-statistically significant reductions in development or persistence of COVID of 17%, 27% and 20% and concluded that HCQ did not reduce, prevent or substantially treat COVID-19 illness.\nWith a likely Type 2 error and over ambitious powering (50% effect), these effects may impact trajectory and resource models that drive decisions on lockdowns. All three studies have signals mostly found in the data appendices that suggest useful effects of HCQ in sub-groups worthy of re-analysis and prospective exploration. HCQ appeared to benefit younger rather than older patients in both the PrEP and PEP studies with respective reductions in COVID-19 of 45% and 36%. There was a strong benefit (40%) of HCQ in women (PrEP). Response to HCQ appeared to vary by type of exposure, with a large benefit (64%) in first responders (PrEP) and in household contacts (31%, PEP). Further confounding the data was the undefined, ex-protocol use of zinc and ascorbic acid.\nINTERIM FINDINGS: A major impediment in interpreting the PEP and treatment studies concerns the estimation of the time from exposure or symptom onset to treatment. Our initial analysis of the PEP study as published revealed a negative correlation between treatment lag and disease reduction, reaching 49% when HCQ was initiated within one day (RR 0.51, CI 0.176-1.46, p=0.249). However, our initial review (pursuant to this protocol, v1.1) of the publicly released PEP dataset revealed that, contrary to the study conclusion, this four-day period referred not to the time from exposure to treatment as we (and others) had understood, but to the time from exposure and enrollment, a difference of up to 3.5 days. Our re-stratification of new data we had requested revealed that HCQ may reduce the development of COVID-19 by as much as 65% (RR 0.35, CI 0.13-0.93, p=0.044) when received within 3 days of exposure (RR 0.83 at 3-5 days; RR 1.37 at 5-7 days). There remains ambiguity in these estimates addressable by further data we have requested.\nThis same issue appears shared by the Treatment study. Further, patients in the PEP study were likely exposed to a series, rather than a single, index exposure, an issue possibly shared with the PrEP study. In the treatment study, there may be a bimodal effect of responders and non-responders, in whom symptoms may actually worsen. All three studies share the confounding effect of a possibly active folate placebo.\nOBJECTIVES: To conduct a post hoc exploratory re-analyses of the de-identified raw datasets from randomized studies of the use of HCQ for pre- and post-exposure prophylaxis, and treatment of early of COVID-19 with view to further defining: (a) The time dependent effect of HCQ, on post exposure prophylaxis and treatment of COVID-19; (b) The age dependent effect of HCQ, on pre- and post- exposure prophylaxis and treatment of COVID-19; (c) The sub-stratification of gender, time- and age-dependent effects by exposure type and risk level, as well as by the use of zinc and ascorbic acid; (d) The design of prospective clinical trials designed to test the hypotheses generated by this study.\n\nThese analyses will be expanded should datasets from similarly designed Spanish studies involving PEP or treatment of (both NCT04304053) COVID-19, with directionally similar results, become available. \n\nThis protocol was devised using the Standard Protocol Items: Recommendations for Interventional Trials (SPIRIT) incorporating the WHO Trial Registration Data Set.\n\nStudy Status:\nProtocol version 1.2 (September 27 2020): registered at: OSF Registries September 27 2020\nhttps://osf.io/fqtnw\nhttps://doi.org/10.17605/OSF.IO/FQTNW\n\nSubmitted to medrxiv 9/30/20 as version1.2a, with revisions requested by medrxiv", "filename": "2020.08.19.20178376v2", "doi": "doi: https://doi.org/10.1101/2020.08.19.20178376 "}, {"title": "A method to estimate the incidence of transfusion reaction for the transfusion-treating disease in Chinese hospital", "abstract": "Though transfusion reaction is directly related to the transfusion component, while in clinic, the transfusion component is related to the disease which the patient caught. As some of the transfusion reactions could be life-threatening, estimating the incidence of transfusion reaction (in this study, allergic and febrile non-haemolytic transfusion reaction only) of some specific categories of diseases is helpful for the clinicians. According to the reported blood use in the specific departments, the number of transfusion patients in these departments could be estimated. By Apriori algorithm the categories of diseases which often encounter the transfusion reaction have been screened. It is found that the diseases which belong to C00-C97, D00-D48, D50-D89, K00-K93, N00-N99 and O00-O99 (ICD-10) often encounter transfusion reaction. The platelet transfusion patients whose diseases belong to C00-C97 would encounter transfusion reaction with the incidence about 1%, which is much higher than the average incidence. The incidence of transfusion reaction of the patients whose diseases belong to K00-K93, with plasma transfusion might be higher than the average incidence, as the lower bound of the incidence equals to the average incidence. Based on this study, it is suggested that attentions should be paid to the patients whose diseases belong to C00-C97 with platelet transfusion to prevent them encountering the allergic transfusion reaction.", "filename": "2020.02.25.20026096v2", "doi": "doi: https://doi.org/10.1101/2020.02.25.20026096 "}, {"title": "A high-throughput microfluidic nano-immunoassay for detecting anti-SARS-CoV-2 antibodies in serum or ultra-low volume dried blood samples", "abstract": "Novel technologies are needed to facilitate large-scale detection and quantification of SARS-CoV-2 specific antibodies in human blood samples. Such technologies are essential to support seroprevalence studies, vaccine clinical trials, and to monitor quality and duration of immunity. We developed a microfluidic nano-immunnoassay for the detection of anti-SARS-CoV-2 IgG antibodies in 1024 samples per device. The method achieved a specificity of 100% and a sensitivity of 98% based on the analysis of 289 human serum samples. To eliminate the need for venipuncture, we developed low-cost, ultra-low volume whole blood sampling methods based on two commercial devices and repurposed a blood glucose test strip. The glucose test strip permits the collection, shipment, and analysis of 0.6 \u03bcL whole blood easily obtainable from a simple fingerprick. The nano-immunoassay platform achieves high-throughput, high sensitivity and specificity, negligible reagent consumption, and a decentralized and simple approach to blood sample collection. We expect this technology to be immediately applicable to current and future SARS-CoV-2 related serological studies and to protein biomarker diagnostics in general.", "filename": "2020.10.07.20208280v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208280 "}, {"title": "Accurate SARS-CoV-2 seroprevalence surveys require robust multi-antigen assays", "abstract": "There is a plethora of severe acute respiratory syndrome-coronavirus-2 (SARS-CoV-2) serological tests based either on nucleocapsid phosphoprotein (N), S1-subunit of spike glycoprotein (S1) or receptor binding domain (RBD). Although these single-antigen based tests demonstrate high clinical performance, there is growing evidence regarding their limitations in epidemiological serosurveys. To address this, we developed a Luminex-based multiplex immunoassay that detects total antibodies (IgG/IgM/IgA) against the N, S1 and RBD antigens and used it to compare antibody responses in 1,225 blood donors across Greece. Seroprevalence based on single-antigen readouts was strongly influenced by both the antigen type and cut-off value and ranged widely [0.8% (95% CI, 0.4-1.5%)-7.5% (95% CI, 6.0-8.9%)]. A multi-antigen approach requiring partial agreement between RBD and N or S1 readouts (RBD&N|S1 rule) was less affected by cut-off selection, resulting in robust seroprevalence estimation [0.6% (95% CI, 0.3-1.1%)-1.2% (95% CI, 0.7-2.0%)] and accurate identification of seroconverted individuals.", "filename": "2020.09.09.20191122v2", "doi": "doi: https://doi.org/10.1101/2020.09.09.20191122 "}, {"title": "Cochlear implant-related speech processing may diminish the advantage of exposure to infant-directed speech", "abstract": "Caregivers modify their speech when talking to infants, a specific type of speech known as infant-directed speech (IDS). This speaking style facilitates language learning compared to adult-directed speech (ADS) in infants with normal hearing (NH). While infants with NH and those with cochlear implants (CIs) prefer listening to IDS over ADS, it is yet unknown how CI speech processing may affect the acoustic distinctiveness between ADS and IDS, as well as the degree of intelligibility of these. This study analyzed speech of seven female adult talkers to model the effects of simulated CI processing on (1) acoustic distinctiveness between ADS and IDS, (2) estimates of intelligibility of caregivers speech in ADS and IDS, and (3) individual differences in caregivers ADS-to-IDS modification and estimated speech intelligibility. Results suggest that CI processing is substantially detrimental to the acoustic distinctiveness between ADS and IDS, as well as to the intelligibility benefit derived from ADS-to-IDS modifications. Moreover, the observed variability across individual talkers in acoustic implementation of ADS-to-IDS modification and speech intelligibility was significantly reduced due to CI processing. The findings are discussed in the context of the link between IDS and language learning in infants with CIs.", "filename": "2020.06.29.20140319v2", "doi": "doi: https://doi.org/10.1101/2020.06.29.20140319 "}, {"title": "The SARS-CoV-2 effective reproduction rate has a high correlation with a contact index derived from large-scale individual location data using GPS-enabled mobile phones in Germany", "abstract": "The novel coronavirus (SARS-CoV-2), which was first discovered in Hubei, China in December 2019, has caused an ongoing pandemic. Due to pauci-symptomatic cases, the virus may spread invisibly in a community. In the absence of vaccination, non-pharmaceutical interventions (NPIs) like interpersonal distancing were implemented in several countries and have been key to effectively reduce viral spreading. In Germany after an exponential growth of case numbers in March 2020, NPIs were able to effectively control the pandemic and sufficiently reduced the daily reported new infections allowing for partial release of NPIs. We developed a novel statistical method to evaluate contacts between individuals, which is essential for virus transmission. We derived the contact index, an index for the intensity and heterogeneity of contact behavior from spatial proximity between individuals as proxy for physical interaction based on complex network science. We estimated the contact index from large-scale GPS mobile phone data of 1.15 to 1.4 million users in Germany per day (March to July 2020). A high correlation between the contact index and the effective reproduction number six days later could be observed (Pearson correlation r=0.96, P-value < 0.001 for all reported Pearson correlations). This correlation was observed in three different phases of the virus spread in Germany 1) the early phase of the first wave with the highest reproduction rate, 2) phase of strict NPIs (lockdown) with the lowest reproduction, 3) release of NPIs accompanied with an increase of reproduction. The results show that the contact index is able to model and potentially forecast the time evolution of the pandemic in Germany.", "filename": "2020.10.02.20188136v2", "doi": "doi: https://doi.org/10.1101/2020.10.02.20188136 "}, {"title": "COVID-19, Type-2 Diabetes, and Associated Health Outcomes in China: Results from a Nationwide Survey of 10,545 Adults", "abstract": "Objective: This study examined the associations between type-2 diabetes (T2DM) and self-reported/familial COVID-19 infection and investigated health-related outcomes among those with diabetes during China's nationwide quarantine.  \n\nResearch Design and Methods: The 2020 China COVID-19 Survey was administered anonymously via social media (WeChat) across China. It was completed by 10,545 adults in all of mainland China's 31 provinces. The survey consisted of 74 items covering sociodemographic characteristics, preventive measures for COVID-19, lifestyle behaviors, and health-related outcomes during the period of quarantine. Regression models examined associations among study variables, adjusting for covariates.\n\nResults: Diabetes was associated with a six-fold increased risk of reporting COVID-19 infection among respondents or their family members. Among patients with diabetes, individuals who rarely wore masks had double the risk of suspected COVID-19 infection compared with those who always wore masks, with an inverse J-shaped relationship between face mask wearing and suspected COVID-19 infection. People with T2DM tended to have both poor knowledge of COVID-19 and poor compliance with preventive measures, despite perceiving a high risk of personal infection (40.0% among respondents reporting T2DM and 8.0% without T2DM). Only 54-55% of these respondents claimed to consistently practice preventive measures, including wearing face masks. Almost 60% of those with T2DM experienced food or medication shortages during the quarantine period, which was much higher than those without T2DM (22.7 % and 25.8%, respectively). Importantly, respondents who experienced medication shortages reported a 63% higher COVID-19 infection rate. \n\nConclusions: T2DM was associated with an increased risk of self-reported personal and family member COVID-19 infection, which is mitigated by consistent use of face masks.", "filename": "2020.10.07.20207282v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207282 "}, {"title": "Role of high-dose exposure in transmission hot zones as a driver of SARS-CoV2 dynamics", "abstract": "Epidemiological data on the spread of SARS-CoV-2 in the absence and presence of various non-pharmaceutical interventions indicate that the virus is not transmitted uniformly in the population. Transmission tends to be more effective in select settings that involve exposure to relatively high viral dose, such as in crowded indoor settings, assisted living facilities, prisons, or food processing plants. To explore the effect on infection dynamics, we describe a new mathematical model where transmission can occur (i) in the community at large, characterized by low dose exposure and mostly mild disease, and (ii) in so called transmission hot zones, characterized by high dose exposure that can be associated with more severe disease. Interestingly, we find that successful infection spread can hinge upon high-dose hot zone transmission, yet the majority of infections are predicted to occur in the community at large with mild disease. This gives rise to the prediction that targeted interventions that specifically reduce virus transmission in the hot zones (but not in the community at large) have the potential to suppress overall infection spread, including in the community at large. The model can further reconcile seemingly contradicting epidemiological observations. While in some locations like California, strict stay-home orders failed to significantly reduce infection prevalence, in other locations, such as New York and several European countries, stay-home orders lead to a pronounced fall in infection levels, which remained suppressed for some months after re-opening of society. Differences in hot zone transmission levels during and after social distancing interventions can account for these diverging infection patterns. These modeling results warrant further epidemiological investigations into the role of high dose hot zone transmission for the maintenance of SARS-CoV-2 spread.", "filename": "2020.10.07.20208231v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208231 "}, {"title": "Hearing loss is associated with gray matter differences in older adults at risk for and with Alzheimer's disease", "abstract": "Hearing loss in healthy older adults is associated with accelerated brain volume loss; however, little is known about this association in those with or at risk for dementia. Using data from the COMPASS-ND study we investigated associations between hearing loss and hippocampal volume as well as cortical thickness in older adults with subjective cognitive decline (SCD, N=35), mild cognitive impairment (MCI, N=79), and Alzheimer's dementia (AD, N=21). SCD participants with greater pure-tone hearing loss exhibited lower hippocampal volume, a biomarker of dementia. They also showed more cortical thickness in the left superior temporal gyrus and right pars opercularis, suggesting compensatory cortical changes. No significant associations were found in those with cognitive impairment (MCI or AD) who had greater brain atrophy, suggesting that dementia-related neuropathology may supercede any effects of pure-tone hearing loss on brain volume loss. In contrast, greater speech-in-noise reception thresholds were associated with lower cortical thickness bilaterally across much of the cortex in AD. The AD group also showed worse speech-in-noise thresholds compared to the SCD group, suggesting that strong brain atrophy driven by dementia-related neuropathology in AD is associated with hearing problems in noisy environments.", "filename": "2020.10.07.20208017v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208017 "}, {"title": "EFFECT OF CONVALESCENT PLASMA ON MORTALITY IN PATIENTS WITH COVID-19 PNEUMONIA", "abstract": "Abstract\nBackground\nConvalescent plasma, widely utilized in viral infections that induce neutralizing antibodies, has been proposed for COVID-19, and preliminary evidence shows that it might have beneficial effect. Our objective was to compare epidemiological characteristics and outcomes between patients who received convalescent plasma for COVID-19 and those who did not, admitted to hospitals in Buenos Aires Province, Argentina, throughout the pandemic.\nMethods\nThis is a multicenter, retrospective cohort study of 2-month duration beginning on June 1, 2020, including unselected, consecutive adult patients with diagnosed COVID-19, admitted to 215 hospitals with pneumonia. Epidemiological and clinical variables were registered in the Provincial Hospital Bed Management System. Convalescent plasma was supplied as part of a centralized, expanded access program.\nResults\nWe analyzed 3,529 patients with pneumonia, predominantly male, aged 62\u00b117, with arterial hypertension and diabetes as main comorbidities; 51.4% were admitted to the ward, 27.1% to the Intensive Care Unit (ICU), and 21.7% to the ICU with mechanical ventilation requirement (ICU-MV). 28-day mortality was 34.9%; and was 26.3%, 30.1% and 61.4% for ward, ICU and ICU-MV patients. Convalescent plasma was administered to 868 patients (24.6%); their 28-day mortality was significantly lower (25.5% vs. 38.0%, p<0.001). No major adverse effects occurred.\nLogistic regression analysis identified age, ICU admission with and without MV requirement, diabetes and preexistent cardiovascular disease as independent predictors of 28-day mortality, whereas convalescent plasma administration acted as a protective factor.\nConclusions\nOur study suggests that the administration of convalescent plasma in COVID-19 pneumonia admitted to the hospital might be associated with decreased mortality.", "filename": "2020.10.08.20202606v1", "doi": "doi: https://doi.org/10.1101/2020.10.08.20202606 "}, {"title": "Modelling testing and response strategies for COVID-19 outbreaks in remote Australian Aboriginal communities", "abstract": "Background\nRemote Australian Aboriginal and Torres Strait Islander communities have potential to be severely impacted by COVID-19, with multiple factors predisposing to increased transmission and disease severity. Our modelling aims to inform optimal public health responses. \n\nMethods\nAn individual-based simulation model represented communities ranging from 100 to 3,500 people, comprised of large interconnected households. A range of strategies for case finding, quarantining of contacts, testing, and lockdown were examined, following the silent introduction of a case.\n\nResults\nMultiple secondary infections are likely present by the time the first case is identified. Quarantine of close contacts, defined by extended household membership, can reduce peak infection prevalence from 60-70% to around 10%, but subsequent waves may occur when community mixing resumes. Exit testing significantly reduces ongoing transmission. Concurrent lockdown of non-quarantined households for 14 days is highly effective for epidemic control and reduces overall testing requirements; peak prevalence of the initial outbreak can be constrained to less than 5%, and the final community attack rate to less than 10% in modelled scenarios. Lockdown also mitigates the effect of a delay in the initial response. Compliance with lockdown must be at least 80-90%, however, or epidemic control will be lost.\n\nConclusions\nA SARS-CoV-2 outbreak will spread rapidly in remote communities. Prompt case detection with quarantining of extended-household contacts and a 14-day lockdown for all other residents, combined with exit testing for all, is the most effective strategy for rapid containment. Compliance is crucial, underscoring the need for community supported, culturally sensitive responses.", "filename": "2020.10.07.20208819v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208819 "}, {"title": "Cost-effectiveness of Dengue Vaccination in Puerto Rico", "abstract": "An effective and widely used vaccine could reduce the burden of dengue virus (DENV) around the world. DENV is endemic in Puerto Rico, where the dengue vaccine CYD-TDV is currently under consideration as a control measure. CYD-TDV has demonstrated efficacy in clinical trials in vaccinees who had prior dengue infection. However, in vaccinees who had no prior dengue infection, the vaccine had a modestly elevated risk of hospitalization and severe disease. The WHO therefore recommended a strategy of pre-vaccination screening and vaccination of seropositive persons. To estimate the cost-effectiveness and benefits of this intervention (i.e., screening and vaccination of seropositive persons) in Puerto Rico, we simulated 10 years of the intervention in 9-year-olds using an agent-based model. Across the entire population, we found that 5.5% (4.6%-6.3%) of dengue hospitalizations could be averted. However, we also found that 1.6 (1.3 - 2.1) additional hospitalizations could occur for every 1,000 DENV-naive children who were vaccinated following a false-positive test results for prior exposure. The ratio of the averted hospitalizations among all vaccinees to additional hospitalizations among DENV-naive vaccinees was estimated to be 19 (13-24). At a base case cost of vaccination of 382 USD, we found an incremental cost-effectiveness ratio of 122,000 USD per QALY gained. Our estimates can provide information for considerations to introduce the CYD-TDV vaccine in Puerto Rico.", "filename": "2020.10.07.20208512v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208512 "}, {"title": "Report on COVID-19 Verification Case Study in Nine Countries Using the SIQR model", "abstract": "This report uses the SIQR model proposed by Takashi Odagaki to examine the epidemic trend of COVID-19 in nine major countries during February-May 2020, and to clarify the peculiar trend of infection in Japan. The SIQR model, which is an improvement on the conventional SIR model, is unique in that it allows us to theoretically clarify the epidemic phenomenon by separating the number of daily confirmed new cases by testing and the number of infecteds at large who remain untested, and also allows us to theoretically consider measures to control the epidemic. The infection control measures of each country were analyzed by dividing them into three groups according to the size of the decay (or growth) rate of infected at large (\u03bb). The active group includes China and South Korea, the passive group includes the United States and Sweden, and the average group includes Germany, Italy, France, Spain, and Japan. China and South Korea are the countries with the best testing and quarantine systems, and South Korea in particular having managed to contain the infection without lockdown through early quarantine by thorough testing. On the other hand, the United States and Sweden do not have a well-developed inspection and quarantine system and have shown little restraint in social distancing. In the case of Japan, the following special factors may have contributed to the extreme lack of PCR testing : (1) The \"4-day fever rule\" established by the Ministry of Health, Labour and Welfare was strictly enforced. (2) Even after the decision to postpone the Olympics, the government continued to monopolize PCR testing for the sake of unified analysis of infection data, and the policy of expanding PCR testing by private companies was not implemented.", "filename": "2020.10.07.20208298v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208298 "}, {"title": "Cardiovascular drugs and COVID-19 clinical outcomes: a living systematic review and meta-analysis", "abstract": "OBJECTIVE\nTo continually evaluate the rapidly evolving evidence base on the role of cardiovascular drugs in COVID-19 clinical outcomes (susceptibility to infection, hospitalization, hospitalization length, disease severity, and all-cause mortality). \nDESIGN\nLiving systematic review and meta-analysis.\nDATA SOURCES\nEligible publications identified from >500 databases indexed through 31st July 2020 and additional studies from reference lists, with planned continual surveillance for at least two years.\nSTUDY SELECTION\nObservational and interventional studies that report on the association between cardiovascular drugs and COVID-19 clinical outcomes.\nDATA EXTRACTION\nSingle-reviewer extraction and quality evaluation (using ROBINS-I), with half the records independently extracted and evaluated by a second reviewer.\nRESULTS\nOf 23,427 titles screened, 175 studies were included in the quantitative synthesis. The most reported drug classes were angiotensin-converting enzyme inhibitors (ACEIs) and angiotensin receptor blockers (ARBs) with ACEI/ARB exposure being associated with higher odds of testing positive for COVID-19 (pooled unadjusted OR 1.15, 95% CI 1.02 to 1.30). Among patients with COVID-19, unadjusted estimates showed that ACEI/ARB exposure was associated with being hospitalized (OR 2.25, 1.70 to 2.98) and having severe disease (OR 1.50, 1.27 to 1.77) but not with the length of hospitalization (mean difference -0.45, -1.33 to 0.43 days) or all-cause mortality (OR 1.25, CI 0.98 to 1.58).  However, after adjustment, ACEI/ARB exposure was not associated with testing positive for COVID-19 (pooled adjusted OR 1.01, 0.93 to 1.10), being hospitalized (OR 1.16, 0.80 to 1.68), having severe disease (1.04, 0.76 to 1.42), or all-cause mortality (0.86, 0.64 to 1.15). Similarly, subgroup analyses involving only hypertensive patients revealed that ACEI/ARB exposure was not associated with being hospitalized (OR 0.84, 0.58 to 1.22), disease severity (OR 0.88, 0.68 to 1.14) or all-cause mortality (OR 0.77, 0.54 to 1.12) while it decreased the length of hospitalization (mean difference -0.71, -1.11 to -0.30 days). After adjusting for relevant covariates, other cardiovascular drug classes were mostly not found to be associated with poor COVID-19 clinical outcomes. However, the validity of these findings is limited by a high level of heterogeneity in terms of effect sizes and a serious risk of bias, mainly due to confounding in the included studies.\nCONCLUSION\nOur comprehensive review shows that ACEI/ARB exposure is associated with COVID-19 outcomes such as susceptibility to infection, severity, and hospitalization in unadjusted analyses. However, after adjusting for potential confounding factors, this association is not evident.  Patients on cardiovascular drugs should continue taking their medications as currently recommended. Higher quality evidence in the form of randomized controlled trials will be needed to determine any adverse or beneficial effects of cardiovascular drugs.\nPRIMARY FUNDING SOURCE\nNone\nSYSTEMATIC REVIEW REGISTRATION\nPROSPERO (CRD42020191283)", "filename": "2020.10.07.20208918v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208918 "}, {"title": "How deep brain stimulation and levodopa affect gait variability in Parkinson disease", "abstract": "Background: Disorders of gait are a very common feature of Parkinsons Disease.  We examined how deep brain stimulation of the subthalamic nucleus (STN DBS) and dopaminergic medication affect gait and more specifically its rhythmicity. \nObjectives: We accurately quantified multiple gait parameters in Parkinsons patients during on and off stages of their treatment (levodopa or STN DBS) to compare and contrast the treatment-induced changes in gait.\n\nMethods: We studied 11 patients with STN DBS, 15 patients on levodopa and 42 healthy controls. They all completed the MDS-UPDRS part III along with a gait assessment protocol while wearing six nine-axis inertial measurement units (lumbar, sternal, and all four extremities).\n\nResults: Both medication and stimulation significantly improved stride length, while medication further significantly increased gait speed. In the lower limbs, both medication and stimulation had a normalising effect on lower limb angles, significantly increasing the foot strike angle and toe-off angle.\n\nConclusions: STN DBS reduced the step to step variability in a range of lower limb gait parameters in PD, while antiparkinsonian medication had no significant effect.  This suggests that STN stimulation, but not dopaminergic medication, has access to circuits that control gait rhythm, and that the resulting effect of stimulation on gait is beneficial.  However, the results we observed for movement of the trunk and upper limbs were strikingly different to those seen in the lower limbs.  We propose a hypothesis to explain why we observe these results, focusing on cholinergic pedunculopontine projections.", "filename": "2020.10.07.20207704v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207704 "}, {"title": "Reliability and limits of transport-ventilators to safely ventilate severe patients in special surge situations.", "abstract": "Background: Several Intensive Care Units (ICU) have been overwhelmed by the surge of COVID-19 patients thus necessitating to extend ventilation capacity outside the ICU where air and oxygen pressure are not always available. Transport ventilators requiring only O2 source may be used to deliver volume-controlled ventilation.\n\nObjective: To evaluate the performances of four transport ventilators compared to an ICU ventilator simulating severe respiratory conditions.\n\nMaterials and methods: Two pneumatic transport ventilators, (Oxylog 3000, Draeger; Osiris 3, Air Liquide Medical Systems) and two turbine transport ventilators (Elisee 350, ResMed; Monnal T60, Air Liquide Medical Systems) were compared to an ICU ventilator (Engstrom Carestation - GE Healthcare) using a Michigan training test lung. We tested each ventilator with different set volumes Vtset (350, 450, 550 ml) and different compliances (20 or 50 ml/cmH2O) and a resistance of 15 cmH20/L/sec based on values recently described in COVID-19 Acute Respiratory Distress Syndrome. Volume error was measured, as well as the trigger time delay during assist-control ventilation simulating spontaneous breathing activity with a P0.1 of 4 cmH20.\n\nResults: Grouping all conditions, the volume error was 2.9 +/- 2.2 % for Engstrom Carestation; 3.6 +/- 3.9 % for Osiris 3; 2.5 +/- 2.1 % for Oxylog 3000; 5.4 +/- 2.7 % for Monnal T60 and 8.8 +/- 4.8 % for Elisee 350. Grouping all conditions, trigger delay was 42 +/- 4 ms, 65 +/- 5 ms, 151 +/- 14 ms, 51 +/- 6 and 64 +/- 5 ms for Engstrom Carestation, Osiris 3, Oxylog 3000, Monnal T60 and Elisee 350, respectively.\n \nConclusions: In special surge situations such as COVID-19 pandemic, most transport ventilators may be used to safely deliver volume-controlled ventilation in locations where only oxygen pressure supply is available with acceptable volume accuracy. Performances regarding triggering function are generally acceptable but vary across ventilators.", "filename": "2020.10.07.20208561v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208561 "}, {"title": "Distinct serum anti-A\u03b2 antibody patterns in hemorrhagic and inflammatory cerebral amyloid angiopathy manifestations", "abstract": "Abstract\nObjective: To study blood anti-A\u03b2 antibodies in the context of spontaneous inflammatory or hemorrhagic CAA manifestations, which are similar to complications occurring after monoclonal anti-A\u03b2 antibody immunotherapies.\nMethods: In this case-control study, serum anti-A\u03b2 antibody isotype, concentration, avidity, and reactivity toward soluble or fibrillary A\u03b21-40 and A\u03b21-42 isoforms were assessed using an ELISA-based multiplex analysis. Anti-A\u03b2 serologic patterns were defined in CAA and CAA subgroups using multivariable logistic regression analyses. \nResults: Fourty-one healthy aged controls and 64 CAA patients were recruited: 46 with hemorrhagic features (CAA-he) and 18 with CAA-related inflammation (CAA-ri). As compared to controls, the most striking features of CAA-related serological profiles were the following: i) both CAA-he and CAA-ri patients displayed lower binding diversity of anti-soluble A\u03b21-40 IgM; ii) CAA-he patients displayed higher anti-soluble A\u03b21-40 / fibrillary A\u03b21-42 IgG4 concentrations ratio and higher anti-soluble A\u03b21-42 IgG4 and IgA avidity; iii) CAA-ri patients displayed higher binding diversity of anti-soluble A\u03b21-40 IgG3 and higher anti-fibrillary/soluble A\u03b21-42 IgG4 dilution curve steepness ratio.\nConclusion: This proof-of-concept study revealed anti-A\u03b2 antibody variations in CAA patients, some of which were associated to CAA clinical phenotypes, unveiling pathophysiological insights regarding CAA-hemorrhagic and inflammatory related events.", "filename": "2020.10.07.20208330v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208330 "}, {"title": "Two-tiered SARS-CoV-2 seroconversion screening in the Netherlands and stability of nucleocapsid, spike protein domain 1 and neutralizing antibodies", "abstract": "Serological testing in the COVID-19 pandemic is mainly implemented to gain sero-epidemiological data, but can also retrospectively inform about suspected SARS-CoV-2 infection. We verified and applied a two-tiered testing strategy combining a SARS-CoV-2 receptor-binding domain (RBD)-specific lateral flow assay (LFA) with a nucleocapsid protein (NCP) IgG ELISA to assess seroconversion in n=7241 individuals. The majority had experienced symptoms consistent with COVID-19, but had no access to RT-PCR testing. Longitudinal follow-up in n=97 LFA+ individuals was performed up to 20 weeks after initial infection using NCP and spike protein S1 domain (S1) IgG ELISAs and a surrogate virus neutralization test (sVNT). Individuals reporting symptoms from January 2020 onwards showed seroconversion, as did a considerable proportion of asymptomatic individuals. Seroconversion for symptomatic and asymptomatic individuals was higher in an area with a known infection cluster compared to a low incidence area. Overall, 94% of individuals with a positive IgG result by LFA were confirmed by NCP ELISA. The proportion of ELISA-confirmed LFA results declined over time, in line with contracting NCP IgG titers during longitudinal follow-up. Neutralizing antibody activity was considerably more stable than S1 and NCP IgG titers, and both reach a plateau after approximately 100 days. The sVNT proved to be not only highly specific, but also more sensitive than the specificity-focussed two-tiered serology approach. Our results demonstrate the high specificity of two-tiered serology testing and highlight the sVNT used as a valuable tool to support modelling of SARS-CoV-2 transmission dynamics, complement molecular testing and provide relevant information to individuals.", "filename": "2020.10.07.20187641v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20187641 "}, {"title": "Near Fibre Electromyography", "abstract": "Near fibre electromyography (NFEMG) is the use of specifically high-pass filtered motor unit potential (MUPs) (i.e. near fibre MUPs (NFMs)) extracted from needle-detected EMG signals for the examination of changes in motor unit (MU) morphology and electrophysiology caused by neuromuscular disorders or ageing. The concepts of NFEMG, the parameters used, including NFM duration and dispersion, which relates to fibre diameter variability and/or endplate scatter, and a new measure of neuromuscular junction transmission (NMJ) instability, NFM segment jitter, and the methods for obtaining their values are explained. Evaluations using simulated needle-detected EMG data and exemplary human data are presented, described and discussed. The data presented demonstrate the ability of using NFEMG parameters to detect changes in MU fibre diameter variability, end plate scatter, and neuromuscular transmission time variability. These changes can be detected prior to alterations of MU size, numbers or muscle recruitment patterns.", "filename": "2020.10.07.20208348v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208348 "}, {"title": "Pulmonary Embolism in Patients with COVID-19: A Systematic review and Meta-analysis", "abstract": "Background: \nThere is an increasing evidence that COVID-19 could be complicated by coagulopathy which may lead to death; especially in severe cases. Hence, this study aimed to build concrete evidence regarding the incidence and mortality of pulmonary embolism (PE) in patients with COVID-19.\nMethods: \nWe performed a systematic search for trusted databases/search engines including PubMed, Scopus, Cochrane library and web of science. After screening, the relevant data were extracted and the incidences and mortality rates from the different included studies were pooled for meta-analysis.\nResults: \nTwenty studies were finally included in our study consisting of 1896 patients.  The results of the meta-analysis for the all included studies showed that the incidence of PE in patients with COVID-19 was 17.6% with the 95% confidence interval (CI) of 12.7 to 22.5%. There was significant heterogeneity. Additionally, the results of meta-analysis including 8 studies showed that the mortality in patients with both PE and COVID-19 was 43.1% with the 95% confidence interval (CI) of 19 to 67.1%. There was significant heterogeneity. \nConclusion: \nPE was highly frequent in patients with COVID-19. The mortality in patients with both COVID-19 and PE was remarkable representing almost half of the patients. Appropriate prophylaxis and management are vital for better outcomes", "filename": "2020.10.09.20209965v1", "doi": "doi: https://doi.org/10.1101/2020.10.09.20209965 "}, {"title": "Optic nerve tortuosity and displacements during horizontal eye movements in healthy and highly myopic subjects", "abstract": "Purpose: (1) To assess the morphology and 3D displacements of the eye globe and optic nerve (ON) in adduction/abduction using magnetic resonance imaging (MRI). (2) To assess differences between healthy emmetropic and highly myopic (HM) subjects. \n\nMethods: MRI volumes of both eyes from 18 controls and 20 HM subjects in primary gaze, abduction and adduction (15\u00b0) were postprocessed. All ONs were manually-segmented and fitted to a 3D curve to assess ON tortuosity. ON displacements were evaluated in 4 quasicoronal planes which were perpendicular to the ON in primary gaze and 3 mm apart.\n\nResults: Axial length was higher in the HM group (28.62\u00b12.60 vs 22.84\u00b10.89 mm; p<0.0001). Adjusted ON tortuosities (i.e., ON tortuosities estimated before myopia onset) were lower in HM eyes (0.9063\u00b10.0591) versus controls (1.0152\u00b10.02981) in primary gaze, adduction (0.9023\u00b10.05538 versus 1.0137\u00b10.0299) and abduction (0.9100\u00b10.0594 versus 1.0182 \u00b1 0.0316); p<0.0001 for all cases. In all eyes, ON displacements in adduction were significantly different from those in abduction in the naso-temporal direction (p<0.0001 in all planes) but not in the supero-inferior direction. ON displacements in the posterior segments of the ON were smaller in the HM group in both gaze directions and were larger in the anterior-most ON segment in adduction only.\n\nConclusions: The adjusted tortuosity of the ON was significantly lower in HM eyes, suggesting that eyes destined toward HM exhibited higher ON traction forces during eye movements before the onset of myopia. Our ON metrics may be valuable to explore a potential link between eye movements and axial elongation.", "filename": "2020.10.07.20208397v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208397 "}, {"title": "Dry eye disease: A Canadian quality of life and productivity loss survey", "abstract": "Aim: To capture the direct and indirect cost estimates of dry eye disease (DED), stratified by disease severity, in patients from Canada and to understand the impact of DED on quality of life (QoL) in this group.\nMethods: A prospective, multi-centre, observational, cross-sectional study was conducted at six optometry and ophthalmology sites across Canada. Eligible patients completed a 20-minute survey on demography, general health, disease severity, QoL, and direct and indirect costs. \nResults: A total of 151 patients participated in the study and 146 were included in the analysis. Mean (standard deviation [SD]) age was 49.8 (11.4) years and most patients were female (89.7%). DED was considered moderate or severe by 19.2% and 69.2% of patients, respectively. Sj\u00f6gren's syndrome was reported by 8.2% of patients. Total mean annual costs of DED were $24,331 (Canadian dollars [CAD]) per patient and increased with disease severity. Mean (SD) indirect costs for mild, moderate, and severe disease were $5,961 ($6,275), $16,525 ($11,607), and $25,485 ($22,879), respectively. Mean (SD) direct costs were $958 ($1,216), $1,303 ($1,574), and $2,766 ($7,161), respectively. QoL scores were lowest in patients with Sj\u00f6gren's syndrome and those with severe DED.\nConclusions: This study provides important insights into the negative impact of DED in a Canadian setting. Patients with severe DED reported higher direct and indirect costs and lower QoL compared with those with mild or moderate disease. Increased costs and poorer QoL were also evident for patients with DED plus Sj\u00f6gren's syndrome versus DED alone.", "filename": "2020.10.07.20207225v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207225 "}, {"title": "Implementation of an ERAS program in patients undergoing thoracic surgery at a third-level university hospital. An ambispective cohort study.", "abstract": "Objetive:  To analyze the effects of the implementation of an ERAS program in patients undergoing pulmonary resection in a tertiary university hospital on the rates of complications and readmission and the length of stay.\nMethods: ambispective cohort study, with a prospective arm of patients undergoing thoracic surgery within an ERAS program versus a retrospective arm of patients before the implementation of the protocol. We recluited 50 patients per arm. The primary outcome was the number of patients with 30-day surgical complications. Secondary outcome included ERAS adherence, no-surgical complications, mortality, readmission, reintervention rates, pain and hospital lenght of stay.  We performed a multivariate logistic analysis to study the association of coutcomes with ERAS adherence.\nResults: We found no difference between the two groups in surgical complications [Standard 18 (36%) vs 12 (24%], p =0.19]. ERAS group was significantly lower only in its readmission rate [Standard 15 (30%) vs 6 (12%], p =0.03]. In multivariate analyses, ERAS adherence was the only factor associated with a reduction in surgical complications [OR (95%CI) = 0.02 (0.00, 0.59), p = 0.03] and length of stay [HR (95%CI) = 18.5 (4.39, 78.4), p < 0.001].\nConclusions: ERAS program was able to decrease the readmission rate at our centre significantly. The adherence to the ERAS protocol influenced the reduction of surgical complications and length of stay.\nKeywords: Fast-track rehabilitation; Enhanced recovery after surgery; VATS.", "filename": "2020.10.07.20197962v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20197962 "}, {"title": "Serological Analysis Reveals an Imbalanced IgG Subclass Composition Associated with COVID-19 Disease Severity", "abstract": "COVID-19 is associated with a wide spectrum of disease severity, ranging from asymptomatic to acute respiratory distress syndrome (ARDS). Paradoxically, a direct relationship has been suggested between COVID-19 disease severity, and the levels of circulating SARS-CoV-2-specific antibodies, including virus neutralizing titers. Through a serological analysis of serum samples from 536 convalescent healthcare workers, we found that SARS-CoV-2-specific and virus-neutralizing antibody levels were indeed elevated in individuals that experienced severe disease. The severity-associated increase in SARS-CoV-2-specific antibody was dominated by IgG, with an IgG subclass ratio skewed towards elevated receptor binding domain (RBD)- and S1-specific IgG3. However, RBD- and S1-specific IgG1, rather than IgG3 were best correlated with virus-neutralizing titers. We propose that Spike-specific IgG3 subclass utilization contributes to COVID-19 disease severity through potent Fc-mediated effector functions. These results have significant implications for SARS-CoV-2 vaccine design, and convalescent plasma therapy.", "filename": "2020.10.07.20208603v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208603 "}, {"title": "Machine Learning Directed Interventions Associate with Decreased Hospitalization Rates in Hemodialysis Patients", "abstract": "Background:\nAn integrated kidney disease company uses machine learning (ML) models that predict the 12-month risk of an outpatient hemodialysis (HD) patient having multiple hospitalizations to assist with directing personalized interdisciplinary interventions in a Dialysis Hospitalization Reduction Program (DHRP). We investigated the impact of risk directed interventions in the DHRP on clinic-wide hospitalization rates.\nMethods: \nWe compared the hospital admission and day rates per-patient-year (ppy) from all hemodialysis patients in 54 DHRP and 54 control clinics identified by propensity score matching at baseline in 2015 and at the end of the pilot in 2018. We also used paired T test to compare the between group difference of annual hospitalization rate and hospitalization days rates at baseline and end of the pilot. \nResults:\nThe between group difference in annual hospital admission and day rates was similar at baseline (2015) with a mean difference between DHRP versus control clinics of -0.008(SD=0.09) ppy and -0.05(SD=0.96) ppy respectively. The between group difference in hospital admission and day rates became more distinct at the end of follow up (2018) favoring DHRP clinics with the mean difference being -0.155 (SD=0.38) ppy and -0.97(SD=2.78) ppy respectively. A paired t-test showed the change in the between group difference in hospital admission and day rates from baseline to the end of the follow up was statistically significant (t-value=2.73, p-value<0.01) and (t-value=2.29, p-value=0.02 ) respectively.\nConclusions:\nThese findings suggest ML model-based risk-directed interdisciplinary team interventions associate with lower hospitalization rates and hospital day rate in HD patients, compared to controls.", "filename": "2020.10.07.20207159v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207159 "}, {"title": "Post-operative serum procalcitonin vs C reactive Protein as a marker of post-operative infectious complications in pancreatic surgery. A systemic review and metaanalysis.", "abstract": "Aim of Study:\nAim of this meta-analysis was to compare diagnostic accuracy of C reactive Protein and Procalcitonin between postoperative day 3 to 5 in predicting infectious complications post pancreatic surgery.\nMethods:\nSystemic literature search was performed using MEDLINE, EMBASE and SCOPUS to identify studies evaluating the diagnostic accuracy of Procalcitonin (PCT) and C-Reactive Protein (CRP) as a predictor for detecting infectious complications between postoperative days (POD) 3 to 5 following pancreatic surgery. A meta-analysis was performed using random effect model and pooled predictive parameters. Geometric means were calculated for PCT cut offs. The work has been reported in line with PRISMA guidelines.\nResults:\nAfter applying inclusion and exclusion criteria 15 studies consisting of 2212 patients were included in the final analysis according to PRISMA guidelines. Pooled sensitivity, specificity ,Area under curve and diagnostic odds ratio (DOR)for day 3 C-reactive protein was respectively 62%,67% 0.772 and 6.54.Pooled sensitivity, specificity , Area under curve and diagnostic odds ratio (DOR)for day 3 procalcitonin was respectively 74%,79%,0.8453 and 11.03. Sensitivity, specificity, Area under curve, and Diagnostic odds ratio for day 4 C-reactive protein was respectively 60%,68%, 0.8022 and 11.90. Pooled Sensitivity, specificity and Diagnostic odds ratio of post-operative day 5 procalcitonin level in predicting infectious complications were respectively 83%,70% and 12.9. Pooled Sensitivity, specificity, AUROC and diagnostic odds ratio were respectively 50%,70%, 0.777 and 10.19.\nConclusion:\nPost-operative procalcitonin is better marker to predict post-operative infectious complications after pancreatic surgeries and post-operative day 3 procalcitonin has highest diagnostic accuracy.", "filename": "2020.10.06.20208181v1", "doi": "doi: https://doi.org/10.1101/2020.10.06.20208181 "}, {"title": "Isolation of infected people and their contacts is likely to be effective against many short-term epidemics", "abstract": "Background: Isolation of infected people and their contacts may be an effective way to control outbreaks of infectious disease, such as influenza and SARS-CoV-2. Models can provide insights into the efficacy of contact tracing, coupled with isolating or quarantining at risk people. \n\nMethods: We developed an agent-based model and simulated 15, 000 short term illnesses, with varying characteristics. For each illness we ran ten simulations on the following scenarios: (1) No tracing or isolation (None), (2) isolation of agents who have tested positive (Isolation), (3) scenario 2 coupled with minimal contact tracing and quarantine of contacts (Minimum), (4) scenario 3 with more effective contact tracing (Moderate), and (5) perfect isolation of agents who test positive and perfect tracing and quarantine of all their contacts (Maximum). \n\nResults: The median total infections of the Isolation, Minimum, Moderate and Maximum scenarios were 80%, 40%, 17% and 4% of the no intervention scenario respectively. \n\nConclusions: Isolation of infected patients and quarantine of their contacts, even if moderately well implemented, is likely to substantially reduce the number of infections in an outbreak. Randomized controlled trials to confirm these results in the real world and to analyse the cost effectiveness of contact tracing and isolation during coronavirus and influenza outbreaks are warranted.", "filename": "2020.10.07.20207845v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207845 "}, {"title": "Predictors of Death in Severe COVID-19 Patients at Millennium COVID-19 Care Center in Ethiopia: A Case-Control Study", "abstract": "Background: As the number of new cases and death due to COVID-19 is increasing, understanding the characteristics of severe COVID-19 patients and identifying characteristics that lead to death is a key to make an informed decision. In Ethiopia, as of September 27, 2020, a total of 72,700 cases and 1165 deaths were reported.\nObjective: The study aimed to assess the determinants of death in Severe COVID-19 patients admitted to Millennium COVID-19 Care Center in Ethiopia.\nMethods: A case-control study of 147 Severe COVID-19 patients (49 deaths and 98 discharged alive cases) was conducted from August to September 2020. A comparison of underlying characteristics between cases (death) and controls (alive) was assessed using a chi-square test and an independent t-test with a p-value of <0.05 considered as having a statistically significant difference. Multivariable binary logistic regression was used to assess a statistically significant association between the predictor variables and outcome of Severe COVID-19 (Alive Vs Death) where Adjusted Odds ratio (AOR), 95% CIs for AOR, and P-values were used for testing significance and interpretation of results.  \nResults: Having diabetes mellitus (AOR= 3.257, 95% CI= 1.348, 7.867, p-value=0.00), fever (AOR=0.328, 95% CI: 0.123, 0.878, p-value= 0.027) and Shortness of breath (AOR= 4.034, 95% CI= 1.481, 10.988, p-value=0.006) were found to be significant predictors of death in Severe COVID-19 patients.\nConclusions: The outcome of death in Severe COVID-19 patients is found to be associated with exposures to being diabetic and having SOB at admission. On the other hand, having a fever at admission was associated with a favorable outcome of being discharged alive.", "filename": "2020.10.07.20205575v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20205575 "}, {"title": "Diagnostic comparison of three fully automated chemiluminescent immunoassay platforms for the detection of SARS-CoV-2 antibodies", "abstract": "The whole world is battling against coronavirus disease-19 (COVID-19) pandemic caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Various strategies are taken to curb the spread of the virus and to move out from the enforced lockdown stage. Serological tests are the neediest diagnostic and surveillance tool to complement the gold standard molecular diagnostic method to track down the transmission rate of SARS-CoV-2. Automated chemiluminescent immunoassay (CLIA) based analyzers become highly demanding platforms both to clinicians and policy makers for the detection anti-SARS-CoV-2 antibodies. In this study, serum from 594 patients positive for COVID-19 and 100 samples from pre-COVID cases were tested by three automated platforms: Abbott architect i2000SR, Roche cobas e411 and Yhlo iFlash 1800 and their diagnostic accuracy were compared. All three platforms showed high specificity as claimed by manufacturer. Clinical sensitivities of the machines were calculated as 64.48% (58.67-70.3) for Abbott, 80.48% (76.62-84.34) for Roche and 76.94% (72.65-81.23) for Yhlo. The Cohens kappa value was determined from 0.69-0.89 when inter-rater agreements were calculated. The area under the curves (AUC) values demonstrated Roche Cobas e411 as the diagnostically most accurate platform among the three CLIA analyzers.", "filename": "2020.10.07.20207696v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207696 "}, {"title": "Psychiatric morbidity and protracted symptoms in recovered COVID-19 patients", "abstract": "We investigated  the psychiatric symptomatology and the protracted symptoms in recently recovered COVID-19 patients. This cross-sectional study assessed 284 patients recruited from a tertiary hospital. Patients completed a web-based survey on socio-demographic data, past medical/psychiatric history, and additional information relevant to the outbreak conditions. The psychiatric status  was assessed using the Impact of Events Scale-Revised (IES-R), Hospital Anxiety and Depression Scale (HADS), Pittsburgh Sleep Quality Index (PSQI), and MINI suicidality scale. Patients completed a checklist for the acute symptom burden and protracted symptoms that were experienced after the acute infection. After a mean of  50 days following the diagnosis of COVID-19, 98 patients (34.5%) reported clinically significant PTSD, anxiety, and/or depression, with PTSD being the most common condition reported (25.4%). One hundred and eighteen patients (44.3%) reported one or more protracted symptom(s), with fatigue, muscle aches, alteration of smell/taste, headache and difficulty in concentration, being the most common symptoms reported. Predictors of PTSD symptom severity were the female gender, past traumatic events, protracted symptoms, perceived stigmatization, and a negative view on the seriousness of the COVID-19 pandemic. Binary logistic regression analysis showed that PTSD symptom severity was the sole independent predictor of the presence of protracted symptoms. Our results suggest that COVID-19 patients may be prone to substantial psychological distress in the first months after the infection. The protracted symptoms were also frequent in this period, and these were related to the posttraumatic psychiatric morbidity. Both the psychiatric morbidity and the protracted symptoms were independent of the initial infection severity. Further research on the neurobiological commonalities between the protracted symptoms and PTSD in COVID-19 patients is warranted.", "filename": "2020.10.07.20208249v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208249 "}, {"title": "Hepatic resection versus transarterial chemoembolisation for intermediate-stage hepatocellular carcinoma\uff1aa predicted mortality risk-based decision analysis", "abstract": "Background: The selection criterion for hepatic resection(HR) in intermediate-stage(IM) hepatocellular carcinoma(HCC) is still controversial. This study aims to compare transarterial chemoembolisation (TACE) and HR in the range of predicted overall mortality(OM).\nMethods: In all, 946 consecutive patients with IM-HCC were categorised in HR and TACE group. We performed multivariable Cox regression model to predict OM in HR patients. To evaluate the HR impact on OM concerning baseline characteristics, we test the interaction between predicted OM risk and HR status. The cut-off values were determined by two-piece-wise linear regression model and decision curve analysis. Also, the inverse probability of treatment weight was performed to minimise potential differences as a sensitivity analysis.\nResults: Totally, 23.0% (n=225) of patients received HR. The 5-yr overall survival rate was higher in the HR group versus the TACE group (52.3% vs 22.8%; p<0.0001). In the HR group, five predictors (all<0.05) were selected to calculate the 5-yr OM risk. This model also used to predict the 5-yr OM-free survival rate. The line of HR and TACE was crossing with predicted OM risk at 100%. The benefit of HR versus TACE decreased progressively as predicted OM risk>55%. When OM risk >80%, HR was not significantly superior to TACE (HR:0.61;95%CI:0.31,1.21), and both HR and TACE did not increase net benefit.\nConclusions: Hepatic resection was superior to transarterial chemoembolisation for intermediate-stage hepatocellular carcinoma at the 5-yr OM risk<80%.", "filename": "2020.10.07.20166769v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20166769 "}, {"title": "High seroprevalence of SARS-CoV-2 antibodies among people living in precarious situations in Ile de France", "abstract": "Background\nA nationwide lockdown was implemented in France on 17 March 2020 to control the COVID-19 pandemic. People living in precarious conditions were relocated by the authorities to emergency shelters, hotels and large venues. Medecins sans Frontieres (MSF) then intervened to provide medical care in several of these locations in Paris and in Seine-Saint-Denis, one of its suburbs, between March and June 2020. A seroprevalence survey was conducted to assess the level of exposure to COVID-19 among the population living in the sites. To our knowledge, this is the first assessment of the impact of the pandemic on populations living in insecure conditions in Europe.\nMethods\nWe conducted a cross-sectional seroprevalence study in the food distribution sites, emergency shelters and workers residences supported by MSF in Paris and Seine-Saint-Denis, to determine the extent of COVID-19 exposure as determined by SARS-CoV2 antibody seropositivity. The detection of SARS-COV2 antibodies in serum was performed at the Institut Pasteur of Paris using two LuLISA (Luciferase-Linked Immunosorbent Assay) assays and a Pseudo Neutralization Test. A questionnaire covering sociodemographic characteristics, living conditions, adherence to sanitary recommendations and symptom manifestations was also completed. We describe here the seroprevalence site by site and identify the risk factors for seropositivity using a multivariable logistic regression model with site random effects. We also investigated associations between seropositivity and symptoms eventually reported.\nFindings\nOverall, 426/818 individuals tested positive in the 14 sites investigated. Seroprevalence varied significantly with the type of site (chi2 p<0.001). It was highest at 88.7% (95%CI 81.8-93.2) among individuals living in workers residences, followed by 50.5% (95%CI 46.3-54.7) in emergency shelters and 27.8 % (95%CI 20.8-35.7) among individuals recruited from the food distribution sites. Seroprevalence also varied significantly between sites of the same type. Among other risk factors, the odds for seropositivity were higher among individuals living in crowded sites (medium: adj. OR 2.7, 95%CI 1.5-5.1, p=0.001; high: adj. OR 3.4, 95%CI 1.7-6.9, p<0.001) compared with individuals from low crowding sites and among those who reported transit accommodation in a gymnasium before the lockdown (adj. OR 3.1, 95%CI 1.2-8.1, p=0.023). More than two-thirds of the seropositive individuals (68.3%; 95%CI 64.2-72.2) did not report any symptoms during the recall period.\nInterpretation \nThe results demonstrate rather high exposure to SARS-COV-2 with important variations between study sites. Living in crowded conditions was identified as the most important explanatory factor for differences in levels of exposure. This study describes the key factors which determine the risk of exposure and illustrates the importance of identifying populations at high risk of exposure in order to orient and adapt prevention and control strategies to their specific needs.", "filename": "2020.10.07.20207795v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20207795 "}, {"title": "AncestryDNA COVID-19 Host Genetic Study Identifies Three Novel Loci", "abstract": "Human infection with SARS-CoV-2, the causative agent of COVID-19, leads to a remarkably diverse spectrum of outcomes, ranging from asymptomatic to fatal. Recent reports suggest that both clinical and genetic risk factors may contribute to COVID-19 susceptibility and severity. To investigate genetic risk factors, we collected over 500,000 COVID-19 survey responses between April and May 2020 with accompanying genetic data from the AncestryDNA database. We conducted sex-stratified and meta-analyzed genome-wide association studies (GWAS) for COVID-19 susceptibility (positive nasopharyngeal swab test, ncases=2,407) and severity (hospitalization, ncases=250). The severity GWAS replicated associations with severe COVID-19 near ABO and SLC6A20 (P<0.05). Furthermore, we identified three novel loci with P<5x10-8. The strongest association was near IVNS1ABP, a gene involved in influenza virus replication, and was associated only in males. The other two novel loci harbor genes with established roles in viral replication or immunity: SRRM1 and the immunoglobulin lambda locus. We thus present new evidence that host genetic variation likely contributes to COVID-19 outcomes and demonstrate the value of large-scale, self-reported data as a mechanism to rapidly address a health crisis.", "filename": "2020.10.06.20205864v1", "doi": "doi: https://doi.org/10.1101/2020.10.06.20205864 "}, {"title": "Detecting and isolating false negatives of SARS-CoV-2 primers and probe sets among the Japanese Population: A laboratory testing methodology and study", "abstract": "The global COVID-19 pandemic has spread across various continents in diverse methods and speed while opening up discussion for technological and scientific questions pertaining methodology of testing accuracy among diverse viral strains. \n\nOn the issue of testing sensitivity and accuracy, RT-PCR is commonly viewed as a standard testing protocol globally as the predominant accurate testing method as opposed to other rapid testing methods. However, each country's infectious disease authority has established its own primers/probe sets guidelines and protocols, thereby, the global testing community lacks a \"Standardized Universal Primer(s)\" (SUP) that is foolproof for the COVID-19 patients among various populations today. As a result, RT-PCR testing accuracy and results may vary depending on which primer was used, most likely resulting in false negative and/or false positive calls associated with RT-PCR testing. \n\nIn this study, a comparative study between primers from different countries' disease control centers was conducted. 11,652 samples from Japanese population were tested for SARS-CoV-2 positive using recommended RT-PCR primers/probe sets from Japan National Institute of Infectious Disease (NIID) and US Centers for Disease Control and Prevention (CDC).\n\nResults: \nOf the 102 positive samples, 17 samples (16.7% of total positives) showed inconsistent results when tested for the following primers: JPN-N2, JPN-N1, CDC-N1, and CDC-N2. In addition, CDC recommended primer/probe sets showed relatively higher sensitivity and accuracy among the primer/probe sets used for the detection of \nSARS-CoV-2 positive clones. \n\nConclusion: \nDue to the inconsistency in the positive/negative results for JPN-N2, JPN-N1, \nCDC-N1, and CDC-N2 primer/probe sets, SARS-CoV-2 samples run via RT-PCR will result in false negative/positive subjected to differences in virus mutation in a specific sequence region targeted by a primer. This outcome shows that the use of JPN-N2 primer combined with CDC-N2 primer produces the most effective result to reduce false negatives in Japan region. Furthermore, adding CDC-N1 will result in reducing false negatives, but also false positives. Further investigation remains open for confirmation whether similar irregular pattern occur with primers targeting other regions such as E or ORF1ab in order to isolate false negatives and/or positives in future PCR testing for COVID-19.\n \nKeywords: COVID-19, SARS-CoV-2, RT-PCR testing, RT-PCR performance, Genomic variants, Primers, Probe sets, Sensitivity.", "filename": "2020.10.07.20208264v1", "doi": "doi: https://doi.org/10.1101/2020.10.07.20208264 "}, {"title": "Assessing Knowledge, Attitudes, and Practices towards Causal Directed Acyclic Graphs among Epidemiologists and Medical Researchers: a qualitative research project", "abstract": "Background: Estimating the strength of causal effects is an important component of epidemiologic research, and causal graphs provide a key tool for optimizing the validity of these effect estimates. Although a large literature exists on the mathematical theory underlying the use of causal graphs, including directed acyclic graphs, to assess and describe causal assumptions, and translate these assumptions into appropriate statistical analysis plans, less literature exists to aid applied researchers in understanding how best to develop and use causal graphs in their research projects. \nObjective: We sought to understand this gap by surveying practicing epidemiologists and medical researchers on their knowledge, level of interest, attitudes, and practices towards the use of causal graphs in applied epidemiology and health research. \nMethods: We conducted an anonymous survey of self-identified epidemiology and health researchers via Twitter and via the Society of Epidemiologic Research membership listserv. The survey was conducted using Qualtrics and asked a series of multiple choice and open-ended questions about causal graphs. \nResults: In total, 439 responses were collected. Overall, a majority of participants reported being comfortable with using causal graphs and reported using them 'sometimes', 'often', or 'always' in their research. Almost three quarters of respondents had received formal training on causal graphs (typically causal directed acyclic graphs). Having received training appeared to improve comprehension of the underlying assumptions of causal graphs. Many of the respondents who did not use causal graphs reported lack of knowledge as a barrier to using DAGs in their research. Of the participants who did not use DAGs, many expressed that trainings, either in-person or online, would be useful resources to help them use causal graphs more often in their research. \nConclusion: Causal graphs are of interest to epidemiologists and medical researchers, but there are several barriers to their uptake. Additional training and clearer guidance are needed. In addition, methodological developments regarding visualization of effect measure modification and interaction on causal graphs is needed.", "filename": "2020.01.17.20017939v2", "doi": "doi: https://doi.org/10.1101/2020.01.17.20017939 "}, {"title": "Polygenic associations and causal inferences between serum immunoglobulins and amyotrophic lateral sclerosis", "abstract": "Chronic inflammation might contribute to the development of amyotrophic lateral sclerosis (ALS), the relationship between serum immunoglobulins and risk of ALS remains however unclear. In order to overcome limitations like reverse causation and residual confounding commonly seen in the observational studies, we applied molecular epidemiological analyses to examine the polygenic and causal associations between serum immunoglobulins and ALS. Summary statistics from the large-scale genome-wide association studies (GWAS) among European ancestry populations (~15000 individuals for serum immunoglobulins, and more than 36000 individuals for ALS) were accessed from different consortia. The relationships between three types of serum immunoglobulins (IgA, IgM, and IgG) and ALS were investigated in a discovery phase and then in a replication phase. Polygenic risk score (PRS) analysis was performed with PRSice package to test the polygenic association, and Mendelian randomization (MR) analysis was performed with TwoSampleMR package to infer the causality. An inverse polygenic association was discovered between IgA and ALS as well as between IgM and ALS. Such associations were however not replicated using a larger GWAS of ALS, and no causal association was observed for either IgA-ALS or IgM-ALS. A positive polygenic association was both discovered [odds ratio (OR) = 1.18, 95% confidence interval (CI): 1.12-1.25, P=5.9x10-7] and replicated (OR=1.13, 95% CI: 1.06-1.20, P=0.001) between IgG and ALS. A causal association between IgG and ALS was also suggested in both the discovery (OR=1.06, 95%CI: 1.02-1.10, P=0.009) and replication (OR=1.07, 95%CI: 0.90-1.24, P=0.420) analyses, although the latter was not statistically significant. This study suggests a shared polygenic risk between serum IgG (as a biomarker for chronic inflammation) and ALS.", "filename": "2020.04.07.20057265v3", "doi": "doi: https://doi.org/10.1101/2020.04.07.20057265 "}, {"title": "Pitfalls in EEG analysis in patients with non-convulsive status epilepticus", "abstract": "Objective.\nElectroencephalography (EEG) interpretations through visual (by human raters) and automated (by computer technology) analysis are still not reliable for the diagnosis of non-convulsive status epilepticus (NCSE). This study aimed to identify typical pitfalls in the EEG analysis and make suggestions as to how those pitfalls might be avoided.\n\nMethods.\nWe analyzed the EEG recordings of individuals who had clinically confirmed or suspected NCSE. Epileptiform EEG activity during seizures (ictal discharges) were visually analyzed by two independent raters. We investigated whether unreliable EEG visual interpretations quantified by low inter-rater agreement can be predicted by the characteristics of ictal discharges and the clinical data of individuals. In addition, the EEG recordings were automatically analyzed by in-house algorithms. To further explore the causes of unreliable EEG interpretations, two epileptologists analyzed EEG patterns most likely misinterpreted as ictal discharges based on the differences between the EEG interpretations through the visual and automated analysis.\n\nResults.\nShort ictal discharges with a gradual onset (developing over 3 seconds in length) were liable to be misinterpreted. An extra 2 minutes of ictal discharges contributed to an increase in the kappa statistics of > 0.1. Other problems were the misinterpretation of abnormal background activity (slow wave activities, other abnormal brain activity, and the ictal-like movement artifacts), continuous interictal discharges, and continuous short ictal discharges.\n\nConclusion.\nA longer duration criterion for NCSE-EEGs than 10 seconds that commonly used in NCSE working criteria is needed. Using knowledge of historical EEGs, individualized algorithms, and context-dependent alarm thresholds may also avoid the pitfalls.", "filename": "2020.10.02.20205583v2", "doi": "doi: https://doi.org/10.1101/2020.10.02.20205583 "}, {"title": "A Bayesian estimate of the COVID-19 infection fatality rate in Brazil based on a random seroprevalence survey", "abstract": "We infer the infection fatality rate (IFR) of SARS-CoV-2 in Brazil by combining  three datasets. We compute the prevalence via the population-based seroprevalence survey EPICOVID19-BR, which tested 89000 people in 3 stages over a period of 5 weeks. This randomized survey selected people of 133 cities (accounting for 35.5% of the Brazilian population) and tested them for IgM/IgG antibodies making use of a rapid test. We estimate the time delay between the development of antibodies and subsequent fatality using the public SIVEP-Gripe dataset. The number of fatalities is obtained using the public Painel Coronavirus dataset. We obtain the IFR via Bayesian inference for each survey stage and 27 federal states. In particular, we include the effect of fading IgG levels by marginalizing over the time T after contagion at which the test gives a negative result. We adopt a flat broad prior on the interval [40,80] days. We infer a country-wide average IFR of 0.85% (95% CI: 0.76-0.99%).", "filename": "2020.08.18.20177626v2", "doi": "doi: https://doi.org/10.1101/2020.08.18.20177626 "}, {"title": "Plasma ACE2 activity is persistently elevated following SARS-CoV-2 infection: implications for COVID-19 pathogenesis and consequences", "abstract": "COVID-19 causes persistent endothelial inflammation, lung and cardiovascular complications. SARS-CoV-2 utilises the catalytic site of full-length membrane-bound angiotensin converting enzyme 2 (ACE2) for cell entry causing downregulation of tissue ACE2. We reported downregulation of cardiac ACE2 is associated with increased plasma ACE2 activity. In this prospective observational study in recovered COVID-19 patients, we hypothesised that SARS-CoV-2 infection would be associated with shedding of ACE2 from cell membranes and increased plasma ACE2 activity.\n\nMethods \nWe measured plasma ACE2 catalytic activity using a validated, sensitive quenched fluorescent substrate-based assay in a cohort of Australians aged 18 years and over who had recovered from mild, moderate or severe SARS-CoV-2 infection (positive result by PCR testing) (n=66) and age and gender matched uninfected controls (n=70). Serial samples were available in 23 recovered SARS-CoV-2 patients. \n\nResults \nPlasma ACE2 activity at a median of 35 days post-infection [interquartile range 30-38 days] was 97-fold higher in recovered SARS-CoV-2 patients compared to controls (5.8 [2-11.3] vs. 0.06 [0.02-2.2] pmol/min/ml, p<0.0001).  There was a significant difference in plasma ACE2 activity according to disease severity (p=0.033), with severe COVID-19 associated with higher ACE2 activity compared to mild disease (p=0.027). Men (n=39) who were SARS-CoV-2 positive had higher median plasma ACE2 levels compared to women (n=27) (p<0.0001). We next analysed whether an elevated plasma ACE2 activity level persisted following SARS-CoV-2 infection in subjects with blood samples at 63 [56-65] and 114 [111-125] days post infection. Plasma ACE2 activity remained persistently elevated in almost all subjects, with no significant differences between timepoints in post-hoc comparisons (p>0.05). \n\nDiscussion \nThis is the first description that plasma ACE2 activity is elevated after COVID-19 infection, and the first with longitudinal data indicating plasma ACE2 activity remains elevated out to a median of 114 days post- infection. Larger studies are now needed to determine if persistent elevated plasma ACE2 activity identifies people at risk of prolonged illness following COVID-19.", "filename": "2020.10.06.20207514v2", "doi": "doi: https://doi.org/10.1101/2020.10.06.20207514 "}, {"title": "Early Release Estimates for SARS-CoV-2 Prevalence and Antibody Response Interim Weighting for Probability-Based Sample Surveys", "abstract": "The authors have withdrawn this manuscript because analytic strategies for this project have changed. Therefore, the authors do not wish this work to be cited as reference for the project. If you have any questions, please contact the corresponding author.", "filename": "2020.09.15.20195099v2", "doi": "doi: https://doi.org/10.1101/2020.09.15.20195099 "}, {"title": "ASSESSING THE AGE SPECIFICITY OF INFECTION FATALITY RATES FOR COVID-19: SYSTEMATIC REVIEW, META-ANALYSIS, AND PUBLIC POLICY IMPLICATIONS", "abstract": "This paper assesses the age specificity of the infection fatality rate (IFR) for COVID-19 using results from 29 seroprevalence studies as well as five countries that have engaged in comprehensive tracing of COVID-19 cases. The estimated IFR is close to zero for children and younger adults but rises exponentially with age, reaching 0.4% at age 55, 1.4% at age 65, 4.6% at age 75, and 15% at age 85. We find that differences in the age structure of the population and the age-specific prevalence of COVID-19 explain nearly 90% of the geographical variation in population IFR. Consequently, protecting vulnerable age groups could substantially reduce the incidence of mortality.", "filename": "2020.07.23.20160895v6", "doi": "doi: https://doi.org/10.1101/2020.07.23.20160895 "}, {"title": "BayesSMILES: Bayesian Segmentation Modeling for Longitudinal Epidemiological Studies", "abstract": "Coronavirus disease 2019 (COVID-19) is a pandemic. To characterize the disease transmissibility, we propose a Bayesian change point detection model using daily actively infectious cases. Our model is built upon a Bayesian Poisson segmented regression model that can 1) capture the epidemiological dynamics under the changing conditions caused by external or internal factors; 2) provide uncertainty estimates of both the number and locations of change points; 3) adjust any explanatory time-varying covariates. Our model can be used to evaluate public health interventions, identify latent events associated with spreading rates, and yield better short-term forecasts.", "filename": "2020.10.06.20208132v2", "doi": "doi: https://doi.org/10.1101/2020.10.06.20208132 "}, {"title": "AN EVALUATION OF EDUCATIONAL INSTITUTIONS SAFE REOPENING STRATEGIES FOR IN-PERSON CLASSES AMID THE COVID-19 PANDEMIC", "abstract": "Research Context. Can educational institutions open up safely amid COVID-19? We build an epidemiological model to investigate the strategies necessary for institutions to safely reopen. The four measures that are most relevant for in-person opening are: (i) wide-spread rapid testing, possibly saliva-based, (ii) enforcement of mask-wearing, (iii) social distancing, and (iv) contact tracing. \n\nResearch Design. Using an analytical setup, we theoretically demonstrate that institutions need to test at a relatively high level (e.g., at least once every week for all individuals) in the initial phases of reopening. Guided by the analytical setup, we derive insights from an agent-based simulation. Contact tracing is relatively more important when the positivity rate from random testing is relatively low, which is likely during the initial phases. An adaptive testing strategy based on positivity rates can help institutions optimally manage the costs and risks of reopening. Finally, to demonstrate the strategies in practice, we provide empirical estimates of some of the educational institutions opening up experience and comment on mitigation strategies. Empirically, we characterize the role of testing using data from the SHIELD program at the University of Illinois at Urbana Champaign (UIUC). \n\nResults. We show that increasing the testing levels from 0.2 per capita per day to 0.3 per capita per day can reduce the infectivity from 0.25 to 0.01, with an average slope of the infectivity to the testing curve being 0.35 in this range. We also cross-validate the results with data from a large number of universities in the United States, and show that institutions with higher levels of testing are associated with lower infections.  The estimated marginal effect of increasing testing levels by 1% per capita per day across universities can reduce the positivity by an average of 0.0228% with a 99% confidence interval of [0.0209%, 0.0253%]. We also provide an estimate of the locational effects of institutions on mitigation strategies. We estimate from data on 228 different universities across the United States that an increase of infection rate at the county where a university is located by 1% has the potential to increase the institutional infection rate by an average of 0.14% with a 99% confidence interval of [0.032%, 0.248%] across all universities. This indicates that universities are not closed systems, rather they are open systems subject to external influence, and the extent of external influence potential is an important consideration for opening up of universities. \n\nContributions. This paper contributes to the nascent literature on combating the COVID-19 pandemic and is especially relevant for large organizations. This work is motivated and guided by the SHIELD program of UIUC. We provide important policy pointers for the reopening of universities.", "filename": "2020.09.04.20188680v3", "doi": "doi: https://doi.org/10.1101/2020.09.04.20188680 "}, {"title": "Modelling the potential impact of mask use in schools and society on COVID-19 control in the UK", "abstract": "Recent findings suggest that an adequate test-trace-isolate (TTI) strategy is needed to prevent a secondary COVID-19 wave with the reopening of society in the UK. Here we assess the potential importance of mandatory masks in the parts of community and in secondary schools. We show that, assuming current TTI levels, adoption of masks in secondary schools in addition to community settings can reduce the size of a second wave, but will not prevent it; more testing of symptomatic people, tracing and isolating of their contacts is also needed. To avoid a second wave, with masks mandatory in secondary schools and in certain community settings, under current tracing levels, 68% or 46% of those with symptomatic infection would need to be tested if masks' effective coverage were 15% or 30% respectively, compared to 76% and 57% if masks are mandated in community settings but not secondary schools.", "filename": "2020.09.28.20202937v2", "doi": "doi: https://doi.org/10.1101/2020.09.28.20202937 "}]}